[{"path":"index.html","id":"prefacio","chapter":"Prefacio","heading":"Prefacio","text":"Este texto ha sido editado en respuesta la aparente falta de un libro de texto introductorio al análisis cuantitativo y estadísticas acesible y moderno en castellano. Si bien fue concebido como material de cátedra para Metodologías cuantitativas materia que dicta el autor en la Escuela de Humanidades de la Universidad Nacional San Martín, se adaptará fácilmente cursos introductorios de estadísticas en general.","code":""},{"path":"index.html","id":"segunda-edición","chapter":"Prefacio","heading":"Segunda edición","text":"En la segunda edición se corrigió algunos errores ortográficos y de estilo. Optamos por actualizar los ejemplos para incorporar los paquetes del «tidyverse» ya que hemos observado que su uso y adaptación atenúa la curva de aprendizaje para quienes usan R por primera vez o con escasos conocimientos previos.","code":""},{"path":"index.html","id":"estructura-del-libro","chapter":"Prefacio","heading":"Estructura del libro","text":"Cada capítulo desarrolla un tema y/o concepto ser tratado en clase y la secuencia corresponde un curso introductorio de estadístocos «clásico», por lo que conviene leerlos en orden. Sigue el orden propuesto por Christopher Butler1.","code":""},{"path":"index.html","id":"glosario","chapter":"Prefacio","heading":"Glosario","text":"Uno de los objetivos de este trabajo es dotar al lector con las herramientas necesarios para convertirse en un consumidor crítico de textos que se valen de métodos cuantitativos y/o estadísticas para su argumento. En vista de la enorme cantidad de material disponible en inglés, sobre todo en el ámbito acadédico, el autor ha optado por incluir terminología bilingüe español-inglés. Esta elección obedece un criterio práctico. En cada capítulo encontrarán un glosario con los principales términos mencionados. Incluye traducción inglés y referencias R cuando sea relevante.","code":""},{"path":"index.html","id":"r-y-rstudio","chapter":"Prefacio","heading":"R y Rstudio","text":"R es un leguaje de programación especializado para análisis de datos. Es de fuente abierta (Open Source) y uso gratuito. Rstudio es un editor de R que también de uso sin cargo. Ambas herramientas están disponibles en internet y son de amplio uso tanto en el mundo académico como la industria.Se puede descargar e instalar R accediendo esta URL: https://cran.r-project.org/mirrors.html.Para Rstudio la URL es: https://www.rstudio.com/products/rstudio/download/#download.Se recomienda siempre instalar R primero y luego Rstudio ya que este depende de aquel.","code":""},{"path":"index.html","id":"ejemplos-en-r","chapter":"Prefacio","heading":"Ejemplos en R","text":"lo largo de este libro encontrarán ejemplos prácticos que pueden ejecutarse en R. El código se diferenciará del resto del texto por su formato, como se puede apreciar en el ejemplo siguiente:Por convención se incluye el promt (p.e. “>”) de la consola de R, y los valores de retorno son comentados con “##”, lo que corresponde al estándar para textos técnicos de esta índole. También se puede hacer referencia código dentro del texto corrido con el mismo formato. Por ejemplo: 1+1.","code":"\n1+1#> [1] 2"},{"path":"index.html","id":"edición","chapter":"Prefacio","heading":"Edición","text":"Este texto fue editado con bookdown,2 un paquete de R3 que extiende las capacidades de knitr4 y R-markdown5 para publicaciones más voluminosas. También hace uso de los paquetes tidyverse6 y bayestestR7.","code":""},{"path":"index.html","id":"agradecimientos","chapter":"Prefacio","heading":"Agradecimientos","text":"Agradezco mi colega Diego Forteza por su ayuda y apoyo en durante el proceso de redacción y Cecilia Magadán por su corrección de estilo.Debo expresar también profunda gratitud Bow Street Destillery en Dublin, Irlanda; sin cuyos productos este proyecto habría sin duda quedado inconcluso.","code":""},{"path":"conceptos-fundamentales.html","id":"conceptos-fundamentales","chapter":"Capítulo 1 Conceptos fundamentales","heading":"Capítulo 1 Conceptos fundamentales","text":"En este capítulo introducimos algunos conceptos fundamentales del análisis cuantitativo y de las estadísticas. Consideramos los conceptos de población y muestra. Hacemos una brevísima introducción la teoría de la probabilidad. Diferenciamos entre los algunos usos importantes de la estadística: descriptiva e inferencial. Finalmente consideramos algunas maneras de clasificar variables.","code":""},{"path":"conceptos-fundamentales.html","id":"poblaciones-y-muestras","chapter":"Capítulo 1 Conceptos fundamentales","heading":"1.1 Poblaciones y muestras","text":"En su uso diaro usamos población para designar un grupo de personas, por ejemplo la población del Gran Buenos Aires; o por lo menos de seres vivos como por ejemplo la población de ratas de la CABA. En estadísticas, en cambio, se usa el término de manera más general para significar cualquier recolección de un conjunto, elementos, artículos o sujetos que gozan de características comunes con el fin de estudiarlos y de esta forma se sacar conclusiones específicas para determinar sus resultados. Así podemos hablar de la población de sustantivos en las obras de Jorge Luis Borges o de la población de notas asignadas en los cursos nivel universitario.Podemos distinguir entre poblaciones finintas e infinitas. La población de motocicletas vendidas en Buenos Aires en septiembre es finita. En cambio la población de temperaturas medidas en el Campus de San Martín es infinita, ya que, por lo menos teóricamente, podemos seguir midiendo para siempre.Cuando una población fininta es demasiado grande podemos investigar la totalidad de la población. Pero, si la población es muy grande o potencialmente infinita tenemos que estar contentos con muestras extraídas de esta población. Por ejemplo: si queremos saber quién va ganar las próximas elecciones podríamos preguntar todo aquel que tiene derecho votar cómo piensa votar para sacar el resultado. En la práctica esta metodología resultaría demasiado costosa, por lo que hacemos una muestra representativa de votantes, les preguntamos y generalizamos.Resulta evidente que hay que tener cuidado al selecionar una muestra para análisis. Los métodos estadísticos, los que nos permiten generalizar e inferir, suponen que las muestras están tomadas de manera aleatoria o al azar. Esto significa que la muestra sea arbitraria, sino que cualquier unidad de la población que estamos estudiando tiene la misma probabilidad de ser selecionada para hacer parte de la muestra.\nFigura 1.1: Población y muestra.\n","code":""},{"path":"conceptos-fundamentales.html","id":"muestra-aleatoria","chapter":"Capítulo 1 Conceptos fundamentales","heading":"1.1.1 Muestra aleatoria","text":"Para tener una muestra verdaderamente aleatoria de una población deberíamos asignar un número u otro identificador único cada una de las unidaded de la población –cada persona si se trata de una población humana– escribir cada número en un papel y echarlos en una tómbola. Luego de virarla por algún tiempo y mesclar bien los papeles, podríamos de allí sacar la cantidad de papeles que corresponda al tamaño de nuestra muestra. Obviamente esto resulta muy práctico por lo que se suele empezar con una secuencia de números aleatorios del tamaño de la muestra y extraer unidades de la población basado en ello. Por ejemplo, si quisieramos sacar veinte libros al hazar de un estante de la biblioteca que contiene doscientos libros, necesitamos veinte números aleatorios entre uno y doscientos, y sacamos los libros que desde algún punto de referencia (primer libro del primer nivel) está esa distancia.Ahora, ¿dónde encontramos números aleatorios? Hay secuencias en libros de estadísticas, usados principalmente antes de la existencia de computadoras. También se pueden generar esas secuencias en linea. Finalmente, R tienen un generador de números aleatorios que nos permite generar los de números de nuestra muestra con un solo comando usando la función de R sample.","code":""},{"path":"conceptos-fundamentales.html","id":"ejemplo-en-r-generar-muestra","chapter":"Capítulo 1 Conceptos fundamentales","heading":"Ejemplo en R: Generar muestra","text":"Acá le estamos pidiendo R que nos de una muestra aleatoria (sample ) de números entre uno y doscientos (x = 1:200), y que la muestra sea de veinte size = 20 ). Con estos números podemos ir al estante y sacar los libros que queremos estudiar.Si corren este comando desde su consola de R los números deben salir diferentes, se hace una muestra aleatoria cada vez.","code":"\nsample(x = 1:200, size = 20)\n\n## [1] 166  46  42 179 188 143 126 135 102  93  72 193  13 107 198 100  88  67  33  99"},{"path":"conceptos-fundamentales.html","id":"ejemplo-en-r-ordenar-los-datos","chapter":"Capítulo 1 Conceptos fundamentales","heading":"Ejemplo en R: Ordenar los datos","text":"También es posible ordenar los números, lo cual nos ahorra un poco de tiempo al retirar los libros. Se logra con la función sort.","code":"\nsort(\n  sample(x = 1:200, size = 20, replace = TRUE)\n)\n## [1]  29  35  38  41  54  74  75  79  85  92 103 112 114 120 127 153 173 185 187 188"},{"path":"conceptos-fundamentales.html","id":"muestra-cuasialeatoria","chapter":"Capítulo 1 Conceptos fundamentales","heading":"1.1.2 Muestra cuasialeatoria","text":"Otra estrategia que podría emplearse para sacar veinte libros al azar del estante que describimos en la sección anterior sería decidir que vamos sacar cada diez libros ya que \\({200\\over20} = 10\\). Este tipo de muestra lleva el epíteto cuasialeatoria, y funciona bien si el orden original de la población es aleatorio. Sin embargo, hay que tener en cuenta que esta estrategia puede generar una muestra representativa si existe una estructura en ese orden. Típicamente puede resultar problemática si existe periodicidad en la población que estamos analizando. Si, por ejemplo, queremos tener una muestra de cuantos ómnibus pasan delante de mi casa por día sería mala idea decir que vamos contarlos cada siete días. Si el día que empezamos es un domingo obtendremos seguramente una muestra con cantidades inferiores la población real (en este caso definida como todos los ómnibus que pasan por mi casa en un día); y si empezamos contar un lunes las cantidades serían superiores.","code":""},{"path":"conceptos-fundamentales.html","id":"ejemplo-en-r-generar-una-sequencia","chapter":"Capítulo 1 Conceptos fundamentales","heading":"1.1.2.1 Ejemplo en R: Generar una sequencia","text":"Si bien sacar la secuencia para sacar cada diez libros resulta trivial, existe la manera que hacerlo también con una función de R.La función seq (de secuencia), toma tres parámetros, desde dónde empezamos (=10), hasta dónde queremos llegar (=200), y con qué distancia (=10).Por lo pronto se vuelve más útil si estamos trabajando con números menos redondos. Digamos que queremos sacar cada siete libros de un estante que contiene cien empezando por el número seis.","code":"\nseq( from = 10, to = 200 , by=10 )\n## [1]  10  20  30  40  50  60  70  80  90 100 110 120 130 140 150 160 170 180 190 200\nseq( from = 6, to = 100 , by = 7 )\n## [1]  6 13 20 27 34 41 48 55 62 69 76 83 90 97"},{"path":"conceptos-fundamentales.html","id":"muestra-estratificada","chapter":"Capítulo 1 Conceptos fundamentales","heading":"1.1.3 Muestra estratificada","text":"Cuando conocemos algunos parámetros de la población que queremos estudiar también nos podemos asegurar que nuestra muestra tenga parámetros similares. Esta estrategia puede resultar particularmente útil si suponemos que este parámetro puede tener alguna influencia en otra variable cuya distribución queremos conocer. Si por ejemplo suponemos que el sexo puede influir en la opinión de una persona sobre la ley del aborto podemos asegurarnos de que nuestra muestra tiene una distribución similar la de la población en general. Se sabe que hay más o menos mitad y mitad8 en la población general por lo que convendría que nuestra muestra tenga la misma distribución. Así podemos sacar, para una muestra de veinte, diez hombres y diez mujeres al azar9. Lo mismo se puede aplicar otras variables, por ejemplo, clase social, país de origen etcétera.","code":""},{"path":"conceptos-fundamentales.html","id":"representatividad","chapter":"Capítulo 1 Conceptos fundamentales","heading":"1.2 Representatividad","text":"Es importante entender que ninguna de las estrategias descritas en la sección anterior nos garantiza que la muestra que sacamos sea representativa de la población, con lo cual está garantizado que una generalización basada en esa muestra sea válida. Lo que sí se puede calcular es la probabilidad de que la muestra sea representativa. Es decir, podemos tener una estimación de en qué medida la muestra representa la población.Para profundizar un poco este concepto vamos hacer un breve desvío y desarrollar un poco de teoría de la probabilidad por medio de un ejemplo sumamente sencillo. Digamos que queremos hacer una muestra aleatoria de la población en Argentina. Vamos seleccionar al azar tan solo tres personas para nuestra muestra. Ya que sabemos que hay la misma cantidad de hombres y mujeres la probabilidad de que el/la primero/que elijamos sea hombre es 0,510, lo cual también es la probabilidad de que sea mujer. Ahora, cuando seleccionamos el/la segundo/y tercero/las probabilidad son las mismas en todos los casos. Las leyes de probabilidad indican que la probabilidad de que dos o más eventos independientes sucedan es el producto de sus probabilidades individuales. Entonces, cuál es la probabilidad de que los tres miembros de la muestra sean mujeres?\\[0,5\\times0,5\\times0,5=0,125\\]\nResulta evidente que lo mismo sucede si queremos calcular la probabilidad de que todos sean hombres.Ahora, bien ¿cuál sería la probabilidad de que sean dos mujeres y un hombre?Hay tres maneras que esto pueda suceder:Tabla 1.1:  Combinaciones posibles.Cada una de estas posibilidades tienen la misma probabilidad y como el orden en el que fueron elegidos es relevante para la muestra, podemos sumar las probabilidades para obtener la probabilidad total:\n\\[(0,5\\times0,5\\times0,5)+(0,5\\times0,5\\times0,5)+(0,5\\times0,5\\times0,5) = 0,375 \\]Lógicamente lo mismo ocurre con el caso de dos hombres y una mujer. Entonces tenemos cuatro posibilidades con distintas probabilidades:Tabla 1.2:  Probabilidades de las combinaciones.Observamos que las probabilidades suman 1, lo cual es matemáticamente inevitable.Está claro que una muestra de tan solo tres personas nunca puede ser representativa de la población, sin embargo vemos que la medida en que son poco representativas varía. Cualquiera de las muestras de 2+1 sería más representativa que las de un solo sexo, y vemos que también son probables.Este ejemplo es extensible muestras más grandes con cálculos similares. Se desarrollará en más detalle en capítulos posteriores, pero para tener un ejemplo un tanto más real imaginemos que hemos decidido realizar una muestra de diez personas de la misma población (que tiene un 50 y 50 de hombres y mujeres).Tabla 1.3:  Probabilidades de las combinaciones de una muestra de diez.Obtendríamos los resultados de la tabla 1.3 y observamos que hay aproximadamente un 0,9 de probabilidad (90%) de obtener una muestra peor que 7-3. También es de sorprenderse que mientras más grande sea la muestra más probable es que sea representativa11.","code":""},{"path":"conceptos-fundamentales.html","id":"estadísticas-descriptivas-e-inferenciales","chapter":"Capítulo 1 Conceptos fundamentales","heading":"1.3 Estadísticas descriptivas e inferenciales","text":"Entre los varios usos de las estadísticas este texto tratará de dos de los más importantes. Uno es el descriptivo que consiste en describir cuantitativamente un conjunto de datos y eventualmente generalizar este análisis una población. Otro es el de inferir propiedades y diferencias entre variables.Vamos desarrollar estas distinciones por medio de un ejemplo12. Supongamos que hemos hecho dos muestras aleatorias de las notas del examen final de dos cursos de la materia Métodos cuantitativos, uno dictado exclusivamente como curso teórico y el otro como curso teórico-práctico.Las notas son: Curso (teórico-práctico):15, 12, 11, 18, 15, 15,9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16,17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16 y 14.Y para el Curso B (teórico):11, 16, 14, 18,6,8,9, 14, 12, 12, 10, 15, 12,9, 13, 16, 17, 12,8,7, 15,5, 14, 13, 13, 12, 11, 13, 11 y 7El examen fue identico para ambos grupos y se podía obtener un máximo de veinte.Antes de sacar conclusiones sobre estos datos deberíamos resumirlos. Podemos construir, por ejemplo, una tabla que muestra la frecuencia de cada nota en cada curso. Esto se llama tabla de frecuencias. También nos gustaría saber cuál es la nota más típica, la nota promedio y cuánto varían las notas respecto éste. Estas son estadísticas descriptivas, y los desarrollaremos en los capítulos dos y tres de este texto.Pero seguramente también quisiéramos saber con qué nivel de confianza podemos generalizar estos datos similares grupos de datos usando métodos similares los mencionados. Nos gustaría saber en qué medida las dos muestras que tenemos son representativas de sus respectivas poblaciones de estudiantes tomando cursos similares. Este tipo de estimaciones se verá en detalle en el capítulo cinco.Además quisiéramos saber si podemos afirmar que alguno de los dos grupos estuvo mejor que el otro en el examen final. Podríamos postular, por ejemplo, que el grupo que recibió el curso teórico-práctico debería sacar mejores notas en promedio que el otro. Para ello hay que construir un test de la hipótesis y someter nuestros datos este test.Tanto la tarea de estimación como el test de hipótesis comprenden la inferencia de relaciones partir de medidas descriptivas y juntos constituyen el área de estadísticas inferenciales.Finalmente, podríamos juntar más datos para determinar si existe en cualquiera de los dos cursos algún sub-grupo cuyas características se relacionan con un resultado específico. Con esta información estaríamos en condiciones de predecir las notas de los estudiantes en futuras cursadas de los cursos en cuestión.","code":""},{"path":"conceptos-fundamentales.html","id":"variables-y-su-clasificación","chapter":"Capítulo 1 Conceptos fundamentales","heading":"1.4 Variables y su clasificación","text":"En estadísticas trabajamos esencialmente con cantidades variables. En estadística definimos variable como: Una característica medida u observada al hacer un experimento u observación. Si, por ejemplo, estamos investigando el clima en Buenos Aires, podemos hacer medidas de temperatura, humedad, dirección e intensidad del viento etcétera.Las variables pueden ser clasificadas de diferentes maneras:","code":""},{"path":"conceptos-fundamentales.html","id":"por-su-relación-con-otras-variables","chapter":"Capítulo 1 Conceptos fundamentales","heading":"Por su relación con otras variables","text":"En la mayoría de investigaciones cuantitativas variamos una o más conjuntos de condiciones y medimos los efectos sobre una o más propiedades que son de nuestro interés. Las condiciones que cambiamos nosotros se denominan variables independientes13 y los cuya respuesta las condiciones cambiantes medimos se llaman variables dependientes.","code":""},{"path":"conceptos-fundamentales.html","id":"por-su-nivel-de-medición","chapter":"Capítulo 1 Conceptos fundamentales","heading":"Por su nivel de medición","text":"Cuando hacemos una medición o observación o «recogemos un dato» debemos fijarnos en su nivel de medición, también llamado escala de medición. Distinguimos cuatro niveles o escalas:","code":""},{"path":"conceptos-fundamentales.html","id":"nivel-nominal","chapter":"Capítulo 1 Conceptos fundamentales","heading":"Nivel nominal","text":"Cuando un dato identifica una etiqueta (o el nombre de un atributo) de un elemento, se considera que la escala de medición es una escala nominal. En esta carecen de sentido el orden de las etiquetas, así como la comparación y las operaciones aritméticas. La única finalidad de este tipo de datos es clasificar las observaciones. Ejemplo:Una variable que indica si el visitante de este post es «hombre» o «mujer».En esta variable se tienen dos etiquetas para clasificar los visitantes. El orden carece de sentido, así como la comparación u operaciones aritméticas.","code":""},{"path":"conceptos-fundamentales.html","id":"nivel-ordinal","chapter":"Capítulo 1 Conceptos fundamentales","heading":"Nivel ordinal","text":"Cuando los datos muestran las propiedades de los datos nominales, pero además tiene sentido el orden (o jerarquía) de estos, se dice que se mide en escala ordinal. Ejemplo:Una variable que mide la calidad del café en la cafetería de la universidad. Le podemos asignar de uno cinco estrellas.En esta variable sigue sin tener sentido las operaciones aritméticas, pero ahora sí tiene sentido el orden. Cuatro estrellas es mejor que dos.","code":""},{"path":"conceptos-fundamentales.html","id":"nivel-de-intervalo","chapter":"Capítulo 1 Conceptos fundamentales","heading":"Nivel de intervalo","text":"En una escala de intervalo, los datos tienen las propiedades de los datos ordinales, pero su vez la separación entre las variables tiene sentido. Este tipo de datos siempre es numérico, y el valor cero indica la ausencia de la propiedad. Por ejemplo: La temperatura (en grados centígrados) medida de una ciudad, puede ser cero sin que tenga sentido decir que «hay temperatura».En este nivel de medición, los número mayores corresponden temperaturas mayores. Es decir, el orden importa, pero la vez la diferencias entre las temperaturas importa. La diferencia entre 10 grados y veinte grados es igual que la diferencia entre 20 y 30. El nivel de medida de intervalo también se conoce como el nivel intervalar.","code":""},{"path":"conceptos-fundamentales.html","id":"nivel-de-razón","chapter":"Capítulo 1 Conceptos fundamentales","heading":"Nivel de razón","text":"En una escala de razón –también llamado de ratio o racional, los datos tienen todas las propiedades de los datos de intervalo, y la proporción entre ellos tiene sentido. Para esto se requiere que el valor cero de la escala indique la ausencia de la propiedad medir. Ejemplos de este tipo de variables son el peso de una persona el tiempo utilizado para una tarea y el salario de una persona. Si una persona gana 100, y otra 10, la primera gana más que la segunda (comparación). También tiene sentido decir que la primera gana 90 más que la segunda (diferencia), o que gana 10 veces más (proporción).","code":""},{"path":"conceptos-fundamentales.html","id":"por-su-precisión","chapter":"Capítulo 1 Conceptos fundamentales","heading":"Por su precisión","text":"Cuando hablamos de precisión en matemáticas y estadísticas nos referimos al numero de decimales que tiene una variable. Esto es distinto de exactitud que significaría la medida en que la medición, o predicción corresponde la realidad. 1,000 (uno coma cero cero cero), tiene más precisión que 1 (uno) si bien miden la misma cantidad. Esto lleva la distinción que hacemos entre variables discretas y continuas. Las discretas por su naturaleza tienen precisión cero (lleva decimales) y las continuas pueden tener la cantidad de decimales que queramos. Para ilustrar la diferencia consideramos dos variables: edad y numero de hijos. En cuanto la edad se puede tener diez años, diez años y medio o si queremos agregar más precisión: 20,45 años. En cambio numero de hijos es una variable discreta. Se puede tener cero, uno o más, pero se puede tener 1,45 hijo.Por su naturaleza vemos que las variables de escala nominal y ordinal son siempre discretas. Las de escala de intervalo y de escala de razón, en cambio pueden ser tanto discretas como continuas.La mayoría de variables de interés en las ciencias duras se miden por escala de razón o de intervalo, mientras las escalas ordinal y nominal son más importantes en ciencias humanas. El nivel de medición de una variable es de suma importancia cuando decidimos qué medidas de tendencia central, variabilidad y dispersión elegimos para nuestro análisis, y qué test de hipótesis son adecuados. Es un error muy común entre investigadores, particularmente en las ciencias sociales, asumir una escala superior lo teóricamente sostenible.","code":""},{"path":"conceptos-fundamentales.html","id":"glosario-1","chapter":"Capítulo 1 Conceptos fundamentales","heading":"1.5 Glosario","text":"Aleatorio/\nAl azar. También son de uso frecuente los anglicismos «random» y «randómica».\nFunción relevante en R: rdunif.\nEquivalente en inglés: «Random».\nHistograma\nVisualización de frecuencia de observaciones de una variable.\nFunción relevante en R: hist.\nEquivalente en inglés: «Histogram».\nMuestra aleatoria\nMuestra en la que todos los elementos de la población tienen igual probabilidad de ser eligidos.\nFunción relevante en R: sample.\nEquivalente en inglés: « Random sampling».\nMuestra cuasialeatoria\nMuestra en la que cada n número de los los elementos de la población van ser eligidos.\nEquivalente en inglés: «Cuasi-Random sampling».\nMuestra estadística\nSubconjunto de una población estadística\nFunción relevante en R: sample.\nEquivalente en inglés: «Sample».\nMuestra estratificada\nMuestra que conserva las proporciones conocidas de la población estadística\nEquivalente en inglés: «Stratified sample».\nMuestreo estadístíco\nEl hecho de generar una muestra.\nFunción relevante en R: sample.\nEquivalente en inglés: «Sampling».\nNivel de Medida\nUno de los cuatro niveles jerárquicamente definidos: Nominal, ordinal, intervalar y racional\nEquivalente en inglés: «Level measurement».\nParámetro estadístico\nNumero que resume una characteristica de la población estadística.\nEquivalente en inglés: «Parameter».\nPoblación estadística\nEl conjunto de individuos, objetos o fenómenos de los cuales se desea estudiar una o varias características.\nEquivalente en inglés: «Population».\nVariable\nCharacteristica que puede tener diferentes valores.\nEquivalente en inglés: «Variable».\n","code":""},{"path":"distribuciones-de-frecuencias.html","id":"distribuciones-de-frecuencias","chapter":"Capítulo 2 Distribuciones de frecuencias","heading":"Capítulo 2 Distribuciones de frecuencias","text":"En este capítulo desarrollaremos el concepto de distribución estadística. Seguiremos desarrollando el ejemplo de notas de los exámenes finales de dos grupos de estudiantes e introduciremos otros ejemplos. Exploraremos el concepto de frecuencia de observaciones, cómo visualizarlos y estimar sus algunas de sus características.","code":""},{"path":"distribuciones-de-frecuencias.html","id":"explorando-los-datos","chapter":"Capítulo 2 Distribuciones de frecuencias","heading":"2.1 Explorando los datos","text":"Recordemos las muestras de exámenes finales que vimos en el capitulo anterior.Grupo (teórico-práctico):15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16 y 14Grupo B (teórico):11, 16, 14, 18, 6, 8, 9, 14, 12, 12, 10, 15, 12, 9, 13, 16, 17, 12, 8, 7, 15, 5, 14, 13, 13, 12, 11, 13, 11 y 7A simple vista es tan fácil darse cuenta «qué pasa» con estos datos. Podemos por lo pronto darnos cuenta de que el grupo B tiene más notas de un solo dígito, pero más allá resulta obvio cómo les fue en los distintos grupos.","code":""},{"path":"distribuciones-de-frecuencias.html","id":"tablas-de-frecuencias","chapter":"Capítulo 2 Distribuciones de frecuencias","heading":"2.2 Tablas de frecuencias","text":"Para darnos cuenta mejor de las estructuras que estamos analizando podemos construir una tabla de frecuencias, que en este caso es un resumen de cuántos alumnos sacaron cuál nota de las posibles (sobre veinte).Tabla 2.1: Frecuencia de notas por grupoAhora podemos hacer algunas observaciones adicionales. Se nota que el rango (distancia entre el menor y el mayor valor del conjunto) es más amplio en el grupo B que en el grupo . Posiblemente también nos damos cuenta que el valor más frecuente del grupo (15) es superior al más frecuente del grupo B (12).","code":""},{"path":"distribuciones-de-frecuencias.html","id":"ejemplo-en-r","chapter":"Capítulo 2 Distribuciones de frecuencias","heading":"Ejemplo en R","text":"Si bien es posible hacer una tabla de frecuencias mano, simplemente contando las observaciones en cada categoría y anotando el resultado en orden, también tenemos funciones en R para el propósito.En este ejemplo estamos usando dos funciones, una dentro de otra. La función c, le pide R que arme un cconjunto de datos, y los datos que queremos usar van entre paréntesis y separados por coma. Esto, su vez, lo estamos haciendo dentro de la función table que genera una tabla de frecuencias.También es posible darle un nombre los datos usar o «asignarlos una variable», lo cual puede ser útil cuando se quiere reutilizar. Esto se hace de la siguiente manera:Con esto podemos usar x como alias para los datos que le asignamos. Entonces:nos da el mismo resultado.Por lo general se recomienda usar nombres de variables que tengan algún sentido, en lugar de usar genéricos como x, y, z o , b, c. En R las variables pueden tener múltiples caracteres (pero espacios), por lo que podríamos ingresar:y nos daría el resultado deseado:","code":"\ntable(\n  c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14)\n)#> \n#>  9 11 12 13 14 15 16 17 18 19 \n#>  1  2  2  3  4  6  3  4  3  2\nx <- c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14)\ntable(x)#> x\n#>  9 11 12 13 14 15 16 17 18 19 \n#>  1  2  2  3  4  6  3  4  3  2\ngrupo.A <- c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14)\ntable(grupo.A)#> grupo.A\n#>  9 11 12 13 14 15 16 17 18 19 \n#>  1  2  2  3  4  6  3  4  3  2"},{"path":"distribuciones-de-frecuencias.html","id":"histogramas","chapter":"Capítulo 2 Distribuciones de frecuencias","heading":"2.3 Histogramas","text":"Para seguir explorando las tablas que hemos creado en la sección anterior se pueden visualizar con un histograma. El histograma resume los datos dentro de algunos rangos, por ejemplo 8-9, 10-11, 12-13 etcétera, y se cuenta el número de observaciones dentro de cada rango.Para nuestros datos obtenemos:yComparando estos dos diagramas nos damos cuenta de que la estructura de los datos son disimilares. En el grupo las notas se centran alrededor de quince, en cambio para el grupo B la concentración está en el rango diez-catorce, con un pico menor alrededor de siete.","code":""},{"path":"distribuciones-de-frecuencias.html","id":"ejemplo-en-r-histograma","chapter":"Capítulo 2 Distribuciones de frecuencias","heading":"2.3.0.1 Ejemplo en R: Histograma","text":"Hacer un histograma con R es bastante sencillo. Usamos la función hist, de histograma y los datos que queremos visualizar. Si lo asignamos una variable, como lo vimos en la parte de las tablas (con table).La función hist tiene muchas opciones adicionales. Para conocerlas se puede ingresar ?hist (signo de interrogación y «hist») en la consola de R y aparecerá la descripción completa de ellas. Lo mismo es cierto para cualquier función de R. El mismo resultado se obtiene usando la función help(hist).","code":"\ngrupo.A <- c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14)\nhist(grupo.A)"},{"path":"distribuciones-de-frecuencias.html","id":"ejemplo-en-r-histograma-en-ggplot","chapter":"Capítulo 2 Distribuciones de frecuencias","heading":"2.3.0.2 Ejemplo en R: Histograma en ggplot","text":"Usando los paquetes de tidyverse podemos generar un histograma con el packete ggplot2. Se carga por default junto con muchos otros paquetes. diferencia del ejemplo anterior la función espera un data.frame como argumento. Para generar un histograma con los mismos datos debemos entonces proceder con crear una estructura de data.frame primero y luego proceder.Nótese que usamos el operador = dentro de la definición del data.frame. Luego cargamos las funciones de tidyverse y procedemos construir nuestro gráfico.\nvemos que si bien los datos son los mismos las columnas parecen separados. Esto se debe que por defecto el geom_histogram distribuye los datos en 30 columnas, lo cual es demasiado para el caso que tenemos. Podemos arreglar esto agragando otro parametro la función asi:","code":"\nmy_data <- data.frame(\n  grupo.A = c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14)\n)\nlibrary(tidyverse) # Carga todos los paquetes, incluso ggplot2\nggplot(my_data, aes(x=grupo.A)) + \n  geom_histogram()\nggplot(my_data, aes(x=grupo.A)) + \n  geom_histogram(binwidth = 1)"},{"path":"distribuciones-de-frecuencias.html","id":"agregando-un-poco-de-color","chapter":"Capítulo 2 Distribuciones de frecuencias","heading":"2.3.0.2.1 Agregando un poco de color","text":"Podemos también manipular los colores de las columnas con algunos parametros más:El uso de %>% es muy frecuente cuando uno trabaja con el tidyverse.","code":"\nggplot(my_data, aes(x=grupo.A)) + \n  geom_histogram(binwidth = 1, fill=\"white\", color='red')"},{"path":"distribuciones-de-frecuencias.html","id":"polígono-de-frecuencias","chapter":"Capítulo 2 Distribuciones de frecuencias","heading":"2.4 Polígono de frecuencias","text":"Los datos también de pueden visualizar con un polígono de frecuencias. En este tipo de visualización ponemos un punto en la intersección de la nota (eje horizontal) y la frecuencia (eje vertical) y trazamos una linea entre los puntos. Una de las ventajas de este tipo de visualización es que facilita la comparación entre varias distribuciones ya que los podemos desplegar en un mismo diagrama.\nFigura 2.1: Polígono de frecuencias de notas obtenidas por dos grupos de estudiantes\nApreciamos con más precisión los valores más típicos y diferencias entre los dos grupos. También podemos ver que la parte inferior de la escala de notas está sin uso, característica que comparten ambos grupos.","code":""},{"path":"distribuciones-de-frecuencias.html","id":"otro-ejemplo","chapter":"Capítulo 2 Distribuciones de frecuencias","heading":"Otro ejemplo","text":"En este ejemplo vamos considerar un libro de la literatura romántica: «Persuasion» escrito por Jane Austen.1415. Vamos visualizar el número de caracteres por palabra en el texto. Obtenemos:\nFigura 2.2: Polígono de frecuencias del largo de palabras en un texto de Austin\ndifferencia de la distribución de notas, vemos acá que encontramos observaciones lo largo del rango de uno deciseis, con la concentración de valores alrededor de tres. Esto tiene su interpretación bastante intuitiva ya que el uso de palabras cortas, como son artículos, preposiciones y conjunciones abundan en cuanquier texto y las palabras muy largas son de uso menos frecuente. Resulta lógico suponer que encontraríamos un perfil similar en cualquier texto de cierta longitud.","code":""},{"path":"distribuciones-de-frecuencias.html","id":"perfil-de-la-distribución","chapter":"Capítulo 2 Distribuciones de frecuencias","heading":"2.5 Perfil de la distribución","text":"Las distribuciones de notas que vimos en las secciones anteriores tienen relativamente pocos datos, por lo que siempre van parecer algo irregulares. Si tenemos muchos datos, sobre todo si con se escala de medición continua, podemos imaginarnos que en lugar de trazar una linea llegamos trazar más bien una curva entre los puntos. Esto nos permite hacer una abstracción de las distribuciones y hablar de distribuciones teóricas. La más conocida de ellas sin duda es la distribución normal, también llamada de Gauss o gaussiana.\nFigura 2.3: Distribución normal\nVamos desarrollar el tema de la distribución normal con más detalle en el capítulo ??. Por ahora simplemente vamos considerar si los datos de nuestras muestras se asemejan ésta o si tiene otro perfil.","code":""},{"path":"distribuciones-de-frecuencias.html","id":"asimetría-o-sesgo","chapter":"Capítulo 2 Distribuciones de frecuencias","heading":"2.5.1 Asimetría o Sesgo","text":"Cuando una distribución se inclina en una dirección u otra decimos, es decir que es simétrica, se dice que tiene un sesgo o que es asimétrica. Se habla de sesgo negativo y sesgo positivo (también: asimetría positiva/negativa y la izquierda/derecha todos equivalentes). Es positivo o negativo según en qué dirección tiene su cola larga.\nFigura 2.4: Distribuciónes normal y sesgadas\nVemos que nuestras distribuciones de notas corresponden una distribución de sesgo negativo, ya que hay menos notas en la parte inferior de la escala que en la parte superior. En cambio, la distribución de número de characteres en el texto de Austen tiene sesgo positivo.\nNótese también que la si bien la escala vertical de los dos gráficos son de muy diferente magnitud, la máxima frecuencia es veinte mil (20.000) y seis (6) respectivamente, podemos comparar las dos distribuciones.","code":""},{"path":"distribuciones-de-frecuencias.html","id":"glosario-2","chapter":"Capítulo 2 Distribuciones de frecuencias","heading":"2.6 Glosario","text":"Asimetría\nEl hecho de que una distribución sea simétrica.\nEquivalente en inglés: «Skew».\nDistribución normal\nDistribución teórica de una variable. Es simétrica y con forma de campana.\nEquivalente en inglés: «Normal distribution».\nHistograma\nVisualización de frecuencia agrupadas de observaciones de una variable.\nFunción relevante en R: hist.\nEquivalente en inglés: «Histogram».\nPolígono de frecuencias\nVisualización de frecuencias de observaciones de una variable.\nEquivalente en inglés: «Frequency poligon».\nSegso\nEl hecho de que una distribución sea simétrica.\nEquivalente en inglés: «Skew».\nTable de frecuencias\nTabla que resume las frecuencias de las observaciones de una variable.\nFunción relevante en R: table.\nEquivalente en inglés: «Frequency table».\n","code":""},{"path":"centralización-y-dispersión.html","id":"centralización-y-dispersión","chapter":"Capítulo 3 Centralización y dispersión","heading":"Capítulo 3 Centralización y dispersión","text":"En el capítulo 2 vimos que resumir los datos y generar visualizaciones nos permite entender mejor la estructura y algunas propiedades de un conjunto de datos, como son sus vales más frecuentes y rango de observaciones. En este capítulo desarrollaremos algunas medidas cuantitativas más precisas de estas propiedades. Específicamente desarrollaremos medidas de centralización o tendencia central y dispersión.","code":""},{"path":"centralización-y-dispersión.html","id":"centralización","chapter":"Capítulo 3 Centralización y dispersión","heading":"3.1 Centralización","text":"La centralización o tendencia central de un conjunto de datos es uno o un número reducido de valores que representan todo el conjunto.Existen tres medidas de centralicación: la media, la mediana y la moda. continuación las vamos definir y ver cómo se calculan y luego vamos considerar cuándo se debe usar cada una de ellas.","code":""},{"path":"centralización-y-dispersión.html","id":"la-media","chapter":"Capítulo 3 Centralización y dispersión","heading":"3.1.1 La media","text":"La media es seguramente la medida de centralización de uso más frecuente 16. Se conoce también como el promedio y, más técnicamente, la media arithmetica. La media se obtiene por la suma de las observaciones dividido por el número de observaciones. Por ejemplo si queremos sacar el promedio de seis observaciones de una variable: 15, 12, 11, 18, 15 y 15; tenemos:\\[\\begin{equation}\n{{15 + 12 + 11 + 18 + 15 + 15}\\{6}}={86\\over6}=14,33\n\\tag{3.1}\n\\end{equation}\\]En el caso de nuestra muestra de notas para de capítulos anteriores tenemos:\\[\\begin{equation}\n{{ 15 + 12 + 11 + 18 + 15 + 15+ \\\\\n  9 + 19 + 14 + 13 + 11 + 12 + \\\\\n  18 + 15 + 16 + 14 + 16 + 17 + \\\\\n  15 + 17 + 13 + 14 + 13 + 15 + \\\\\n  17 + 19 + 17 + 18 + 16 + 14}\\{30}}={448\\over30}=14.93\n  \\tag{3.2}\n\\end{equation}\\]Ya con el cómputo en (3.2) nos damos cuenta de que si bien es posible hacer estos cálculos mano puede resultar bastante engorroso. Además con tantos números dando vuelta sube la probabilidad de un error de tipeo y con lo cual sacaríamos un resultado incorrecto.Ejemplo 3.1  (Ejemplo en R) :Por suerte es bastante sencillo sacar la media con R. Para los dos ejemplos anteriores tenemos:y","code":"\nx = c(15, 12, 11, 18, 15 , 15)\nmean(x)#> [1] 14.33333\nnotas = c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, \n           15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, \n           17, 18, 16, 14)\nmean(notas)#> [1] 14.93333"},{"path":"centralización-y-dispersión.html","id":"notación-matemática","chapter":"Capítulo 3 Centralización y dispersión","heading":"Notación matemática","text":"En textos de matemática y estadística se usa con frecuencia llaves para significar un conjunto, de modo que los datos del primer conjunto se expresaría así: x = {15, 12, 11, 18, 15 , 15}.Una notación compacta para significar la suma de las observaciones en una variable es \\(\\Sigma\\): la letra griega sigma, en mayúscula.Para significar el número de observaciones de usa N, de número.Así se puede definir la media de manera compacta así:\n\\[\n{\\Sigma{x}}\\{N}\n\\]También se usa una barra vertical sobre el nombre de la variable para significar la media (o promedio aritmético): por ejemplo: \\[\\bar{x} = 14,33\\]Entonces en general tenemos:Definición 3.1  (La media) \\[\n\\bar{x} = {\\Sigma{x}\\{N}}\n\\]que se podría leer: «la media de equis es igual la suma de las observaciones de equis sobre el número de observaciones».","code":""},{"path":"centralización-y-dispersión.html","id":"la-mediana","chapter":"Capítulo 3 Centralización y dispersión","heading":"3.1.2 La mediana","text":"Otra medida de centralización es la mediana (también: valor mediano). Para obtenerla ponemos nuestros datos en orden ascendiente y sacamos el valor que está justo en la mitad. Por ejemplo: si queremos sacar la mediana de {15, 12, 11, 18, 15, 15, 9}, primero los ordenamos:\n{9, 11, 12, 15, 15 ,15, 18}. Vemos que hay siete observaciones con lo cual la mediana es la observación que está en cuarta posición, es decir que la mediana de estos datos es 15. Si el conjunto de datos tiene un número par de observaciones, va haber una observación justo en el medio. En ese caso se toman los dos valores del medio, se los suma y se divide por dos17. Por ejemplo: {8, 8, 9, 11, 12, 15, 15 ,15}. Acá tenemos ocho observaciones (ya ordenados) tomamos los dos valores de la posición cuarta y quinta, los sumamos y dividimos por dos: \\({11+12\\over2}=11,5\\).","code":""},{"path":"centralización-y-dispersión.html","id":"notación-matemática-1","chapter":"Capítulo 3 Centralización y dispersión","heading":"Notación matemática","text":"El valor mediano, o la mediana, se denota en notación matemática con una tilde como la que se usa en la letra ñ en español. Al igual que la barra para la media, se coloca por encima de la variable, así: \\[\\huge{\\tilde{x}}\\].Ejemplo 3.2  (Ejemplo en R) :Al igual que la media podemos sacar la mediana de forma sencilla con R con la función median.y","code":"\nx = c(9, 11, 12, 15, 15 ,15, 18)\nmedian(x)#> [1] 15\nx = c(8, 8, 9, 11, 12, 15, 15 ,15)\nmedian(x)#> [1] 11.5"},{"path":"centralización-y-dispersión.html","id":"la-moda","chapter":"Capítulo 3 Centralización y dispersión","heading":"3.1.3 La moda","text":"La moda es la observación más frecuente del conjunto. Por ejemplo: {9, 11, 12, 15, 15 ,15, 18}. El valor 15 es la moda de estos datos.diferencia de las otras medidas de centralidad la moda necesariamente es un valor único. Si tuviéramos por ejemplo: {2, 4, 5, 7, 7, 7, 9, 11, 12, 15, 15, 15, 18} hay dos valores con la misma frecuencia máxima. Tanto 7 como 15 aparecen tres veces. En este caso hay dos modas y hablamos de una distribución bimodal.Vemos un ejemplo en el gráfico que sigue.","code":""},{"path":"centralización-y-dispersión.html","id":"cuál-usar","chapter":"Capítulo 3 Centralización y dispersión","heading":"3.1.4 ¿Cuál usar?","text":"La selección de una medida de centralización depende de varios factores:La escala de medición de la variable (nominal, ordinal, de intervalo o de razón)La forma de la distribución - si hay sesgo o noPara qué vamos usar la medida.La media debería usarse solo para variables de escala de intervalo o de razón. Si los datos son ordenables, pero sin que se pueda hablar de distancias reales entre los datos la mediana es más apropiada. Y en los casos donde ni esto es posible la moda puede ser la única medida disponible. Por ejemplo: si decimos que Italia es un país católico estamos expresando la moda de la variable nominal «religión», y si decimos que Alemania es un país católico y protestante estamos expresando una distribución bimodal de la misma variable. Podemos observar en el gráfico que en realidad se podría hablar incluso de una distribución trimodal.\nFigura 3.1: Religión en Alemania\nEn cuanto la forma de la distribución se favorece la mediana por sobre la media si la distribución es muy sesgada. Esto ocurre sobre todo si hay valores extremos o atípicos. Por ejemplo si tenemos los datos: {15, 12, 11, 18, 15, 15, 200} está claro que si calculamos la media el valor extremo (200) va influir mucho más que cualquier otra observación. En este caso la media es 40,85 y el mediano 15. El primer valor (40,85) es muy representativo de la muestra ya que corresponde ninguna observación y está lejos de cualquiera de ellas. El mediano, en cambio, puede resultar una mejor medida en este caso.\nFigura 3.2: Medidas de centralización en una distribución con sesgo positivo\nPara darnos cuenta de cuál de las medidas puede ser la más adecuada si tenemos datos por lo menos numéricos podemos sacar las tres medidas y ver qué tanto de asemejan unas otras. Hay que tener en mente que cualiér distribución de datos reales va tener un sesgo, la distribución perfectamente normal solo existe en teoría. Entonces debemos fijarnos si el sesgo que tenemos justifica el uso de una medida en espeficia. Por ejemplo, para nuestros datos de notas de dos grupos tenemos:Grupo \nMedia: 14,93\nMediana: 15\nModa: 15\nMedia: 14,93Mediana: 15Moda: 15Grupo B:\nMedia: 11,76\nMediana: 12\nModa: 12\nMedia: 11,76Mediana: 12Moda: 12Vemos que hay muy poca diferencia entre las tres medidas por lo cual vamos concluir que el sesgo observado es lo suficientemente fuerte como para justificar el uso de otra medida que la media.","code":""},{"path":"centralización-y-dispersión.html","id":"medidas-de-dispersión","chapter":"Capítulo 3 Centralización y dispersión","heading":"3.2 Medidas de dispersión","text":"En la sección anterior desarrollamos varias medidas de centralización y cuál eligir para describir el valor «más típico» de los datos. Cuando calculamos medidas de dispersión estamos contestando la pregunta: ¿cuán típico es este valor?Cuando tratamos con variables nominales, como el ejemplo de religión en Alemania de la sección anterior, lo mejor que podemos hacer el indicar la proporción o porcentaje18, pero si los datos son de alguna escala ya numérica tenemos algunas posibilidades que nos permiten más exactitud.","code":""},{"path":"centralización-y-dispersión.html","id":"rango-o-amplitud","chapter":"Capítulo 3 Centralización y dispersión","heading":"3.2.1 Rango o amplitud","text":"El rango de un conjunto de datos son dos números: el valor mínimo y el valor máximo. Por ejemplo el conjunto de datos {9, 11, 12, 15, 15 ,15, 18} tiene un rango 9 18; y el conjunto {2, 4, 5, 7, 7, 7, 9, 11, 12, 15, 15 ,15, 18} tiene un rango de 2 18.En castellano se usa con alguna frecuencia también el término amplitud como equivalente rango.Ejemplo 3.3  (Ejemplo en R) :Para sacar el rango de un conjunto de datos en R podemos usar la función range. Así:","code":"\nx = c(2, 4, 5, 7, 7, 7, 9, 11, 12, 15, 15 ,15, 18)\nrange(x)#> [1]  2 18"},{"path":"centralización-y-dispersión.html","id":"el-rango-intercuartílico","chapter":"Capítulo 3 Centralización y dispersión","heading":"3.2.2 El rango intercuartílico","text":"Otra medida de dispersión que tenemos disposición es el rango intercuartílico o rango intercuartíl. Para calcularlo dividimos las observaciones en cuatro partes iguales y sacamos los valores de cada corte. Esto nos da cinco valores19, le los cuales el rango intercuartílico es la diferencia entre el segundo y el cuarto. Este sería el rango de las observaciones del 50% de los datos que se encuentran más cerca la mediana del mismo.\nFigura 3.3: Cuartiles y rangos\nEl rango intercuartílico da una idea de la dispersión de los datos y es por su naturaleza menos sensitivo valores extremos.Ejemplo 3.4  (Ejemplo en R) :Para sacar en rango intercuartílico podemos usar la función quantiles. Por defecto divide la distribución en cuartiles.Vemos que en este caso el rango intercuartíl es 7 y 15, que da una amplitúd de 8 ya que \\(15 - 7 = 8\\).","code":"\nx = c(2, 4, 5, 7, 7, 7, 9, 11, 12, 15, 15 ,15, 18)\nquantile(x)#>   0%  25%  50%  75% 100% \n#>    2    7    9   15   18"},{"path":"centralización-y-dispersión.html","id":"la-varianza-y-desviación-estándar","chapter":"Capítulo 3 Centralización y dispersión","heading":"3.2.3 La varianza y desviación estándar","text":"La medida de dispersión más usada en estadística es la desviación estándar, también conocida como desviación típica. Esta medida tiene una relación matemática muy estrecha con la varianza que tiene usos menos frecuentes. Ambas medidas tienen propiedades que los hacen útiles para otras técnicas estadísticas.Para calcular la desviación estándar debemos primero calcular la varianza. Para ello tomamos la diferencia de cada observación de la media. Recordemos que la media se expresa con \\(\\bar{x}\\) (equis con barra). Entonces la diferencia entre una observación de x y la media es \\(x - \\bar{x}\\). Luego los llevamos al cuadrado \\((x - \\bar{x})^2\\) los sumamos y dividimos por el número total de observaciones. Para expresarlo usamos la notación que ya vimos. Entonces \\(\\Sigma\\) es «la suma de» y N es «el total de las observaciones». Juntando todo tenemos:Definición 3.2  (Varianza) \\[\n\\text{varianza} = {{\\Sigma (x - \\bar{x})^2}\\{N}}\n\\]Ahora para sacar la desviación estándar tomamos la raíz cuadrada de la varianza. La desviación estándar de la población se representa por la letra griega \\(\\sigma\\) que es sigma pero en minúscula. Entonces tenemos la definición:Definición 3.3  (Desviación estándar de la población) \\[\n\\sigma = {\\sqrt{{\\Sigma (x - \\bar{x})^2}\\{N}}}\n\\]Si estamos trabajando con una muestra en lugar de la población completa, que es el caso más común cuando trabajamos con estadísticas se usa la letra «s». También se hace un ajuste en el denominador de la fórmula ya que se ha comprobado que sin el ajuste la medida puede resultar sesgada si la muestra tiene pocas observaciones. La formula para una muestra es:Definición 3.4  (Desviación estándar de la muestra) \\[\ns = {\\sqrt{{\\Sigma (x - \\bar{x})^2}\\{N-1}}}\n\\]Finalmente. Ya que s y \\(\\sigma\\) son la raíz cuadrada de la varianza, esta también se denomina por las mismas letras, pero llevado al cuadrado: \\(s^2\\) y \\(\\sigma^2\\)Puede parecer enredado llevar todo al cuadrado para luego volver sacar la raíz cuadrada. La razón es que si se resta todas las obvervaciones de la media, gran parte de estas diferencias van ser negativas. Sabemos que un número negativo llevado al cuadrado se vuelve positivo igual que un número positivo, entonces esta parte del procedimiento sirve para que todos los valores que sumamos tengan el mismo signo positivo.Ejemplo 3.5  (Ejemplo en R) :Por suerte es sencillo sacar tanto la varianza como la desviación estándar en R. Usamos las funciones var y sd20.Hay varios motivos más bien técnicos por los que se prefiere la desviación estándar por sobre la varianza. Sin embargo tiene también algunas ventajas bastante práctica e incluso intuitivas. Una de las más importantes es que la dispersión se expresa en la misma unidad que los datos. Para profundizar esto vemos un ejemplo. Los salarios de una PYME son: $14.000, $14.000, $14.000, $16.000, $17.000, $18.000, $26.000 y $35.000. La media de estos es 19,250, y la desviación estándar es: 7,497. La interpretación de la desviación estándar en este caso es que los salarios en promedio tiene una diferencia de $7,497 (por arriba o abajo) del salario medio de $19,250.","code":"\nx = c(2, 4, 5, 7, 7, 7, 9, 11, 12, 15, 15 ,15, 18)\nvar(x)#> [1] 24.69231\nsd(x)#> [1] 4.969136"},{"path":"centralización-y-dispersión.html","id":"visualizar-la-dispersión","chapter":"Capítulo 3 Centralización y dispersión","heading":"3.2.4 Visualizar la dispersión","text":"Puede resultar útil visualizar la dispersión de un conjunto de datos. Esto se logra con un diagrama de caja (box-plot). Vemos un ejemplo de ello en la figura 3.4.\nFigura 3.4: Ejemplo de box-plot\n\nFigura 3.5: Ejemplo de box-plot con explicaciones\nEjemplo 3.6  (Crear boxplot en R) :La función boxplot nos permite generar un boxplot en R.","code":"\nnotas = c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, \n           15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, \n           17, 18, 16, 14)\nboxplot(notas)"},{"path":"centralización-y-dispersión.html","id":"glosario-3","chapter":"Capítulo 3 Centralización y dispersión","heading":"3.3 Glosario","text":"Amplitud\nLa diferencia entre la mínima y la máxima de una variable. También se llama rango\nFunción relevante en R: range.\nEquivalente en inglés: «Range».\nCentralización\nEl hecho de que una variable puede describirse por uno o más valores. También se llama tendiencia central.\nEquivalente en inglés: «Central tendency».\nDesviación estándar (de la muestra).\nMedia de la diferencia entre la media y todas las observaciones de la muestra.\nFórmula: \\(s = {{\\sqrt{ \\Sigma (x - \\bar{x})^2}\\{N}} }\\)\nFunción relevante en R: sd.\nEquivalente en inglés: «Standard deviation».\nDesviación estándar (de la población).\nMedia de la diferencia entre la media y todas las observaciones de la población.\nFórmula: \\(\\sigma = {{\\sqrt{ \\Sigma (x - \\bar{x})^2}\\{N}} }\\)\nFunción relevante en R: sd.\nEquivalente en inglés: «Standard deviation (population)».\nDesviación típica\nVer desviación estándar.\nEquivalente en inglés: «Standard deviation».\nMedia\nLa suma de las observaciónes de una variable dividido por el número de las observaciones. También se conoce como la media aritmética.\nFórmula: \\(\\bar{x} = {\\Sigma{x}\\{N}}\\)\nFunción relevante en R: mean.\nEquivalente en inglés: «Mean».\nMediana\nEl la observación de una variable que está justo en el medio cuando los valores están ordenados.\nFunción relevante en R: median.\nEquivalente en inglés: «Median».\nModa\nEl valor más frecuente de la observaciones de una variable.\nEquivalente en inglés: «Mode».\nRango\nLa diferencia entre la mínima y la máxima de una variable. También se llama amplitud\nFunción relevante en R: range.\nEquivalente en inglés: «Range».\nRango intercuartílico\nRango dentro del cual se encuentras en 50% más centralizado de las variables.\nFunción relevante en R: quantile.\nEquivalente en inglés: «Interquartile range (IQR)».\nVarianza\nMedia de la diferencia cuadrada entre la media y todas las observaciones.\nFórmula: \\(\\sigma^2 = {{\\Sigma (x - \\bar{x})^2}\\{N}}\\)\nFunción relevante en R: var.\nEquivalente en inglés: «Variance».\n","code":""},{"path":"la-distribución-normal.html","id":"la-distribución-normal","chapter":"Capítulo 4 La distribución normal","heading":"Capítulo 4 La distribución normal","text":"En el capítulo 2 tocamos brevemente la llamada distribución normal. En este capítulo vamos desarrollar con más detalle esta distribución, fundamental para muchas técnicas estadísticas y cuantitativas.","code":""},{"path":"la-distribución-normal.html","id":"importancia-de-la-distribución-normal","chapter":"Capítulo 4 La distribución normal","heading":"4.1 Importancia de la distribución normal","text":"Como vimos en la sección ??, si tenemos muchos datos y construimos un polígono de frecuencias, es posible trazar una curva entre los puntos de la distribución. También mencionamos que la llamada distribución normal es de particular interés para trabajo estadístico y cuantitativo. Hay varios razones de ello:Muchos fenómenos que podemos medir tanto en las ciencias exactas como las sociales de asemejan en su frecuencia esta distribución.La distribución normal tiene ciertas propiedades matemáticas que nos permiten predecir qué proporción de la población (estadística) caerá dentro de cierto rango si la variable tiene distribución normal.Varios tests de significanza de diferencia entre conjuntos de datos presumen que los datos del conjunto tiene una distribución normal.","code":""},{"path":"la-distribución-normal.html","id":"propiedades-de-la-curva-normal","chapter":"Capítulo 4 La distribución normal","heading":"4.2 Propiedades de la curva normal","text":"Como ya vimos, la curva normal tiene forma de campana y es simétrica. Por ende, las tres medidas de centralización la media, la mediana y la moda coinciden en el punto superior de la curva, como lo podemos apreciar en la figura 4.1.\nFigura 4.1: Curva normal\nCiertas propiedades importantes de esta curva se relacionan con la manera en que el área debajo de la curva de puede seccionar con lineas verticales con origen en distintos puntos del eje horizontal. Para explorar estas vamos considerar algunos histogramas, el tipo de visualización que vimos en la sección 2.3. El alto de cada barra es proporcional la frecuencia de observaciones y como el ancho de las barras es el mismo en todos los casos el área de cada barra también es proporcional la frecuencia de observaciones. El ancho puede representar una sola unidad, o varias si agrupamos, por ejemplo por rango etario como lo vemos en la figura 4.2, en el que hemos sacado una muestra aleatoria de mil observaciones de un test de matemáticas nivel nacional. Los hemos agrupado por rangos de diez, es decir de 0 10, de 10 20 y así sucesivamente. Hemos sobrepuesto una curva normal teórica para apreciar hasta qué punto se asemeja la distribución observada la teórica.\nFigura 4.2: Muestra de notas de un test de matemática (N=1000)\nAhora, bien, si en lugar de agrupar las notas en grupos de diez21 los podemos también agregar en grupos de cinco. Entonces obtenemos un histograma como el de la figura 4.3.\nFigura 4.3: Muestra de notas de un test de matemática (N=1000)\nPodemos seguir achicando el ancho de las barras, y vemos que si bien el histograma es puntudo mientras menos anchas son las barras más se aproxima la curva. En la figura 4.4 hemos achicado las barras para que cada una represente tan solo un valor entero, es decir tan solo una de las cien notas posibles. Se entiende que es posible seguir con más precisión si, por ejemplo, el examen fue calificado con la posibilidad de asignar notas con decimales.\nFigura 4.4: Muestra de notas de un test de matemática (N=1000)\nLa curva normal de define por dos propiedades: La media y la desviación estándar. Si conocemos estos dos valores es posible construir la curva aplicando una fórmula 22 un tanto compleja y con poca importancia fuera del ámbito plenamente teórico.De más importancia son algunas propiedades que tiene la curva. Si graficamos la curva normal y expresamos los valores en el eje horizontal en desviaciones estándares (también se dice «sigmas» por su letra griega \\(\\sigma\\)), el área que está de cada lado de la linea es constante y conocido. Si trazamos una linea justo en el medio (\\(\\sigma=0\\)), sabemos que un 50% de las observaciones están la derecha y la izquierda de esa linea. Lo mismo aplica una distribución expresado en un histograma. En la figura 4.5 vemos cuales son los cortes para desviaciones estándares de menos 3 3.\nFigura 4.5: Área debajo de la curva normal\nEsta propiedad es de bastante utilidad y se puede aprovechar de varias maneras. Si tenemos una muestra de datos cuya distribución presumimos normal (en la sección 7.2 vamos desarrollar cómo lo podemos determinar) ya sabemos que más o menos el 68% de las observaciones va estar dentro de ± una desviación estándar de la media y más del 95% se encontrará dentro de dos desviaciones. Por último el 99% de las observaciones de encuentran dentro de tres desviaciones estándares de la media. veces se refiere esta propiedad como la regla empírica o la regla de de 68-95-99,7.","code":""},{"path":"la-distribución-normal.html","id":"variables-normalizadas","chapter":"Capítulo 4 La distribución normal","heading":"Variables normalizadas","text":"En textos de estadística frecuentemente se habla de variable normalizada, también se conoce como unidad tipificada, variable centrada reducida o variable estandarizada. Normalizar una variable es simplemente expresar su magnitud en unidades de desviación estándar. Para lograr ello tomamos la variable, restamos la media y dividimos por la desviación estándar. En literatura en inglés es de uso frecuente el término «z-score», por lo que su definición formal (véase 4.1) lleva esta letra.Definición 4.1  (Variable normalizada) La variable normalizada z de un conjunto de datos X se obtiene por la fórmula siguiente:\\[\n  z = {x-\\bar{x}\\{\\sigma}}\n\\]\ndonde:z: la variable normalizadax: una observación de X\\(\\bar{x}\\): la media de las observaciones\\(\\sigma\\) o s: la desviación estándar de la población o muestra respectivamente.Es importante entender que normalizar una variable cambia su valor, solo su unidad de cuenta: El lo mismo comprar medio kilo de queso que comprar quinientos gramos.Normalizar las variables nos permite comparar su distribución independientemente de su unidad de cuenta y amplitud, también nos permite sacar conclusiones sobre probabilidades y proporciones. Vamos desarrollar esta idea por medio de un ejemplo.\n::: {.example #estatura-mujeres-argentinas name=“Analizando datos del ministerio de salud”}\n:\n:::En el 2007 el Ministerio de Salud de Argentina realizó un estudio23 que entre otras recopiló datos sobre la estatura de las argentinas entre 19 y 49 años. La media fue de 161,01 centímetros con una desviación estándar de 6,99. Con estos datos podemos construir nuestra curva.\nFigura 4.6: Estatura de argentinas entre 19 y 49 años\nAhora, sabiendo que esta variable tiene una distribución normal podemos saber que casi el 70% de las argentinas miden entre 154,04 y 168 centímetros. También podemos encontrar respuesta una pregunta como: ¿qué proporción de la población femenina mide más que 175 centímetros? Para ello tenemos que normalizar el dato así:\\[\nz = {175 - 161,01\\{6.99}} = {13,99\\{6.99}} = 2,001\n\\]Con este número podemos volver la figura 4.5 y fijarnos que con por arriba de 2 desviaciones estándar (o 2\\(\\sigma\\)) está el 2,2% de la población. Es el área indicado en rojo en la figura 4.7.\nFigura 4.7: Proporción de argentinas que miden más de 175 centímetros\nEn este caso tuvimos un poco se suerte ya que la variable normalizada resultó un número redondo que era fácil encontrar en la figura 4.5. Ahora digamos que queremos conocer la proporción de la población que mide menos de 150 centímetros, ¿cómo hacemos? Primero normalizamos:\\[\nz = {150 - 161,01\\{6.99}} = {11,01\\{6.99}} = -1,575\n\\]Con este número podemos sacar la proporción por ejemplo calculando el área debajo del segmento de la curva con cálculos integrales, lo podemos buscar en una tabla de probabilidades o podemos recurrir la función pnorm (p: probabilidad, norm: normal)de R así:entonces el 5,76% de la población de argentinas entre 19 y 49 años miden menos de un metro con cincuenta.También podemos expresar esto en términos de probabilidades: Si medimos una mujer argentina de entre 19 y 49 años seleccionada aleatoriamente de la población, la probabilidad de que mida menos de 150 centímetros es de 5,76% (p=0,0576).","code":"\npnorm(-1.575)#> [1] 0.05762822"},{"path":"la-distribución-normal.html","id":"evaluar-la-normalidad","chapter":"Capítulo 4 La distribución normal","heading":"4.3 Evaluar la normalidad","text":"Hemos visto que el hecho de que una variable tenga una distribución normal nos resulta muy útil para extraer información sobre sus propiedades. También nos permite realizar algunos tests estadísticos que veremos en capítulos posteriores.En la sección ?? decidimos usar la media como medida de centralización porque las tres medidas disponibles –media, mediana y moda– se aproximaban unas otras. Si queremos saber si una variable se aproxima la curva normal podemos generar un histograma y sobreponer una curva normal. Así podemos sacar alguna conclusión inspeccionando el gráfico.También podemos valernos del conocimiento de la proporción de observaciones que deben estar dentro de la primera y segunda desviación estándar y verificar si nuestros datos se conforman con estas predicciones.Ejemplo 4.1  :Si tomamos nuestros datos de las notas de nuestros dos cursos que vimos en la sección ?? y que fuimos desarrollando lo largo de los capítulos anteriores podemos realizar este análisis.Grupo : {15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14}Grupo B: {11, 16, 14, 18, 6, 8, 9, 14, 12, 12, 10, 15, 12, 9, 13, 16, 17, 12, 8, 7, 15, 5, 14, 13, 13, 12, 11, 13, 11, 7}Grupo :\nMedia: 14.93\nDesviación estándar: 2,49\nEntre \\(\\pm{1}\\) desviación: 66%\nEntre \\(\\pm{2}\\) desviaciones: 96%\nMedia: 14.93Desviación estándar: 2,49Entre \\(\\pm{1}\\) desviación: 66%Entre \\(\\pm{2}\\) desviaciones: 96%Grupo B:\nMedia: 11,76\nDesviación estándar: 3,31\nEntre \\(\\pm{1}\\) desviación: 66%\nEntre \\(\\pm{2}\\) desviaciones: 96%\nMedia: 11,76Desviación estándar: 3,31Entre \\(\\pm{1}\\) desviación: 66%Entre \\(\\pm{2}\\) desviaciones: 96%Observamos que nuestras notas carecen en cierta medida de valores extremos, sin embargo la muestra es relativamente pequeña con lo cual nos conformamos con estos resultados y consideramos normales las distribuciones.Ejemplo 4.2  (Ejemplo en R) :Si queremos hacer estos cálculos mano los podemos hacer también en R, así:Existen también tests más formales de normalidad que desarrollaremos en capítulos posteriores.","code":"\ngrupo.A = c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14)\n\nmedia= mean(grupo.A)\ndesviacion = sd(grupo.A)\nN = 30\nsum( \n    grupo.A <  media + desviacion \n    &\n    grupo.A > media - desviacion  \n)/N#> [1] 0.6666667\nsum( \n    grupo.A <  media + desviacion * 2\n    &\n    grupo.A > media - desviacion  * 2\n)/N#> [1] 0.9666667"},{"path":"la-distribución-normal.html","id":"glosario-4","chapter":"Capítulo 4 La distribución normal","heading":"4.4 Glosario","text":"Regla empírica\nCuando la distribución es normal el 68% de las observaciones se encuentran entre \\(\\pm\\) una desviación estándar de la media, el 95% entre dos desviaciones estándar y el 99,7% entre tres.\nEquivalente en inglés: «Empirical rule».\nVariable normalizada\nVariable expresada en desviaciones estándar\nFórmula: \\(z = {x-\\bar{x}\\{\\sigma}}\\) o \\(z = {x-\\bar{x}\\{s}}\\)\nFunción relevante en R: scale.\nEquivalente en inglés: «z-score».\n","code":""},{"path":"estimación-de-parámetros.html","id":"estimación-de-parámetros","chapter":"Capítulo 5 Estimación de parámetros","heading":"Capítulo 5 Estimación de parámetros","text":"Hemos visto que si trabajamos con poblaciones que son potencialmente infinitas o muy grandes usamos muestras para nuestro trabajo cuantitativo. Las medidas que calculamos en base estas muestras son estimativos de los parámetros de la población. Si tenemos una muestra de estatura de argentinas entre 19 y 49 años de edad, como la que vimos en el ejemplo ??, sabemos con certeza cuál es la media de la población. La estimamos en base una muestra. Con ello podemos afirmar que la media es la misma para la población, de hecho ignoramos cuál es la media de la población. Lo que sí podemos calcular un intervalo de valores dentro de los cuales tenemos cierta confianza de que nuestro valor estimativo sea correcto para la población.En este capítulo desarrollaremos las técnicas que se utilizan para arribar estos intervalos de confianza y calcular un margen de error.","code":""},{"path":"estimación-de-parámetros.html","id":"distribución-muestral","chapter":"Capítulo 5 Estimación de parámetros","heading":"5.1 Distribución muestral","text":"Si suponemos que la estatura promedio de las argentinas entre 19 y 49 años es de 161 centímetros con una desviación estándar de 6,99, estos serían los parámetros de la población. Si sacamos cinco muestras aleatorias de veinte observaciones de esta población van arrojar resultados distintos estos valores. Algunas muestras van tener una media por arriba de la media real y otras van tener una media por debajo.Ejemplo 5.1  (Distribucion de muestras) :\nFigura 5.1: Cinco Muestras de 20 obseraciones\nComo lo podemos observar en la figura 5.1 la distribución de las muestras es simétrica y normal. La media de nuestras muestras es 161,42; ligeramente por arriba de la media real, y la desviación estándar es de 6,17; más de medio centímetro por debajo de la desviación estándar de la población. La distribución muestral tiene algunas propiedades que son útiles para nuestro trabajo estadístico:Se aproxima una distribución normal. Esto se conoce como el teorema del límite central.La media de la distribución es igual (o casi igual) la media de la población.La dispersión es menor la de la población general.El número (3) de la lista tiene su lógica ya que en una muestra aleatoria un valor frecuente tiene más probabilidad de ser seleccionada que un valor extremo. La diferencia entre curva normal de la población y la curva de la distribución muestral está ilustrada en la figura 5.2.\nFigura 5.2: Distribución de la población y la muestra\n","code":""},{"path":"estimación-de-parámetros.html","id":"el-error-estándar-y-su-interpretación","chapter":"Capítulo 5 Estimación de parámetros","heading":"5.2 El error estándar y su interpretación","text":"La variabilidad de las medias muestrales se puede medir por su desviación estándar. Esta medida se conoce como el error estándar y tiende disminuir cuando aumenta el tamaño de la(s) muestra(s).Definición 5.1  (Error estándar) \\[\nSE = {\\sigma\\{\\sqrt{N}}}\n\\]si conocemos la desviación estándar de la población, y\\[\nSE = {s\\{\\sqrt{N}}}\n\\]si usamos la desviación estándar de la muestra.donde:SE: el error estándar (por sus siglas en inglés «Standard Error»)\\(\\sigma\\): la desviación estándar de la poblacións: desviación estándar de la muestraN: número de observaciones de la muestraNótese que el error estándar disminuye en relación directamente proporcional con el tamaño de la muestra. Ya que tomamos la raíz cuadrada de N, es necesario cuadruplicar el tamaño de la muestra para reducir el error estándar la mitad.","code":""},{"path":"estimación-de-parámetros.html","id":"intervalos-de-confianza","chapter":"Capítulo 5 Estimación de parámetros","heading":"5.2.1 Intervalos de confianza","text":"Volvemos nuestro ejemplo de la estatura de las argentinas entre 19 y 49 en 2007. Si sacamos una muestra aleatoria de esta población de tan solo 30 observaciones. de manera que:Muestra = {163, 171, 171, 167, 164, 160, 153, 176, 162, 171, 166, 164, 169, 160, 151, 155, 156, 147, 162, 170, 164, 160, 158, 159, 157, 159, 156, 162, 159, 174}podemos calcular la media y la desviación estándar de la muestra. Obtenemos \\(\\bar{x}=160,94\\) y s = 6,89 respectivamente. Con esto podemos calcular el error estándar:\\[\nSE = {s\\{\\sqrt{N}}} = {6,89\\{\\sqrt{30}}} = {s\\{5,477}} = 1,257\n\\]\nAhora podemos estimar que la media de la población es de 160,94 \\(\\pm\\) 1,257. Hemos reportado muestra estimación con un margen de error. Pero ¿cómo se interpreta este número?Sea \\(\\mu\\) la media real –por convención se usa la letra griega \\(\\mu\\) que corresponde m para la media de la población. La desviación de la media de la muestra entonces es de \\(161,94 - \\mu\\). Podemos normalizar esta variable por división con la desviación estándar de la muestra:\n\\[\nz = {161,94 - \\mu\\over1,257}\n\\]Recordemos que se usa z para la variable normalizada. Para muestras desde más o menos 30 observaciones, z tiene una distribución normal, con lo cual nos podemos valer de la regla empírica y mirar la figura 4.5 para darnos cuenta qué tan probable es que nuestro valor caiga dentro o fuera de los rangos esperados. El error estándar es, entonces, el rango de valores que caen dentro de una desviación estándar en la curva normal del error, es decir que hay un 68% de probabilidad de que el valor real esté dentro del rango reportado.Podemos valernos de esta información para calcular rangos que nos den más confianza en nuestra estimación. La regla empírica dice que el 95% de las observaciones se encuentran entre dos desviaciones estándar de la media. Si se expresa con un poco más de precisión es de 1,96. Este número mágico o valor crítico de usa mucho en los textos con análisis cuantitativo ya que se puede demostrar matemáticamente que:\n\\[\n\\text{media de la muestra} \\pm(1,96\\times{SE})\n\\]\nes un estimado de la media de la población con un 95% de confianza.De la misma manera tenemos:\\[\n\\text{media de la muestra} \\pm(2,58\\times{SE})\n\\]que nos da un rango con 99% de confianza.Entonces, para nuestra muestra de argentinas podemos decir que estimamos que la media de la población (\\(\\mu\\)) es:entre 160,94 y 162,20 con un 68% de confianzaentre 159,73 y 164,66 con un 95% de confianzaentre 158,94 y 165,44 con un 99% de confianza","code":""},{"path":"estimación-de-parámetros.html","id":"la-distribución-t","chapter":"Capítulo 5 Estimación de parámetros","heading":"5.3 La distribución t","text":"En la sección anterior vimos que la razón:\\[\nz = {\\bar{x}\\{SE}}\n\\]tiene una distribución normal cuando la muestra tiene un tamaño grande. Cuando la muestra es relativamente pequeña, sin embargo, tiende otra distribución llamada la distribución t y veces distribución t de Student24.El valor de t se calcula de la misma manera que el error estándar, pero debido las características de la distribución los valores críticos son distintos dependiendo de los grados de libertad (que el la mayoría de los casos es igual N-1.)Ejemplo 5.2  (Muestra pequeña) Hacemos una muestra aleatorea de 15 argentinas y medimos su estatura, esta vez con precisión milimetrica y obtenemos:X = {153,26; 158,81; 165,73; 159,85; 160,56; 166,69; 159,85; 148,07; 160,3; 173,02; 154,55; 145,52; 159,98; 158,22; 166,12 }La media es de 159,36 y la desviación estándar de 7,125. Por tanto:\n\\[\n  SE = {s\\{\\sqrt{N}}} = {7,125\\{\\sqrt{15}}} = 1,338\n  \\]El valor crítico de t con 14 grados de libertad (N-1) es \\(\\pm{2,145}\\).\\[\n2,145 \\times{SE} = 2,145 \\times 1,338 = 2,869\n\\]Por tanto, basado en esta muestra más chica podemos estimar que la media de la población es de 159,36 \\(\\pm2,869\\) es decir entre 156,49 y 162,23 centímetros.Del ejemplo 5.2 vemos que si bien logramos estimar la media de la población, el margen de error es más amplio que con una muestra más grande.","code":""},{"path":"estimación-de-parámetros.html","id":"dónde-obtenemos-los-valores-críticos-de-t","chapter":"Capítulo 5 Estimación de parámetros","heading":"¿Dónde obtenemos los valores críticos de t?","text":"Se pueden consultar los valores críticos de la distribución t para distintos grados de libertad en tablas estadísticas, como el del [Apendix ][Apendix : distribución t] o en linea. También se puede sacar con una función en R llamada qt.Ejemplo 3.2  (Ejemplo en R: extraer el valor crítico de t) :La función toma dos argumentos p de qué proporción de la curva en cada lado queremos y df que son los grados de libertad, en este caso 15-1=14. Ponemos el valor de 0.025 porque queremos un 2,5% de arriba y un 2,5% de abajo (=5%).","code":"\nqt(p = 0.025, df = 14)#> [1] -2.144787"},{"path":"estimación-de-parámetros.html","id":"glosario-5","chapter":"Capítulo 5 Estimación de parámetros","heading":"5.4 Glosario","text":"Distribución muestral\nEl resultado de todas las muestras posibles que pueden ser tomadas de una población\nEquivalente en inglés: «Sample distribution».\nDistribución t\nDistribución de probabilidad de una muestra pequeña de una distribución normal.\nFunción relevante en R: qt.\nEquivalente en inglés: «T distribution».\nError estándar\nLa desviación estándar de la distribución muestral.\nFórmula: \\(SE = {\\sigma\\{\\sqrt{N}}}\\) o \\(SE = {s\\{\\sqrt{N}}}\\)\nEquivalente en inglés: «Standard error».\nIntervalo de confianza\nIntervalo dentro del cual estimamos que se encuentre un valor buscado, con cierto porcentaje de confianza.\nEquivalente en inglés: «Confidence Interval».\n","code":""},{"path":"diseño-de-proyectos-y-test-de-hipotesis.html","id":"diseño-de-proyectos-y-test-de-hipotesis","chapter":"Capítulo 6 Diseño de proyectos y test de hipotesis","heading":"Capítulo 6 Diseño de proyectos y test de hipotesis","text":"knowledge can finite, ignorance must necessarily infinite.—Karl Popper","code":""},{"path":"diseño-de-proyectos-y-test-de-hipotesis.html","id":"el-método-científico","chapter":"Capítulo 6 Diseño de proyectos y test de hipotesis","heading":"6.1 El método científico","text":"El filósofo de ciencias Karl Popper es considerado por muchos como el padre de la teoría científica moderna. Sostiene que la ciencia avanza proponiendo teorías e ideas que sean empíricamente refutables. Cuando una teoría es refutada por investigaciones empíricas surgen otras teorías que toman en cuenta las refutaciones de las anteriores y son sometidos al mismo proceso. Este tipo de pensamiento se conoce también como pensamiento «deductivo» y es fundamental para las ciencias empíricas. Deductivo, en este caso es contrario «inductivo» toma como confirmatorias toda observación que sostiene una teoría, sea esta falseable o .Por ejemplo, podemos proponer la teoría de que «en la Ciudad de Buenos Aires nunca cae nieve». Durante la segunda mitad del siglo pasado podíamos corroborar nuestra teoría día tras día al medir el nivel de nieve –que era cero–, pero bastó con una sola nevada, que ocurrió el nueve de julio del 2007, para que nuestra teoría quedara refutada.Para que una teoría sea científica tiene que ser posible demostrar su falsedad empíricamente, es decir tenemos que poder obtener datos, por experimentos u observaciones, capazes de comprobar que la teoría es correcta. Esto se llama el principio de falsabilidad,25 falsación o refutabilidad.Nuestra teoría de la falta de nieve en la ciudad de Buenos Aires es científica, ya la podemos hacer medidas para refutarla. El hecho de que la teoría resultó incorrecta implica que sea científica.Cabe mencionar que existen ciencias: las ciencias «formales» como las matemáticas, la lógica formal etcétera; cuyas teorías dependen de observación empírica ya que se concentran en el estudio abstracto de cantidades, estructuras y cambio.","code":""},{"path":"diseño-de-proyectos-y-test-de-hipotesis.html","id":"el-diseño-de-una-investigación","chapter":"Capítulo 6 Diseño de proyectos y test de hipotesis","heading":"6.2 El diseño de una investigación","text":"","code":""},{"path":"diseño-de-proyectos-y-test-de-hipotesis.html","id":"estudios-experimentales-y-observacionales","chapter":"Capítulo 6 Diseño de proyectos y test de hipotesis","heading":"Estudios experimentales y observacionales","text":"Podemos distinguir entre dos tipos de investigación científica en las ciencias empíricas.\nLos estudios experimentales son estudios donde nosotros manipulamos alguna variable para darnos cuenta qué efecto tiene. En nuestro ejemplo de dos cursos con metodologías distintas, nosotros hemos manipulado la variable metodología. Como hemos mencionado antes en la sección ?? esta es la variable independiente. Los estudios experimentales son muy frecuentes en las ciencias naturales y también se aplican las ciencias humanas.En las ciencias humanas, sin embargo, menudo nos encontramos con datos en los que podemos manipular la variable independiente. En el caso de los datos lingüísticos de la figura 2.2, podemos cambiar el largo de las palabras. Nos tenemos que limitar recoger los datos e intentar discernir alguna relación entre ellas. Igual tenemos una variable dependiente «largo de palabra» y una independiente «frecuencia», solo que controlamos la variable independiente. Este tipo de estudios son observacionales y veces se habla de estudios correlacionales.","code":""},{"path":"diseño-de-proyectos-y-test-de-hipotesis.html","id":"fuentes-de-ruido-en-los-datos","chapter":"Capítulo 6 Diseño de proyectos y test de hipotesis","heading":"Fuentes de ruido en los datos","text":"Cuando estamos haciendo un estudio experimental controlamos solo la variable independiente, sino también podemos diseñar el experimento para minimizar el efecto de otras variables que puedan influir en la variable dependiente. La meta es de minimizar los efectos provinientes de de factores que son relevantes para nuestro estudio fin de poder afirmar con más confianza que los efectos observados en realidad tienen que ver con la variable independiente. En el caso de los dos grupos con metodologías distintos podemos, por ejemplo, asegurarnos de que los dos cursos tengan el mismo profesor, se dicte en horarios similares y que los de estudiantes que reciben el curso tengan características similares en cuanto edad, género, promedio de notas en otras materias etcétera. En el caso de un estudio observacional tenemos este nivel de control, lo que sí podemos hacer es intentar estimar el efecto de interferencia de otras variables y tomarlo en cuenta en nuestros análisis.Incluso en el caso de un estudio experimental, es realista esperar que podemos remover totalmente el efecto de variables irrelevantes. lo que podemos aspirar y debemos intentar, sin embargo, es de remover la mayor cantidad posible de variación sistemática. Si en el caso del las notas de los grupos de estudiantes pusimos todos los hombres en un grupo y todas las mujeres en otro, podemos saber si la diferencia que observamos se debe la diferencia de metodología didáctica o si es una diferencia de género. Por ello es preciso hacer lo posible para que las variables que son irrelevantes para nuestra investigación operen de manera aleatoria en nuestras muestras y, de ser posible, minimizar su efecto. Si operan de manera aleatoria corremos el riesgo de en realidad medir otra variable –género en lugar de metodología– de la que queremos investigar, y si su efecto genera mucha varianza va bajar la confianza que podemos tener el las conclusiones obtenidas.","code":""},{"path":"diseño-de-proyectos-y-test-de-hipotesis.html","id":"tests-de-hipótesis","chapter":"Capítulo 6 Diseño de proyectos y test de hipotesis","heading":"6.3 Tests de hipótesis","text":"Vimos en la sección ?? que podemos estimar los valores de la población en base muestras y que podemos calcular un margen de error y niveles de confianza de estas estimaciones. Podemos valernos de los mismos conceptos para concluir algo sobre la relación entre variables: independiente y dependiente por ejemplo.","code":""},{"path":"diseño-de-proyectos-y-test-de-hipotesis.html","id":"tests-estadísticos-de-significanza","chapter":"Capítulo 6 Diseño de proyectos y test de hipotesis","heading":"6.3.1 Tests estadísticos de significanza","text":"En el caso de nuestros dos grupos de estudiantes (véase: ??) ya vimos que existe una diferencia entre los dos grupos en la media de la nota obtenida. De la figura 2.1 vimos que igual las dos distribuciones de solapan en gran medida. Por tanto podemos afirmar con absoluta certeza que las diferencias observadas son el efecto de la metodología pedagógica aplicada o si son producto de la inherente variabilidad de las muestras.El objetivo de un test estadístico de significanza es determinar si las diferencias observadas el resultado de variación aleatoria o si pueden razonablemente ser atribuidos la variable independiente.","code":""},{"path":"diseño-de-proyectos-y-test-de-hipotesis.html","id":"la-hipótesis-nula-y-alternativa","chapter":"Capítulo 6 Diseño de proyectos y test de hipotesis","heading":"6.3.2 La hipótesis nula y alternativa","text":"Para testear una hipótesis el primer paso es establecer una hipotesis nula. Esta hipótesis afirma que existe el efecto que estamos investigando. Siguiendo los lineamientos del método cientifico, ahora nuestra labor es, través de mediciones u observaciones, refutar esta hipótesis, con lo cual podemos proponer otra, llamada hipótesis alternativa. Una hipótesis nula se formula como una afirmación precisa y empiricamente refutable. En el ejemplo de los dos grupos de estudiantes la hipotesis nula podría expresarse como: «existe diferencia entre la media de notas entre los dos grupos».También debemos formular una o dos hipotesis alternativas. Si formulamos dos, una va afirmar que la media de notas del grupo es superior la del grupo B y la otra que la media de notas del grupo B es mayor la media de notas del grupo . Si usamos una sola hipótesis alternativa esta simplemente plantea que la media notas de los dos grupos es desigual.En notación formal, muy frecuente en textos académicos, se usa la letra H (mayuscula) para significar una hipótesis y tiene subindice «0» o «null». Las hipótesis alternativas reciben subindice numérica (1 y 2 etcétera). En el caso descrito en la sección anterior se podría expresar así:\\(H_0: \\text{hay diferencia entre los grupos}\\)\\(H_1: \\text{Hay diferencia}\\)o, includo más formal:\\(H_0: \\mu_A=\\mu_B\\)\\(H_1: \\mu_A\\neq\\mu_B\\).La estrategia del test de hipótesis acumular evidencia empírica que nos permita refutar la hipótesis nula y intentar fomentar cualquiera de las alternativas directamente. Lo que temenos que hacer es aplicar un test estadístico y calcular la probabilidad de obtener las observaciones que hemos obtenido y si esa probabilidad es muy baja, refutamos \\(H_0\\) favor de una de las alternativas.Es preciso aclarar que nunca podemos estar absolutamente seguros de estar justificados en refutar \\(H_0\\). Siempre existe la posibilidad de que las diferencias observadas de deban la aleatoriedad de las muestras. Lo que sí podemos mostrar es que la probabilidad de que así sea es muy baja.","code":""},{"path":"diseño-de-proyectos-y-test-de-hipotesis.html","id":"niveles-de-significanza","chapter":"Capítulo 6 Diseño de proyectos y test de hipotesis","heading":"6.3.3 Niveles de significanza","text":"Dado que siempre existe la posibilidad de refutar injustificadamente nuestra \\(H_0\\), tenemos que determinar un nivel debajo del cual estamos dispuestos equivocarnos en nuestra afirmación. Este se llama el nivel de significanza, también se describe con la letra griega \\(\\alpha\\) y se llama nivel-\\(\\alpha\\) (nivel alfa). El nivel de significanza está coneptual y matemáticamente ligado con los intervalos de confianza que vimos en el capítulo ??.Si estamos dispuestos rechazar \\(H_0\\) si la probabilidad (p) de hacerlo injustificadamente es igual o menor 0,05, eligimos un nivel de significanza de 0,05, también llamado «nivel de 5%». Su notación menudo se encuentra como: \\(p\\leqslant0,05\\). Este nivel es bastante común en las ciencias humanas, en cambio en otras disciplinas de las ciencias exactas y médicas por ejemplo, veces se opera con \\(p\\leqslant0,01\\) o \\(p\\leqslant0,001\\), lo que significa que se acepta rechazar injustificadamente \\(H_0\\) una vez en cien o una vez en mil respectivamente.Para cada test estadístico y cada nivel de significanza eligido existirá un valor crítico o un rango crítico dentro del cual el valor del cálculo estadístico tiene que encontrarse para que las diferencias observadas en las muestras se consideren estadísticamente significativos. Si el valor del test estadístico cae en ese rango podemos rechazar \\(H_0\\) sobre la base este conjunto específico de observaciones, pero es posible que debamos repetir el estudio con muestras más grandes.","code":""},{"path":"diseño-de-proyectos-y-test-de-hipotesis.html","id":"tipos-de-error","chapter":"Capítulo 6 Diseño de proyectos y test de hipotesis","heading":"6.3.4 Tipos de error","text":"Cuando tomamos la decisión de rechazar o aceptar la hipótesis nula hay dos errores que podemos cometer. Podemos rechazar \\(H_0\\) cuando \\(H_0\\) es correcta, o podemos aceptar \\(H_0\\), cuando es falsa. En el primer caso estamos hablando de un error de tipo , también denominado error de tipo \\(\\alpha\\) o falso positivo. En el segundo caso hablamos de un error de tipo II, error de tipo \\(\\beta\\) (beta) o falso negativo.","code":""},{"path":"diseño-de-proyectos-y-test-de-hipotesis.html","id":"tests-direcionales-y-no-direcionales","chapter":"Capítulo 6 Diseño de proyectos y test de hipotesis","heading":"6.3.5 Tests direcionales y no direcionales","text":"En la sección ?? propusimos una hipótesis nula y su alternativa:Ejemplo 6.1  (Hipotesis nula y una alternativa) \\(H_0: \\mu_A=\\mu_B\\)\\(H_1: \\mu_A\\neq\\mu_B\\).\\(H_1\\) se leería: «la media de es desigual la media de B». Este ejemplo 6.1 es de una predición direcional. Es decir que hemos tomado una posición priori sobre si esperamos que las diferencias que observemos sean positivos o negativos.veces tenemos razones bien fundadas en creer que las diferencias, si las observamos, van darse en una direción u otra. Si por ejemplo estamos midiendo la estaturas de muestras aleatorias de argentinas y argentinos podemos suponer de antemano que los hombres van ser más altos que las mujeres ya que está comprobado que es así en otros países, hay razones biológicas etcétera. En ese caso podríamos formular una predicción direccional, lo cual significa que nuestra hipótesis alternativa es una sola y va en una dirección específica:Ejemplo 6.2  (Hipotesis nula y una alternativa direccional) \\(H_0: \\mu_M=\\mu_F\\)\\(H_1: \\mu_M > \\mu_F\\).La diferencia entre usar un test direccional o direccional influye en los valores críticos de los diferentes tests. Si usamos un test direccional –y está justificado su uso, claro– disminuye el riesgo de cometer un error de tipo II. Está ilustrado en la figura 6.1: para un test -direcional necesitamos un 2,5% en cada extremo de la curva para que sume 5%, en el test direccional «gastamos» todo el lado positivo.\nFigura 6.1: Test direccionales y test direccionales\nEjemplo 5.1  (¿cara o cruz?) :Para desarrollar un poco más el concepto de test de hipótesis vamos imaginarnos que estamos jugando cara o cruz. Si tiramos una moneda hay un 50 y 50 de que salga cruz o cara. Tiramos la moneda y sale cara. La tiramos dos veces y sale dos veces cara. Tres veces – tres caras… y seguimos perdiendo.¿En qué momento empezamos sospechar que la moneda tiene dos caras?Aún sin conocimientos matemáticos o de la teoría de la probabilidad empieza obrar nuestra intuición –basada en nuestra experiencia que por su naturaleza es empírica.Podemos formalizar el problema de la siguiente manera:\\(H_0\\): La moneda es honesta\\(H_1\\): La moneda tiene dos caras.Podemos también calcular las probabilidades de lo que está pasando. La probabilidad de que salga cara es 0,5 (50%) y de que salga cara dos veces es, por tanto, \\(0,5\\times0,5=0,25\\). Podemos calcular las probabilidades de varios casos más:3 caras: \\(0,5\\times0,5\\times0,5=0,125\\)4 caras: \\(0,5\\times0,5\\times0,\\times0,55=0,0625\\)5 caras: \\(0,5\\times0,5\\times0,\\times0,55=0,03125\\),y vemos que si sale cara cinco veces de cinco ya podemos rechazar nuestra \\(H_0\\) con un nivel de significanza de 0,05 (\\(p\\leqslant0,05\\)).","code":""},{"path":"diseño-de-proyectos-y-test-de-hipotesis.html","id":"qué-test-usar","chapter":"Capítulo 6 Diseño de proyectos y test de hipotesis","heading":"6.3.6 ¿Qué test usar?","text":"En los capítulos que siguen vamos desarrollar algunos tests de significanza estadística: el test de z, el test de t de Student, Mann-Whitney U, \\(\\chi^2\\), Wilcoxon y sign-test. La elección de cuál de ellos usar en un caso específico dependerá de:Escala de medición de las variablesLas características de su distribuciónSi las muestras son correlacionadas o ,y los iremos detallando en cada caso.","code":""},{"path":"diseño-de-proyectos-y-test-de-hipotesis.html","id":"procedimiento","chapter":"Capítulo 6 Diseño de proyectos y test de hipotesis","heading":"6.3.7 Procedimiento","text":"El diseño de una investigación cuantitativa se puede resumir en estos cuatro pasos:Formular hipotesis nula y alternativa(s)Decidir el nivel de significanza estadísticaEligir un test estadístico utilizarseAplicar la estadística y decidir si rechazamos \\(H_0\\) o .","code":""},{"path":"diseño-de-proyectos-y-test-de-hipotesis.html","id":"glosario-6","chapter":"Capítulo 6 Diseño de proyectos y test de hipotesis","heading":"6.4 Glosario","text":"Error tipo \nEl error de rechazar \\(H_0\\) cuando esta es correcta.\nEquivalente en inglés: «Type error».\nError tipo II\nEl error de rechazar \\(H_0\\) cuando esta es incorrecta.\nEquivalente en inglés: «Type II error».\nFalsabilidad\nEl hecho de que sea posible refutar una hipótesis, por medio de métodos empíricos.\nEquivalente en inglés: «Falsifiability».\nHipotesis alternativa\nHipótesis la que recurrimos si logramos refutar \\(H_0\\).\nFórmula: \\(H_1\\)\nEquivalente en inglés: «Alternative hypothesis.».\nHipotesis núla\nLa hipótesis que plantea que el patrón que estamos buscando existe. través de un estudio empírico intentaremos refutar esta hipótesis.\nFórmula: \\(H_0\\)\nEquivalente en inglés: «Null hypothesis (\\(H_0\\))».\nMétodo científico\nMetodología basada en la observación, medición y experimentación; y la formulación, análisis y modificación de hipótesis.\nEquivalente en inglés: «Scientific method».\nNivel de significanza\nLa probabilidad de rechazar \\(H_0\\) cuando esta es correcta.\nFórmula: \\(\\alpha\\)\nEquivalente en inglés: «Alpha-level».\nTest direccional\nTest estadístico en la que hypótesis alternativa de expresa en una dirección u otra.\nEquivalente en inglés: «Directional test».\nTest direccional\nTest estadístico en la que hypótesis alternativa de expresa sin dirección especificar dirección.\nEquivalente en inglés: «Non-directional test».\n","code":""},{"path":"pruebas-paramétricas.html","id":"pruebas-paramétricas","chapter":"Capítulo 7 Pruebas paramétricas","heading":"Capítulo 7 Pruebas paramétricas","text":"En este capítulo vamos desarrollar algunos técnicas estadísticos que nos permiten realizar una prueba o un test de diferencias entre medias de dos conjuntos de datos provenientes de muestras independientes o correlacionadas. Los tests que vamos ver se llaman «paramétricos», lo cual quiere decir viene con algunas presunciones acerca de los datos:Los datos son de escala de intervalo o razónLa población de la muestra debe aproximarse una distribución normalLas varianzas de las muestras debe aproximadamente similar26Las pruebas estadísticas son las que nos permiten, algún nivel de significanza, rechazar o aceptar la hipótesis nula (\\(H_0\\)), por lo que son de bastante utilidad en investigaciones cuantitativas.","code":""},{"path":"pruebas-paramétricas.html","id":"prueba-t-de-student-para-muestras-independientes","chapter":"Capítulo 7 Pruebas paramétricas","heading":"7.1 Prueba t de Student para muestras independientes","text":"Supongamos que tenemos dos muestras aleatorias e independientes con medias de \\(\\bar{x_1}\\) y \\(\\bar{x_2}\\) y que queremos saber si estas dos medias son signifacativamente distintas un nivel de \\(p\\leqslant0,05\\). Esto es lo mismo que decir que si afirmamos que hay una diferencia entre las muestras tenemos un 95% de probabilidad de tener razón. Lo que tenemos que calcular, entonces, es la probabilidad de que las dos muestras pueder provenir de la misma distribución y que la diferencia que vemos es por varianza en esa población. En otras palabras: queremos saber si dos muestras con la diferencia observada (\\(\\bar{x_1}-\\bar{x_2}\\)) podrían tener provenir de la misma población.Si sacamos un número significativo de muestras de una misma población la media de estas muestra va tener una diferencia con la media de la población, en algunos casos más altos y en otros más bajos. Usamos este conocimiento para calcular el error estándar:\\[\nSE = {\\sigma\\{\\sqrt{N}}}.\n\\]De la misma manera existe un error estándar de diferencias entre medias (SED por sus siglas en ingles).Definición 7.1  (Error estándar de diferencia entre medias) \\[\nSED = \\sqrt{\\sigma^2_1/N_1 + \\sigma^2_1/N_2}\n\\]donde:\\(\\sigma^2_1\\) y \\(\\sigma^2_2\\): las varianzas de las poblaciones 1 y 2\\(N_1\\) y \\(N_2\\): es el número de observaciones en cada muestra.Al igual que con el error estándar, menudo desconocemos la varianza de la población, por lo cual lo estimamos de la muestra y la formula es la que vemos en la definición 7.2.Definición 7.2  (Error estándar de diferencia entre medias estimado de muestras) \\[\nSED = \\sqrt{s^2_1/N_1 + s^2_1/N_2}\n\\]donde:\\(s^2_1\\) y \\(s^2_2\\): las varianzas de las muestras 1 y 2\\(N_1\\) y \\(N_2\\): es el número de observaciones en cada muestra.Vimos en la sección ?? que para muestras relativamente pequeñas (N<30) la distribución de la muestra tiende la distribución t de Student. Podemos valernos de esto para calcular la probabilidad de que nuestro SED esté en el rango requerido aplicando la formula de la definiciónDefinición 7.3  (Prueba de t) \\[\nt = {{(\\bar{x_1}-\\bar{x_2})}\\{SED}}.\n\\]Si aplicamos la fórmula de la definición 7.3 nos sale un valor que podemos comparar con los valores críticos de la tabla del apendice para determinar si rechazamos \\(H_0\\) o .Ejemplo 7.1  (Prueba t) :Volvemos ahora nuestros datos de notas de dos grupos de estudiantes con diferentes metodologías pedagígicos. Queremos saber con un nivel de significanza de 0,05 si existe diferencia entre la media de los dos grupos. Nuestras hipótesis nula y alternativa son entonces:\\(H_0:\\mu_A=\\mu_B\\),\\(H_1: \\mu_A\\neq\\mu_B\\).Los datos son:Grupo : {15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14} yGrupo B: {11, 16, 14, 18, 6, 8, 9, 14, 12, 12, 10, 15, 12, 9, 13, 16, 17, 12, 8, 7, 15, 5, 14, 13, 13, 12, 11, 13, 11, 7}.La media y desviación estándar:   Grupo :\n       \\(\\bar{x_A} = 14,933\\)\n       \\(s = 2,490\\)\n       \\(N=30\\)   Grupo B:\n      \\(\\bar{x} = 11,77\\)\n      \\(s = 3,308\\)\n      \\(N=30\\).Aplicando la fórmula de la definición 7.2 obtenemos:\\[\nSED = \\sqrt{s^2_1/N_1 + s^2_1/N_2} = \\sqrt{2,490^2/30 + 3,308^2/N_2} = 0,756\n\\]y podemos calcular el valor de t aplicando la fórmula de la definición 7.3\\[\nt = {{\\bar{x_1}-\\bar{x_2}}\\{SED}} = {{14.933-11,766}\\{0,756}}=4,188.\n\\]Si buscamos este valor en el Apendix para 29 grados de libertad (N-1), vemos que debemos rechazar \\(H_0\\) y concluir que existe una diferencia estadísticamente significativa entre las dos muestras. Tenemos razón de creer que el método pedagógico influye en los resultados finales de los estudiantes.Ejemplo 7.2  (Prueba t en R) :Si queremos hacer todos estos cálculos mano podemos hacerlos en R usando la función `t.test. Toma como parámetros las dos muestras que queremos comparar.Vemos que el test nos devuelve además un valor de p más preciso.","code":"\nGrupo.A = c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14)\nGrupo.B = c(11, 16, 14, 18, 6, 8, 9, 14, 12, 12, 10, 15, 12, 9, 13, 16, 17, 12, 8, 7, 15, 5, 14, 13, 13, 12, 11, 13, 11, 7)\nt.test(Grupo.A,Grupo.B)#> \n#>  Welch Two Sample t-test\n#> \n#> data:  Grupo.A and Grupo.B\n#> t = 4.1887, df = 53.88, p-value = 0.0001046\n#> alternative hypothesis: true difference in means is not equal to 0\n#> 95 percent confidence interval:\n#>  1.650905 4.682428\n#> sample estimates:\n#> mean of x mean of y \n#>  14.93333  11.76667"},{"path":"pruebas-paramétricas.html","id":"test-de-normalidad","chapter":"Capítulo 7 Pruebas paramétricas","heading":"7.2 Prueba de Shapiro-Wilks","text":"En la sección 4.3 mencionamos que existen algunas maneras de estimar si una variable tiene una distribución normal o . Nos basamos sobre todo en la forma de los polígonos de frecuencias (2.1). Ahora vamos introducir un test más formal de normalidad.El test de Shapiro-Wilks plantea la hipótesis nula que una muestra proviene de una distribución normal. Eligimos un nivel de significanza, por ejemplo 0,05, y tenemos una hipótesis alternativa que sostiene que la distribución es normal.Tenemos:\\(H_0\\): La distribución es normal\\(H_1\\): La distribución es normal,o más formalmente aún:\\(H_0: X \\sim \\mathcal{N}(\\mu,\\sigma^2)\\)\\(H_1: X \\nsim \\mathcal{N}(\\mu,\\sigma^2)\\).Ahora el test Shapiro-Wilks intenta rechazar la hipotesis nula nuestro nivel de significanza. Para realizar el test usamos la función shapiro.test en R:Ejemplo 7.3  (Test de Shapiro Wilks en R) :Vemos que en ambos casos el valor de probabilidad (p) es muy superios nuestro nivel elegido (0,05), por lo que rechazamos la hipótesis nula.En el caso de los ejemplos 7.1 y 7.2 ya obramos bajo la premisa de que las variables tenían una distribución normal, pero generalmente conviene realizar el test Shapiro-Willks antes de decidir qué prueba estadística vamos usar. Si rechazamos \\(H_0\\), es decir si concluimos que la distribución sea normal, deberíamos usar un test paramétrico.","code":"\nGrupo.A = c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14)\n\nshapiro.test(Grupo.A)#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  Grupo.A\n#> W = 0.97032, p-value = 0.548\nGrupo.B = c(11, 16, 14, 18, 6, 8, 9, 14, 12, 12, 10, 15, 12, 9, 13, 16, 17, 12, 8, 7, 15, 5, 14, 13, 13, 12, 11, 13, 11, 7)\n\n\nshapiro.test(Grupo.B)#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  Grupo.B\n#> W = 0.97636, p-value = 0.7227"},{"path":"pruebas-paramétricas.html","id":"prueba-de-fisher","chapter":"Capítulo 7 Pruebas paramétricas","heading":"7.3 Prueba de Fisher","text":"Al inicio del capítulo también vimos que uno de los requisitos para que una prueba estadística paramétrica sea válida es que las varianzas sean de similar magnitud. Para ello también existe un test, el test de Fisher27 que plantea las hipótesis:\\(H_0: \\sigma^2_1 = \\sigma^2_2\\),\\(H_1: \\sigma^2_1 \\neq \\sigma^2_2\\)Sin entrar en mucho detalle teórico, en R hay una función var.test para este propósito. La función toma dos argumentos: los dos conjuntos de datos que queremos comparar.Ejemplo 7.4  (Realizar la prueba de Fisher en R) :Vemos que el valor de probabilidad \\(p\\) es mayor nuestro nivel de significanza (\\(p\\leqslant0,05\\)), con lo cual rechazamos \\(H_0\\) y concluimos que las varianzas son relativamente similares.","code":"\nvar.test(Grupo.A, Grupo.B)#> \n#>  F test to compare two variances\n#> \n#> data:  Grupo.A and Grupo.B\n#> F = 0.56675, num df = 29, denom df = 29, p-value =\n#> 0.1321\n#> alternative hypothesis: true ratio of variances is not equal to 1\n#> 95 percent confidence interval:\n#>  0.2697517 1.1907335\n#> sample estimates:\n#> ratio of variances \n#>          0.5667472"},{"path":"pruebas-paramétricas.html","id":"prueba-t-para-muestras-pareadas","chapter":"Capítulo 7 Pruebas paramétricas","heading":"7.4 Prueba t para muestras pareadas","text":"En los ejemplos 7.1 y 7.2 teníamos dos grupos de estudiantes de dos cursos distintos, pero en muchos tenemos observaciones pareadas o datos interdependientes. Esto es muy típico de investigaciones experimentales en los que medimos la variable dependiente antes y después28 de cambiar la variable independiente. Si, por ejemplo, queremos investigar el efecto de la cafeína sobre el pulso sanguineo podríamos obtener una muestra de personas y tomarles el pulso antes y después de hacerles tomar una taza de café.En este sacamos las diferencias entre las dos medidas y comparamos estas diferencias con la distribución teórica. La fórmula está en la definición 7.4.Definición 7.4  (Prueba t para muestras dependientes) \\[\nt = {{\\bar{X}_D}\\{s_D\\{\\sqrt{n}}}}\n\\]donde:\\({\\bar{X}_D}\\): media de las diferencias\\(s_D\\): la desviación estándar de las diferenciasn: número de pares de observaciones.Lo que nos va decir la prueba t en este caso es si la diferencia es significativamente diferente cero: Si la variable independiente tiene efecto entonces debería dar lo mismo medir antes o después. Las hipótesis planteadas son, por tanto:\\(H_0: \\bar{X}_D = 0\\),\\(H_1: \\bar{X}_D \\neq 0\\).Ejemplo 7.5  (Prueba t dependiente) :En este ejemplo29 vamos suponer que tenemos un grupo de veinte estudiantes y queremos investigar el efecto del uso de algún recurso didáctico, por ejemplo un video en YouTube, en su destreza para resolver cierto tipo de problemas matemáticos. Les tomamos un test inicial, pedimos que miren el video y cuando terminen tomamos otro test. Ahora tenemos dos observaciones de cada estudiante. Calculamos la diferencia entre ellos. El resultado de todo esto está resumido en la tabla 7.1.Tabla 7.1: Resultados de dos tests de matemáticasLa media de las diferencias es 2.05 con una desviación estándar de 2,837. Entonces tenemos:\\[\nt = {{\\bar{X}_D}\\{s_D\\{\\sqrt{n}}}} =  {{2,05}\\{2,837\\{\\sqrt{20}}}}=3,231.\n\\]Buscando este valor en la tabla de valores críticos con 19 (N-1) grados de libertad vemos que sí podemos rechazar la hipótesis nula y concluir que hay una diferencia estadísticamente significativa entre los resultados de los dos tests.Ejemplo 7.6  (Ejemplo en R) :Para reproducir en R lo que hicimos en el ejemplo 7.5 tenemos que tener sumo cuidado con el ingreso de los datos. Ya que hay dos observaciones por estudiante lo más conveniente es ponerlos en un data.frame. Vamos incluir los nombres de los estudiantes, si bien son necesarios para el cálculo sirve mantener la referencia para poder verificar el correcto ingreso de los datos con los tests. Vamos ingresar los datos mano aunque en la práctica seguramente se leyera de un archivo externo de R. Usamos la función t.test con un paramertro adiciónal paired=TRUE para avisar que son datos pareados.Vemos que el resultado tiene significanza estadística alta (\\(p\\leqslant0,01\\)). El cálculo de R también nos da un intervalo de confianza al 95%.","code":"\n# Ingresamos los datos\n datos.pre.post = data.frame(\n   Nombre = c('Luis', 'Javier', 'Pedro', 'Soledad', 'Manuel', 'Cecilia', 'Cristina', 'Angel', 'Manuela', 'José', 'Juan', 'Antonio', 'Carmen', 'Carlos ', 'Francisco', 'Miguel', 'Laura', 'Lucía', 'Paula', 'Dolores'),\n   Pre = c(18, 21, 16, 22, 19, 24, 17, 21, 23, 18, 14, 16, 16, 19, 18, 20, 12, 22, 15, 17),\n   Post = c(22, 25, 17, 24, 16, 29, 20, 23, 19, 20, 15, 15, 18, 26, 18, 24, 18, 25, 19, 16)\n )\n\n# Verificamos la homogeneidad de varianzas\nvar.test(datos.pre.post$Pre,datos.pre.post$Post)#> \n#>  F test to compare two variances\n#> \n#> data:  datos.pre.post$Pre and datos.pre.post$Post\n#> F = 0.60329, num df = 19, denom df = 19, p-value =\n#> 0.2795\n#> alternative hypothesis: true ratio of variances is not equal to 1\n#> 95 percent confidence interval:\n#>  0.238790 1.524186\n#> sample estimates:\n#> ratio of variances \n#>          0.6032913\n# Verificamos que los datos tienen distribución normal\nshapiro.test(datos.pre.post$Pre)#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  datos.pre.post$Pre\n#> W = 0.98197, p-value = 0.9569\nshapiro.test(datos.pre.post$Post)#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  datos.pre.post$Post\n#> W = 0.94235, p-value = 0.2654\n# Realizamos prueba t\n\nt.test(datos.pre.post$Post,datos.pre.post$Pre, paired = TRUE)#> \n#>  Paired t-test\n#> \n#> data:  datos.pre.post$Post and datos.pre.post$Pre\n#> t = 3.2313, df = 19, p-value = 0.004395\n#> alternative hypothesis: true difference in means is not equal to 0\n#> 95 percent confidence interval:\n#>  0.7221251 3.3778749\n#> sample estimates:\n#> mean of the differences \n#>                    2.05"},{"path":"pruebas-paramétricas.html","id":"prueba-de-z","chapter":"Capítulo 7 Pruebas paramétricas","heading":"7.5 Prueba de z","text":"Existe también una prueba, llamada de z, que se puede usar para muestras más grandes. Se basa en el hecho de que cuando las muestras son más grandes tienden una distribución normal y una distribución t. Aparte de eso su concepto y mecánica es similar la de la prueba t. Puede aplicarse cuando las muestras tienen más de 30 (N>30) observaciones y la principal diferencia de que es capaz de detectar diferencias más pequeñas en los datos lo que reduce el riesgo de un error tipo II.","code":""},{"path":"pruebas-paramétricas.html","id":"resumen-de-procedimiento","chapter":"Capítulo 7 Pruebas paramétricas","heading":"7.6 Resumen de procedimiento","text":"La figura 7.1 despliega un diagrama de flujo para eligir un test estadístico inferencial.\nFigura 7.1: Diagrama de flujo para selección de estadística inferencial\n","code":""},{"path":"pruebas-paramétricas.html","id":"glosario-7","chapter":"Capítulo 7 Pruebas paramétricas","heading":"7.7 Glosario","text":"Error estándar de diferencias entre medias\nEl error estándar calculado sobre la distribución de diferencias entre dos muestras.\nFórmula: \\(SED = \\sqrt{\\sigma^2_1/N_1 + \\sigma^2_1/N_2}\\)\nEquivalente en inglés: «Standar error differences (SED)».\nPrueba de Fisher\nPrueba estadística que nos permite estimar si la varianza de dos muestras en similar.\nEquivalente en inglés: «Fisher test».\nPrueba de Shapiro-Wilks\nPrueba estadística que nos permite estimar en qué medida una muestra proviene de una distribución normal.\nEquivalente en inglés: «Shapiro-Wilks Test».\nPrueba de z\nPrueba estadística que nos permite estimar si dos muestras grandes (N>30 para ambas) provienen de poblaciones diferentes.\nEquivalente en inglés: «z-test».\nPrueba t para muestras independientes\nTest estadístico que nos indica si la media de dos muestras tienen más diferencias de lo que se esperaría si son aleatorias.\nFórmula: \\(t = {{(\\bar{x_1}-\\bar{x_2})}\\{SED}}\\)\nFunción relevante en R: t.test.\nEquivalente en inglés: «T-test independent samples».\nPrueba t para muestras pareadas\nTest estadístico que nos indica si la media de dos muestras correlacionadas tienen más diferencias de lo que se esperaría por razones aleatorias.\nFórmula: \\(t = {{\\bar{X}_D}\\{s_D\\{\\sqrt{n}}}}\\)\nFunción relevante en R: t.test.\nEquivalente en inglés: «T-test dependent samples».\n","code":""},{"path":"pruebas-no-paramétricas.html","id":"pruebas-no-paramétricas","chapter":"Capítulo 8 Pruebas no paramétricas","heading":"Capítulo 8 Pruebas no paramétricas","text":"En el capítulo ?? vimos que para usar esas pruebas tenemos que cumplir con algunos requisitos sobre la distribución normal de las variables, nivel de medición y homogeneidad de las varianzas. Con alguna frecuencia, sin embargo, resulta que nuestros datos cumplen con alguno de esos requisitos. Esto se puede dar por la naturaleza de la investigación, por ejemplo si estamos investigando un fenómeno que se puede medir escala de intervalo o razón; o tenemos relativamente pocos datos y luego de realizar los test de Fisher y Shapiro nos damos cuenta de que o la varianza es muy heterogénea o que las variables carecen de distribución normal.Por suerte todavía hay esperanza. Existen algunas pruebas estadísticas, llamadas paramétricas que nos pueden salvar en estos casos. En este capítulo desarrollaremos tres de ellos.","code":""},{"path":"pruebas-no-paramétricas.html","id":"prueba-u-de-mann-whitney","chapter":"Capítulo 8 Pruebas no paramétricas","heading":"8.1 Prueba U de Mann-Whitney","text":"La prueba U de Mann-Whitney resulta útil si tenemos dos muestras independientes y queremos si hay una diferencia en la magnitud de la variable que estamos estudiando, pero podemos usar la prueba de t independiente o la prueba de z porque los datos cumplen con alguno de los requisitos. Para realizar la prueba U de Mann-Whitney ponemos las observaciones de las dos muestras en orden ascendiente y asignamos un rango ordinal de manera que 1 corresponde la observación de menor magnitud, 2 la segunda etcétera. Luego nos fijamos en las diferencias entre las observaciones.La prueba se basa en una comparación de cada observación de una muestra \\(x_i\\) con cada observación en la segunda muestra \\(y_j\\). Si las muestras tienen la misma mediana, entones cada observación tiene un 0,5 (50%) de chance de ser mayor o menor que la observación correspondiente de la otra muestra. Por tanto plantea las hipotesis:\\(H_0: P(x_i>y_j)={1\\over2}\\)\\(H_1: P(x_i>y_j)\\neq{1\\over2}\\)La prueba U de Mann-Whitney también se conoce con otros nombres: Mann–Whitney–Wilcoxon, Wilcoxon rank-sum test y Wilcoxon–Mann–Whitney. Por ello está disponible en R por medio de la función wilcox.test.Ejemplo 5.1  (Prueba U de Mann-Whitney en R) :En este ejemplo vamos suponer que tenemos datos diagnósticos de cuatro mujeres y cinco hombres. Todos fueron diagnosticados con diabetes y tenemos la edad la cual se les descubrió la enfermedad. Queremos saber si hay diferencia en la edad entre hombres y mujeres.\nLos datos son:Hombres: {19, 22, 16, 29, 24},\nMujeres: {20, 11, 17, 12}.Vemos que podemos rechazar \\(H_0\\) en este caso.","code":"\nHombres = c(19, 22, 16, 29, 24)\nMujeres = c(20, 11, 17, 12)\nwilcox.test(Hombres, Mujeres)#> \n#>  Wilcoxon rank sum exact test\n#> \n#> data:  Hombres and Mujeres\n#> W = 17, p-value = 0.1111\n#> alternative hypothesis: true location shift is not equal to 0"},{"path":"pruebas-no-paramétricas.html","id":"wilcoxon-signed-rank-test","chapter":"Capítulo 8 Pruebas no paramétricas","heading":"8.2 Prueba de los rangos con signo de Wilcoxon","text":"Vimos en la sección 8.1 que la prueba U de Mann-Whitney puede ser una alternativa la prueba de t de Student para muestras intependiente (véase la sección 7.1) cuando los requisitos para un test paramétrico se cumplen. Si los datos son pareados tenemos la prueba de los rangos con signo de Wilcoxon como alternativa prueba t para muestras pareadas que vimos en la sección 7.4.La lógica de la prueba de los rangos con signo de Wilcoxon es similar la de la prueba de t pareada. Si hay diferencia en el antes y despues, por ejemplo, las diferencias entre las observaciones deberían tender cero.Ejemplo 4.1  (Prueba de los rangos con signo de Wilcoxon en R) :En este ejemplo vamos suponer que tenemos un grupo de doce pacientes con artritis y les damos dos medicaciones distintas para aliviar los síntomas. Pedimos todos que nos indiquen cuantas horas de alivio observaron con ambas drogas.Los datos se observan en la tabla 8.1.Tabla 8.1: Eficiencia de dos medicamentos reportada por los pacientes.En R ponemos los datos en un data.frame:E iniciamos nuestros tests:¡Bien! tenemos problemas de varianza.¡Ups!, las variables tienen distribución normal. Entonces podemos usar la prueba t pareada, tenemos que probar con Wilcoxon.Usamos la función wilcox.test con el parametro extra de paired = TRUE.Vemos que el valor p se encuentra debajo de nuestro nivel de significanza (\\(\\alpha=0,05\\)), con lo cual rechazamos \\(H_0\\) y concluimos que hay una diferencia estadísticamente significativa entre las dos mediamentos.","code":"\ndatos = data.frame(\n  Paciente = c( 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12),\n  Droga.A = c( 2,  3.6,  2.6,  2.7,  7.3,  3.4,  14.9,  6.6,  2.3,  2.1,  6.8,  8.5),\n  Droga.B = c( 3.5,  5.7,  2.9,  2.4,  9.9,  3.3,  16.7,  6,  3.8,  4,  9.1,  20.9)\n)\nvar.test(datos$Droga.A,datos$Droga.B)#> \n#>  F test to compare two variances\n#> \n#> data:  datos$Droga.A and datos$Droga.B\n#> F = 0.41865, num df = 11, denom df = 11, p-value =\n#> 0.1643\n#> alternative hypothesis: true ratio of variances is not equal to 1\n#> 95 percent confidence interval:\n#>  0.1205199 1.4542635\n#> sample estimates:\n#> ratio of variances \n#>          0.4186498\nshapiro.test(datos$Droga.A)#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  datos$Droga.A\n#> W = 0.80692, p-value = 0.01124\nshapiro.test(datos$Droga.B)#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  datos$Droga.B\n#> W = 0.7883, p-value = 0.006919\nwilcox.test(datos$Droga.A, datos$Droga.B, paired = TRUE)#> \n#>  Wilcoxon signed rank test with continuity correction\n#> \n#> data:  datos$Droga.A and datos$Droga.B\n#> V = 8, p-value = 0.01669\n#> alternative hypothesis: true location shift is not equal to 0"},{"path":"pruebas-no-paramétricas.html","id":"y-si-usabamos-la-prueba-t-igual","chapter":"Capítulo 8 Pruebas no paramétricas","heading":"¿Y si usabamos la prueba t igual?","text":"Si nos hubéramos olvidado de verificar la conformidad de los requisitos podríamos haber caído en la prueba t paramétrica, ¿qué hubiera pasado?Veamos:Podemos observar que la prueba de t es sensible la falta de normalidad en nuestras variables y logra rechazar \\(H_0\\).","code":"\nt.test(datos$Droga.A, datos$Droga.B, paired = TRUE)#> \n#>  Paired t-test\n#> \n#> data:  datos$Droga.A and datos$Droga.B\n#> t = -2.1465, df = 11, p-value = 0.05498\n#> alternative hypothesis: true difference in means is not equal to 0\n#> 95 percent confidence interval:\n#>  -4.28706458  0.05373125\n#> sample estimates:\n#> mean of the differences \n#>               -2.116667"},{"path":"pruebas-no-paramétricas.html","id":"prueba-de-signos","chapter":"Capítulo 8 Pruebas no paramétricas","heading":"8.3 Prueba de signos","text":"La prueba de Wilcoxon que vimos en la sección 8.2 requiere que los datos tengan una escala de medición (véase la sección ??) de intervalo. Pero veces tenemos datos que solo se pueden medir escala ordinal como por ejemplo la preferencia por alguna bebida de 1 5. En este caso es razonable afirmar que la diferencia entre uno y dos es la misma que entre dos y tres, entonces podemos tomar en cuenta la magnitud de esas diferencias.La prueba de signos resuelve este problema convirtiendo la diferencia en una variable trinaria: puede ser cero, positiva o negativa. La lógica del test es similar la de Wilcoxon, si hay un patrón en las observaciones estas diferencias deberían tender cero.\nPara realizar un test de signo debemos primero anotar el signo (positivo, negativo o cero) de todas los pares de observaciones que tenemos. Cuando la diferencia es cero se excluye el par del análisis y reducimos N acorde eso. Luego sumamos los positivos por un lado y los negativos por otro y tomamos el menor le los dos. Este número, menudo significado por una W, de puede compara con la tabla de valores críticos para el N que quedó, que se puede consultar en el apendice B para N entre 5 y 25.Cuando N es superior 25, es decir cuando tenemos venticinco o más observaciones que sean cero, se puede transformar W en una variable normalizada. Usando la fórmula en la definición 8.1.Definición 8.1  (Normalizar W del test de signos) \\[\nz={{N-2\\times{W}-1}\\\\sqrt{N}}\n\\]Ejemplo 7.6  (Realizar prueba de sign para N>25) :En este ejemplo vamos suponer que hemos preguntado 150 personas su opinión sobre el café de dos cafeterías: y B, de la Ciudad de Buenos Aires. Les pedimos que indiquen en una escala de 1 5 cuánto les gusta cada producto. De ellos cincuenta dan el mismo ranking ambos productos, con lo sus opiniones se eliminan del cálculo. De los restantes cien tenemos 39 que prefieren B y 61 que prefieren . Tomamos el menor valor (39) y aplicamos la fórmula:\n\\[\nz={{N-2\\times{W}-1}\\\\sqrt{N}} = {{100-2\\times{39}-1}\\\\sqrt{100}} = {21\\over10} = 2,1\n\\]Recordamos que el valor mágico de la distribución normal –la regla empírica– es 1,96 para nuestro nivel de significanza \\((p\\leqslant0,05)\\) y concluimos que existe una diferencia estadísticamente significativa.","code":""},{"path":"pruebas-no-paramétricas.html","id":"cuál-usar-1","chapter":"Capítulo 8 Pruebas no paramétricas","heading":"8.4 ¿Cuál usar?","text":"En la figura 8.1 podemos ver un diagrama de flujo para eligir un test paramétrico.\nFigura 8.1: Diagrama de flujo para selección de pruebas estadísticas paramétricas.\n","code":""},{"path":"pruebas-no-paramétricas.html","id":"glosario-8","chapter":"Capítulo 8 Pruebas no paramétricas","heading":"8.5 Glosario","text":"Prueba de los rangos con signo de Wilcoxon\nPrueba estadística. Alternativa la prueba t pareada, cuando los datos cumplen con los requisitos para pruebas paramétricas.\nFunción relevante en R: wilcox.test.\nEquivalente en inglés: «Wilcoxon ranked sign test».\nPrueba de signos\nPrueba estadística. Alternativa la prueba t pareada, cuando los datos son de escala ordinal.\nEquivalente en inglés: «Sign-test».\nPrueba U de Mann-Whitney\nPrueba estadística. Alternativa la prueba t o prueba z, cuando los datos cumplen con los requisitos para pruebas paramétricas.\nFunción relevante en R: wilcox.test.\nEquivalente en inglés: «Mann-Whitney U test».\n","code":""},{"path":"chi-square-test.html","id":"chi-square-test","chapter":"Capítulo 9 Prueba de \\(\\chi^2\\)","heading":"Capítulo 9 Prueba de \\(\\chi^2\\)","text":"En los capítulos ?? y ?? vimos varios tests estadísticos que nos permiten apreciar la significanza de diferencias entre dos conjuntos de medidas cuantitativas. Las variables que vimos se medían en escala de razón, intervalo u ordinal. En este capítulo vamos explorar algunas técnicas que nos permiten trabajar con variables que se pueden medir en términos numéricos, sino que son de tipo «sí-o-»; es decir que son de escala nominal.En particular vamos explorar la distribuciónd de \\(\\chi^2\\) de Pearson. \\(\\chi\\) es una letra griega que suele pronunciarse «ji» (/xi/) y «chi» (/tʃiː)/30.\nFigura 9.1: Distribución «ji cuadrado» con diferentes grados de libertad.\n","code":""},{"path":"chi-square-test.html","id":"características","chapter":"Capítulo 9 Prueba de \\(\\chi^2\\)","heading":"9.1 Características","text":"El test de \\(\\chi^2\\) nos permite comparar las frecuencias que observamos con las frecuencias que esperaríamos en base un modelo teórico o una hipótesis sobre la distribución de la variable en cuestión. Por cada par de valores observados y esperados calculamos la diferencia y aplicamos la fórmula de la definición 9.1.Definición 9.1  ($\\chi^2$) \\[\n\\chi^2 = \\sum{(O-E)^2\\{E}}\n\\]\ndonde:O: la frecuencia observadaE: la frecuencia esperadaEs importante tener en cuenta que \\(\\chi^2\\) se calcula usando las frecuencias y las proporciones.La hipótesis nula es que existe diferencia entre los valores observamos y los valores esperados. La alternativa es que hay tal diferencia. La forma de la distribución \\(\\chi^2\\), al igual que la de t, depende de los grados de liberdad que desarrollaremos más adelante.","code":""},{"path":"chi-square-test.html","id":"prueba-de-independencia-o-asociación","chapter":"Capítulo 9 Prueba de \\(\\chi^2\\)","heading":"9.2 Prueba de independencia o asociación","text":"Un uso muy frecuente de la prueba de \\(\\chi^2\\) es la de probar si dos características son independientes o tienen una asociación de manera que las frecuencias elevadas en una de ellas suele ser acompañado con frecuencias altas en la otra.Digamos que estamos haciendo una encuesta de opinión y preguntamos 1230 argentinas y 961 argentinos si están favor o en contra de la ley del aborto o . Queremos saber si en género de la persona está asociado con esa opinión. Entonces nuestros datos se pueden desplegar en una tabla 2 por 2.La hipótesis nula es que hay asociación entre las dos variables, es decir que el género de la persona se asocia con su opinión política sobre este tema. Para calcular los valores esperados tenemos que calcular las sumas de las filas y las columnas y además el total de ellos.Tabla 9.1: Opiniones sobre la ley del aborto.El valor esperado es la cantidad de las observaciones que caen en cada celda si las distribuimos proporcionalmente. Esto se calcula multiplicando las sumas de la fila y columna de la celda respectiva y dividir por el total de las observaciones. Por ejemplo, el valor esperado de mujeres favor sería:\n\\[\nE = {{1230\\times1246}\\over2191} = 699,48\n\\]Si calculamos esto para todas las celdas obtenemos:Tabla 9.2: Valores esperados: opiniones sobre la ley del aborto.y con esto podemos calcular las diferencias.Tabla 9.3: Diferencias entre valores observados y esperados.y podemos aplicar la fórmula en 9.1:\\[\n\\chi^2 = \\sum{(O-E)^2\\{E}} = {62,52^2\\over699,49} +{-62,52^2\\over530,51} +{62,52^2\\over546,51}+{-62,52^2\\over414,49} = 29,53.\n\\]Podemos comparar este valor con los de la tabla en el apendice C para un grado de libertad. Vemos que rechazamos \\(H_0\\) y concluimos que el género sí influye en la opinión sobre este tema.","code":""},{"path":"chi-square-test.html","id":"degrees-of-freedom","chapter":"Capítulo 9 Prueba de \\(\\chi^2\\)","heading":"9.2.1 Grados de libertad","text":"lo largo de este texto se ha mencionado en algunas ocasiones el término grados de libertad y hasta ahora ha sido demasiado complejo calcularlo restando uno del número de observaciones. El concepto de grado de libertad se puede entender si consideramos la tabla 9.1 en la que tenemos una tabla de contingencia \\(2\\times2\\). Calculamos en ese caso las frecuencias marginales que están el la columna suma. Imaginemos que tenemos la misma tabla con las frecuencias marginales pero con una sola de las frecuencias observadas. Así lo hemos hecho en la tabla 9.4Tabla 9.4: Tabla de contingencia con un solo valor.Con este único valor podemos rellenar las demás celdas, ya que su contenido está dato por la diferencia entre ese valor y los totales marginales. Esto quiere decir que en esta tabla hay un solo valor que se pueda asignar arbitrariamente, el resto está dado por este valor. Por ello decimos que tenemos un solo grado de libertad.En capítulos anteriores hemos visto que los grados de libertad menudo son N-1. Podemos usar un ejemplo sencillo para demostrar por qué tiene que ser así. Si hacemos un conjunto de tres números y queremos que la suma sea diez, podemos asignar cualquier número en las primeras dos posiciones, pero cuando vamos asignar el tercero ya tenemos libertad de eligir. Entonces tenemos dos grados de libertad.Para una tabla de contingencia la fórmula general para calcular los grados de libertad es: \\((c-1)\\times(f-1)\\) es decir número de columnas menos uno por número de filas menos uno. Si la tabla es de \\(3\\times3\\), tendríamos 4 grados de libertad.Ejemplo 5.1  (Prueba de $\\chi^2$ en R) ;En este ejemplo vamos realizar la misma prueba de \\(\\chi^2\\) que fuimos desarrollando en las secciones anteriores. Podemos usar la función de R chisq.test para realizarla. Toma como argumento una matriz de datos de las frecuencias.Como se puede observar, la sintaxis de R es del todo intuitiva, por lo que siempre conviene verificar que tenemos los números y nombres correctos antes de proceder con el test.El valor de p es tan bajo que R lo devuelve en notación científica. La parte e-08 quiere decir que el número es: 0,000000007019, es decir que hay ocho ceros antes de los dígitos significativos.También vemos que el valor de \\(\\chi^2\\) que calculó R es distinto al que calculamos mano, aunque sea por unas décimas. Esto se debe que por defecto R hace una corrección de Yates. Yates descubrió que para una tabla de contingencia \\(2\\times2\\) hay un sesgo positivo y propuso una técnica para contrarrestar el sesgo. Si queremos usar la formula original, y la que usamos para nuestro cálculo mano podemos agregar el parámetro correct = FALSE la función así:y vemos que R coincide con nuestros cálculos.","code":"\nM <- as.table(\n  rbind(c(762, 468), \n        c(484, 477))\n  )\n# Damos nombre a las columnas y las filas \ncolnames(M) <- c(\"A favor\",\"En contra\")\nrownames(M) <- c(\"Mujeres\",\"Hombres\")\n\n# Verificamos el ingreso de datos\nM#>         A favor En contra\n#> Mujeres     762       468\n#> Hombres     484       477\n# Realizamos test de ji-cuadrado\nchisq.test(M)#> \n#>  Pearson's Chi-squared test with Yates' continuity\n#>  correction\n#> \n#> data:  M\n#> X-squared = 29.06, df = 1, p-value = 7.019e-08\nchisq.test(M, correct = FALSE)#> \n#>  Pearson's Chi-squared test\n#> \n#> data:  M\n#> X-squared = 29.53, df = 1, p-value = 5.506e-08"},{"path":"chi-square-test.html","id":"glosario-9","chapter":"Capítulo 9 Prueba de \\(\\chi^2\\)","heading":"9.3 Glosario","text":"Grados de libertad\nNúmero de valores que se pueda asignar arbitrariamente un conjunto manteniendo estable sus propiedades.\nEquivalente en inglés: «Degrees freedom».\nPrueba de \\(\\chi^2\\) «ji cuadrado»\nPrueba estadística que nos permite apreciar si dos variables nominales están asociadas.\nFórmula: \\(\\chi^2 = \\sum{(O-E)^2\\{E}}\\)\nEquivalente en inglés: «Chi-square test».\n","code":""},{"path":"correlación.html","id":"correlación","chapter":"Capítulo 10 Correlación","heading":"Capítulo 10 Correlación","text":"La correlación es el área de las estadísticas que estudia la relación sistemática entre dos o más variables e intenta contestar preguntas como: ¿Si sube va subir B también? En este capítulo desarrollaremos algunas técnicas para contestar este tipo de pregunta.","code":""},{"path":"correlación.html","id":"visualización","chapter":"Capítulo 10 Correlación","heading":"10.1 Visualización","text":"El primer paso para estudiar posibles relaciones entre variables es visualizarlos. Si tenemos dos variables medidas por cada miembro de la población o muestra que estamos investigando podemos generar un diagrama de disperción también conocido como scatterplot. En este tipo de visualización cada miembro de la muestra/población está representado por un punto, y las coordinadas del punto corresponde las dos variables que hemos medido, en el eje horizontal y vertical respectivamente.El las figura 10.1, vemos que la concentración de puntos suben de la izquierda la derecha. Es decir cuando avanzamos en el eje horizontal avanzamos en el eje vertical también. Es un ejemplo de una correlación positiva, como podría ser edad y estatura.\nFigura 10.1: Correlación positiva\nEn la figura 10.2 vemos lo contrario, mientras avanzamos en el eje vertical retrocedemos (o bajamos) en el eje horizontal. Esto se conoce como correlacion negativa.\nFigura 10.2: Correlación negativa\nEn la figura 10.3, también vemos correlación negativa, pero es menos fuerte que en la figura 10.2.\nFigura 10.3: Correlación negative leve\nEn la figura 10.4 vemos una correlación negativa casi perfecta entre las dos variables.\nFigura 10.4: Correlación casi perfecta\nEn la figura 10.5 vemos un caso de correlación inexistente entre las variables en cuestión.\nFigura 10.5: Correlación nula\nEn la figura 10.6 vemos que existe una relación entre las dos variables, pero que esta es lineal.31\nFigura 10.6: Relación lineal\nLas figuras 10.1,\n10.2,\n10.3,\n10.4,\n10.5 y\n10.6\ndemuestran por qué es preciso graficar los datos al inicio del análisis. Nos da una indicación de si existe una correlación o , si es positiva o negativa y que tan fuerte es.\nTambién nos podemos darnos cuenta de patrones en los datos que son lineales, como es el caso de los datos en la figura 10.6. Asimismo, veces nos encontramos con una correlación como la que vemos en la figura 10.4. Las correlaciones que son demasiado perfectas suelen ser un signo de advertencia y podemos preguntarnos si en realidad son dos variables distintas o si las dos están midiendo lo mismo.Ejemplo 10.1  (Generar diagrama de dispersión en R) :En el ejemplo 10.1 utilizamos la función rnorm para generar cien observaciones aleatorias con distribución normal y los ponemos dentro de un data.frame. Luego usamos la función plot para graficarlos. Como nuestro data.frame tiene solo dos columnas R entiende que estos son los datos que queremos graficar. Si el data.frame tiene más columnas, podemos especificar los que queremos graficar así:Ejemplo 10.2  (Generar diagrama de dispersión en R) :Por defecto R viene con algunos data.frames ya cargados, uno de ellos es «trees», podemos usar la función head para ver las primeras seis filas.Vemos que tiene tres columnas «Girth», «Height» y «Volume» (circumferencia, alto y volumen), los que, por lógica, deben tener alta correlación. Graficamos dos de ellos.Si usamos la función plot sin especificar columnas R entiende que queremos ver todas las combinaciones.Este tipo de visualización puede ser útil cuando tenemos algunas variables y queremos darnos cuenta qué correlaciones hay. La visualización funciona bien hasta cierto número de columnas –ocho más o menos–, luego se vuelve difícil de leer y por ende de interpretar.","code":"\n# Generamos datos\ndatos = data.frame(\n  x=rnorm(100),\n  y=rnorm(100)\n)\n\n# Graficamos\nplot(datos)\nplot(datos$x,datos$y)\nhead(trees)#>   Girth Height Volume\n#> 1   8.3     70   10.3\n#> 2   8.6     65   10.3\n#> 3   8.8     63   10.2\n#> 4  10.5     72   16.4\n#> 5  10.7     81   18.8\n#> 6  10.8     83   19.7\nplot(trees$Girth, trees$Volume)\nplot(trees)"},{"path":"correlación.html","id":"coeficientes-de-correlación","chapter":"Capítulo 10 Correlación","heading":"10.2 Coeficientes de correlación","text":"Para tener una medida cuantitativa precisa de la correlación entre las variables calculamos un coeficiente de correlación. continuación vamos tres de ellos, el de Pearson, el de Spearman y el coeficiente \\(\\phi\\) (de la letra griega que corresponde f en minúscula – se pronuncia «fi». Los coeficientes de correlación se expresan por un número con varios decimales entre -1 y 1, donde -1 y 1 indican correlaciones perfectas, negativas y positivas respectivamente y 0 indica correlación nula.El coeficiente Pearson es adecuado para datos de escala de razón o intervalo, el de Spearman para datos de escala ordinal y el coeficiente \\(\\phi\\) se usa para datos nominales.","code":""},{"path":"correlación.html","id":"coeficiente-pearson","chapter":"Capítulo 10 Correlación","heading":"10.2.1 Coeficiente Pearson","text":"Como ya mencionamos, el coeficiente de Pearson es apropiado cuando las variables comparar con de escala de intervalo o razón ya que toma en cuenta la magnitud relativa de las observaciones.Si tenemos un conjunto de pares de observaciones podemos representar el primer elemento del par por x y el segundo por y. Entonces el conjunto de los x van tener una desviación estándar se calcula según la definición 3.4, así:\n\\[\ns_x = {\\sqrt{(\\sum(x-\\bar{x})^2\\{N-1}}}.\n\\]De la misma manera y tiene su desviación estándar:\n\\[\ns_y = {\\sqrt{(\\sum(y-\\bar{y})^2\\{N-1}}}.\n\\]Ahora podemos normalizar las variables según 4.1 asi:\\[\nz_x = {x-\\bar{x}\\{s_x}},\n\\]\\[\nz_y = {y-\\bar{y}\\{s_y}}.\n\\]Y con estos datos podemos calcular el coeficiente según la definición 10.1.Definición 10.1  (Coeficiente de correlación de Pearson) :\\[\nr={\\sum{z_xz_y}\\{N-1}}\n\\]\ndonde:\\(\\sum{z_xz_y}\\): La suma de los productos32 de las dos variables normalizadas.Existe otra definición es matemáticamente equivalente y que se usa veces para hacer el cálculo mano:Definición 10.2  (Coeficiente de correlación Pearson) :\\[\nr={N\\Sigma{xy}-\\Sigma{x}\\Sigma{y}\\{\\sqrt{\\{N\\Sigma{x^2}-(\\Sigma{x})^2\\}\\times\\{N\\Sigma{y^2}-(\\Sigma{y})^2\\} }}}\n\\]Ejemplo 10.3  (Cálculo del Coeficiente de correlación de Pearson) :En este ejemplo, adaptado de,33 vamos suponer que hemos tomado un examen de traducción y otro de comprensión de inglés doce estudiantes. Los resultados de estos exámenes están en la tabla 10.1.Tabla 10.1: Resultados de un examen de tradución (x) y de comprensión (y) de ingles.Para poder aplicar la fórmula vamos precisar los valores llevados al cuadrado, el producto de \\(x\\times y\\) y las sumas de las columnas. Calculándolos obtenemos los datos de la tabla 10.2.Tabla 10.2: Resultados de un examen de tradución (x) y de comprensión (y) de ingles.Sabemos que N=12, pero vamos precisar las sumas de algunas columnas:\\(\\Sigma{x}\\) = 154\\(\\Sigma{y}\\) = 162\\(\\Sigma{x^2}\\) = 2054\\(\\Sigma{y^2}\\) = 2290\\(\\Sigma{xy}\\) = 2124.Aplicamos la fórmula:Ejemplo 10.4  (Cálculo del Coeficiente de correlación de Pearson en R) :Si queremos hacer todos los cálculos del ejemplo 10.3 mano podemos recurrir R que con la función cor lo calcula.","code":"\n# Cargamos datos\ndatos<- data.frame(\n  Estudiante = c( 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12),\n  x = c( 17, 13, 12, 14, 15, 8, 9, 13, 11, 14, 12, 16),\n  y = c( 15, 13, 8, 17, 16, 9, 14, 10, 16, 13, 14, 17)\n) \n\n# Llamamos función\ncor(datos$x, datos$y)#> [1] 0.5031258"},{"path":"correlación.html","id":"coeficiente-spearman","chapter":"Capítulo 10 Correlación","heading":"10.2.2 Coeficiente Spearman","text":"Si una o ambas variables que estamos comparando son de escala ordinal, el coeficiente apropiado es el de Spearman. Para calcularlo ordenamos las observaciones de la primer variable de manera ascendiente y les damos el valor de su orden. Si dos observaciones de la misma variable tienen el mismo valor, si hay empates, se saca el promedio cual si el empate hubiera existido. Hacemos lo mismo para la segunda variable. Calculamos la diferencia entre los rangos para cada par de observaciones. La correlación Spearman o \\(\\rho\\) de la letra griega r se calcula según la definición 10.3.Definición 10.3  (Coeficiente de correlación de Spearman) :\\[\n\\rho = 1-{6\\sum{d^2}\\{N(N^2-1)}}  \n\\]Imaginamos que pedimos diez personas que ranqueen en una escala de uno diez cuánto les gustaron dos cafeterías de Buenos Aires. Ya que los datos son de escala ordinal, tenemos que recurrir Spearman. Usamos la misma función cor con un parámetro extra: method = \"spearman\" para indicar que queremos usar la correlación de Spearman.Observamos que hay alto grado de correlación entre los ranking de los dos cafés.","code":"\n# Cargamos datos\nrankings <- data.frame(\n  Cafe.A = c(7, 6, 4, 5, 8, 7, 10, 3, 9, 2),\n  Cafe.B = c(5, 4, 5, 6, 10, 7, 9, 2, 8, 1)\n)\n\n# Llamamos función\ncor(rankings$Cafe.A, rankings$Cafe.B, method = \"spearman\")#> [1] 0.875"},{"path":"correlación.html","id":"coeficiente-phi","chapter":"Capítulo 10 Correlación","heading":"10.2.3 Coeficiente \\(\\phi\\)","text":"Si las dos variables en cuestión son nominales la pregunta se reduce : ¿Si observamos la propiedad es probable que observemos también B? Si estamos trabajando con datos educativos la pregunta podría ser ¿Si el estudiante responde correctamente el 1r ítem, es probable que también acierte el 2o? Esto se puede representar en una tabla \\(2\\times2\\) como la que vemos en 10.7.\nFigura 10.7: Tabla de contingencia dos por dos\nEn esta tabla las celdas , B, C y D son las frecuencias de las observaciones. Por ejemplo sería el número de estudiantes que acertaron el 1o pero el 2o. B la frecuencia de estudiantes que pasaron ambos ítems y así sucesivamente. La correlación entre las dos variables se puede medir aplicando la formula de la definición 10.4.Definición 10.4  (Coefficiente de $\\phi$) \\[\n\\phi = {{BC-AD}\\{\\sqrt{(+B)\\times(C+D)\\times(+C)\\times(B+D)}}}\n\\]Debería quedar claro que el coeficiente \\(\\phi\\) está estrechamente relacionado con la prueba de \\(\\chi^2\\) que vimos en la definición 9.1. De hecho se relacionan matemáticamente:\n\\[\n\\phi = \\sqrt{\\chi^2/N} \\Leftrightarrow \\chi^2 = N\\times\\phi^2.\n\\]\nPor tanto la significanza de \\(\\phi\\) se puede obtener por medio de la conversión \\(\\chi^2\\).","code":""},{"path":"correlación.html","id":"interpretación-de-correlacciones","chapter":"Capítulo 10 Correlación","heading":"10.3 Interpretación de correlacciones","text":"Es muy importante entender que una correlación, incluso alta, entre dos variables quiere decir que la relación entre ellas es de causa y efecto. Si hacemos una muestra en la escuela secundaria y medimos estatura, por un lado, y nivel de inglés por otra, es bastante probable que encontremos una correlación muy fuerte entre las dos variables. Pero debería estar claro que ni la estatura causa conocimientos de inglés ni tampoco lo contrario. Lo que claramente pasa es que mas edad los estudiantes tienen más estatura y han cursado más niveles de inglés.Saltar conclusiones sobre causalidad basadas en correlaciones es tal vez el error estadístico más frecuente en la literatura tanto académica como periodística. Nunca hay que olvidar que una correlación significativa solo nos dice que existe una relación matemática entre dos variables. nos indica cómo interpretarla ni mucho menos sobre sus causas y efectos.","code":""},{"path":"correlación.html","id":"glosario-10","chapter":"Capítulo 10 Correlación","heading":"10.4 Glosario","text":"Coeficiente \\(\\phi\\) «fi».\nCoeficiente que da cuenta de la correlación entre dos variables nominales.\nFórmula: \\(\\phi = {{BC-AD}\\{\\sqrt{(+B)\\times(C+D)\\times(+C)\\times(B+D)}}}\\)\nFunción relevante en R: chi.test.\nEquivalente en inglés: «Phi correlation».\nCoeficiente de correlación de Pearson\nCoeficiente que da cuenta de la correlación entre dos variables.\nFórmula: \\(r={\\sum{z_xz_y}\\{N-1}}\\)\nFunción relevante en R: cor.\nEquivalente en inglés: «Pearson coefficient».\nCoeficiente Spearman\nCoeficiente que da cuenta de la correlación entre dos variables cuando una o ambas de ellas son de escala ordinal.\nFórmula: \\(\\rho = 1-{6\\sum{d^2}\\{N(N^2-1)}}\\)\nFunción relevante en R: cor.\nEquivalente en inglés: «Spearman coefficient».\nCorrelación negativa\nRelación entre dos variables que muestra que si una aumenta la otra disminuye.\nEquivalente en inglés: «Positive correlation».\nCorrelación positiva\nRelación entre dos variables que muestra que ambas aumentan o disminuyen simultáneamente.\nEquivalente en inglés: «Positive correlation».\n","code":""},{"path":"distribución-t.html","id":"distribución-t","chapter":"A Distribución t","heading":"A Distribución t","text":"La tabla que sigue despliega los valores críticos de la distribución t para diferentes niveles de significanza y grados de libertad (GL). Los niveles de significanza indican un test direccional. Para una prueba unidireccional se usará el nivel inmediatamente superior.Tabla .1: Valores críticos de t por nivel de significanza y grados de libertad.","code":""},{"path":"valores-críticos-del-test-de-signo.html","id":"valores-críticos-del-test-de-signo","chapter":"B Valores críticos del test de signo","heading":"B Valores críticos del test de signo","text":"La tabla (B.1) muestra valores críticos de W para diferentes valores de N. Para que sea significativo W tiene que ser menor o igual al valor.Tabla B.1: Valores críticos de W en el test de signo por N.","code":""},{"path":"chi-square-disrtibution.html","id":"chi-square-disrtibution","chapter":"C Distribución \\(\\chi^2\\)","heading":"C Distribución \\(\\chi^2\\)","text":"La tabla que sigue despliega los valores críticos de la distribución \\(\\chi^2\\) para diferentes niveles de significanza y grados de libertad (GL). Los niveles de significanza indican un test direccional.Tabla C.1: Valores críticos de χ2 por nivel de significanza y grados de libertad.","code":""},{"path":"referencias.html","id":"referencias","chapter":"Referencias","heading":"Referencias","text":"","code":""}]
