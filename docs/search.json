[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Métodos Cuantitativos",
    "section": "",
    "text": "Este texto ha sido editado en respuesta a la aparente falta de un libro de texto introductorio al análisis cuantitativo y estadísticas accesible y moderno en castellano. Si bien fue concebido como material de cátedra para Metodologías cuantitativas materia que dicta el autor en la Escuela de Humanidades de la Universidad Nacional San Martín, se adaptará fácilmente a cursos introductorios de estadísticas en general.\n\n\nEn la segunda edición se corrigió algunos errores ortográficos y de estilo. Optamos por actualizar los ejemplos para incorporar los paquetes del «tidyverse» ya que hemos observado que su uso y adaptación atenúa la curva de aprendizaje para quienes usan R por primera vez o con escasos conocimientos previos.\n\n\n\nCada capítulo desarrolla un tema y/o concepto a ser tratado en clase y la secuencia corresponde a un curso introductorio de estadístocos «clásico», por lo que conviene leerlos en orden. Sigue el orden propuesto por Butler (1985).\n\n\nUno de los objetivos de este trabajo es dotar al lector con las herramientas necesarios para convertirse en un consumidor crítico de textos que se valen de métodos cuantitativos y/o estadísticas para su argumento. En vista de la enorme cantidad de material disponible en inglés, sobre todo en el ámbito acadédico, el autor ha optado por incluir terminología bilingüe español-inglés. Esta elección obedece a un criterio práctico. En cada capítulo encontrarán un glosario con los principales términos mencionados. Incluye traducción a inglés y referencias a R cuando sea relevante.\n\n\n\n\nR es un leguaje de programación especializado para análisis de datos. Es de fuente abierta (Open Source) y uso gratuito. Rstudio es un editor de R que también de uso sin cargo. Ambas herramientas están disponibles en internet y son de amplio uso tanto en el mundo académico como la industria.\nSe puede descargar e instalar R accediendo a esta URL: https://cran.r-project.org/mirrors.html.\nPara Rstudio la URL es: https://www.rstudio.com/products/rstudio/download/#download.\nSe recomienda siempre instalar R primero y luego Rstudio ya que este depende de aquel.\n\n\nA lo largo de este libro encontrarán ejemplos prácticos que pueden ejecutarse en R. El código se diferenciará del resto del texto por su formato, como se puede apreciar en el ejemplo siguiente:\n\n1+1\n\n[1] 2\n\n\nPor convención no se incluye el promt (p.e. “>”) de la consola de R, y los valores de retorno son comentados con “##”, lo que corresponde al estándar para textos técnicos de esta índole. También se puede hacer referencia a código dentro del texto corrido con el mismo formato. Por ejemplo: 1+1.\n\n\n\n\nEste texto fue editado con bookdown (Xie 2018), un paquete de R (Xie 2018) que extiende las capacidades de knitr(Xie 2015) y R-markdown (Allaire et al. 2019) para publicaciones más voluminosas. También hace uso de los paquetes tidyverse (Wickham et al. 2019) y bayestestR(Makowski, Ben-Shachar, y Lüdecke 2019).\n\n\n\nAgradezco a mi colega Diego Forteza por su ayuda y apoyo en durante el proceso de redacción y a Cecilia Magadán por su corrección de estilo.\nDebo expresar también profunda gratitud a Bow Street Destillery en Dublin, Irlanda; sin cuyos productos este proyecto habría sin duda quedado inconcluso.\n\n\n\n\nAllaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, Hadley Wickham, Joe Cheng, Winston Chang, y Richard Iannone. 2019. rmarkdown: Dynamic Documents for R. https://CRAN.R-project.org/package=rmarkdown.\n\n\nButler, Christopher. 1985. Statistics in linguistics. Basil Blackwell.\n\n\nMakowski, Dominique, Mattan S. Ben-Shachar, y Daniel Lüdecke. 2019. «bayestestR: Describing Effects and their Uncertainty, Existence and Significance within the Bayesian Framework.» Journal of Open Source Software 4 (40): 1541. https://doi.org/10.21105/joss.01541.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. «Welcome to the tidyverse». Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nXie, Yihui. 2015. Dynamic Documents with R and knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. http://yihui.name/knitr/.\n\n\n———. 2018. bookdown: Authoring Books and Technical Documents with R Markdown. https://CRAN.R-project.org/package=bookdown."
  },
  {
    "objectID": "01-conceptos-fundamentales.html",
    "href": "01-conceptos-fundamentales.html",
    "title": "1  Conceptos fundamentales",
    "section": "",
    "text": "source(\"_common.R\")\nEn este capítulo introducimos algunos conceptos fundamentales del análisis cuantitativo y de las estadísticas. Consideramos los conceptos de población y muestra. Hacemos una brevísima introducción a la teoría de la probabilidad. Diferenciamos entre los algunos usos importantes de la estadística: descriptiva e inferencial. Finalmente consideramos algunas maneras de clasificar variables."
  },
  {
    "objectID": "01-conceptos-fundamentales.html#poblaciones-y-muestras",
    "href": "01-conceptos-fundamentales.html#poblaciones-y-muestras",
    "title": "1  Conceptos fundamentales",
    "section": "1.1 Poblaciones y muestras",
    "text": "1.1 Poblaciones y muestras\nEn su uso diaro usamos población para designar un grupo de personas, por ejemplo la población del Gran Buenos Aires; o por lo menos de seres vivos como por ejemplo la población de ratas de la CABA. En estadísticas, en cambio, se usa el término de manera más general para significar cualquier recolección de un conjunto, elementos, artículos o sujetos que gozan de características comunes con el fin de estudiarlos y de esta forma se sacar conclusiones específicas para determinar sus resultados. Así podemos hablar de la población de sustantivos en las obras de Jorge Luis Borges o de la población de notas asignadas en los cursos a nivel universitario.\nPodemos distinguir entre poblaciones finintas e infinitas. La población de motocicletas vendidas en Buenos Aires en septiembre es finita. En cambio la población de temperaturas medidas en el Campus de San Martín es infinita, ya que, por lo menos teóricamente, podemos seguir midiendo para siempre.\nCuando una población fininta no es demasiado grande podemos investigar la totalidad de la población. Pero, si la población es muy grande o potencialmente infinita tenemos que estar contentos con muestras extraídas de esta población. Por ejemplo: si queremos saber quién va a ganar las próximas elecciones podríamos preguntar a todo aquel que tiene derecho a votar cómo piensa votar para sacar el resultado. En la práctica esta metodología resultaría demasiado costosa, por lo que hacemos una muestra representativa de votantes, les preguntamos y generalizamos.\nResulta evidente que hay que tener cuidado al selecionar una muestra para análisis. Los métodos estadísticos, los que nos permiten generalizar e inferir, suponen que las muestras están tomadas de manera aleatoria o al azar. Esto no significa que la muestra sea arbitraria, sino que cualquier unidad de la población que estamos estudiando tiene la misma probabilidad de ser selecionada para hacer parte de la muestra.\n\n\n\n\n\nPoblación y muestra.\n\n\n\n\n\n1.1.1 Muestra aleatoria\nPara tener una muestra verdaderamente aleatoria de una población deberíamos asignar un número u otro identificador único a cada una de las unidaded de la población –a cada persona si se trata de una población humana– escribir cada número en un papel y echarlos en una tómbola. Luego de virarla por algún tiempo y mesclar bien los papeles, podríamos de allí sacar la cantidad de papeles que corresponda al tamaño de nuestra muestra. Obviamente esto no resulta muy práctico por lo que se suele empezar con una secuencia de números aleatorios del tamaño de la muestra y extraer unidades de la población basado en ello. Por ejemplo, si quisieramos sacar veinte libros al hazar de un estante de la biblioteca que contiene doscientos libros, necesitamos veinte números aleatorios entre uno y doscientos, y sacamos los libros que desde algún punto de referencia (primer libro del primer nivel) está a esa distancia.\nAhora, ¿dónde encontramos números aleatorios? Hay secuencias en libros de estadísticas, usados principalmente antes de la existencia de computadoras. También se pueden generar esas secuencias en linea. Finalmente, R tienen un generador de números aleatorios que nos permite generar los de números de nuestra muestra con un solo comando usando la función de R sample.\n\nEjemplo en R: Generar muestra\n\nsample(x = 1:200, size = 20)\n\n## [1] 166  46  42 179 188 143 126 135 102  93  72 193  13 107 198 100  88  67  33  99\n\nAcá le estamos pidiendo a R que nos de una muestra aleatoria (sample ) de números entre uno y doscientos (x = 1:200), y que la muestra sea de veinte size = 20 ). Con estos números podemos ir al estante y sacar los libros que queremos estudiar.\nSi corren este comando desde su consola de R los números deben salir diferentes, se hace una muestra aleatoria cada vez.\n\n\nEjemplo en R: Ordenar los datos\nTambién es posible ordenar los números, lo cual nos ahorra un poco de tiempo al retirar los libros. Se logra con la función sort.\n\nsort(\n  sample(x = 1:200, size = 20, replace = TRUE)\n)\n## [1]  29  35  38  41  54  74  75  79  85  92 103 112 114 120 127 153 173 185 187 188\n\n\n\n\n1.1.2 Muestra cuasialeatoria\nOtra estrategia que podría emplearse para sacar veinte libros al azar del estante que describimos en la sección anterior sería decidir que vamos a sacar cada diez libros ya que \\({200\\over20} = 10\\). Este tipo de muestra lleva el epíteto cuasialeatoria, y funciona bien si el orden original de la población es aleatorio. Sin embargo, hay que tener en cuenta que esta estrategia puede generar una muestra no representativa si existe una estructura en ese orden. Típicamente puede resultar problemática si existe periodicidad en la población que estamos analizando. Si, por ejemplo, queremos tener una muestra de cuantos ómnibus pasan delante de mi casa por día sería mala idea decir que vamos a contarlos cada siete días. Si el día que empezamos es un domingo obtendremos seguramente una muestra con cantidades inferiores a la población real (en este caso definida como todos los ómnibus que pasan por mi casa en un día); y si empezamos a contar un lunes las cantidades serían superiores.\n\n1.1.2.1 Ejemplo en R: Generar una sequencia\nSi bien sacar la secuencia para sacar cada diez libros resulta trivial, existe la manera que hacerlo también con una función de R.\n\nseq( from = 10, to = 200 , by=10 )\n## [1]  10  20  30  40  50  60  70  80  90 100 110 120 130 140 150 160 170 180 190 200\n\nLa función seq (de secuencia), toma tres parámetros, desde dónde empezamos (from=10), hasta dónde queremos llegar (to=200), y con qué distancia (by=10).\nPor lo pronto se vuelve más útil si estamos trabajando con números menos redondos. Digamos que queremos sacar cada siete libros de un estante que contiene cien empezando por el número seis.\n\nseq( from = 6, to = 100 , by = 7 )\n## [1]  6 13 20 27 34 41 48 55 62 69 76 83 90 97\n\n\n\n\n1.1.3 Muestra estratificada\nCuando conocemos algunos parámetros de la población que queremos estudiar también nos podemos asegurar que nuestra muestra tenga parámetros similares. Esta estrategia puede resultar particularmente útil si suponemos que este parámetro puede tener alguna influencia en otra variable cuya distribución queremos conocer. Si por ejemplo suponemos que el sexo puede influir en la opinión de una persona sobre la ley del aborto podemos asegurarnos de que nuestra muestra tiene una distribución similar a la de la población en general. Se sabe que hay más o menos mitad y mitad1 en la población general por lo que convendría que nuestra muestra tenga la misma distribución. Así podemos sacar, para una muestra de veinte, diez hombres y diez mujeres al azar2. Lo mismo se puede aplicar a otras variables, por ejemplo, clase social, país de origen etcétera."
  },
  {
    "objectID": "01-conceptos-fundamentales.html#representatividad",
    "href": "01-conceptos-fundamentales.html#representatividad",
    "title": "1  Conceptos fundamentales",
    "section": "1.2 Representatividad",
    "text": "1.2 Representatividad\nEs importante entender que ninguna de las estrategias descritas en la sección anterior nos garantiza que la muestra que sacamos sea representativa de la población, con lo cual no está garantizado que una generalización basada en esa muestra sea válida. Lo que sí se puede calcular es la probabilidad de que la muestra sea representativa. Es decir, podemos tener una estimación de en qué medida la muestra representa la población.\nPara profundizar un poco este concepto vamos a hacer un breve desvío y desarrollar un poco de teoría de la probabilidad por medio de un ejemplo sumamente sencillo. Digamos que queremos hacer una muestra aleatoria de la población en Argentina. Vamos a seleccionar al azar a tan solo tres personas para nuestra muestra. Ya que sabemos que hay la misma cantidad de hombres y mujeres la probabilidad de que el/la primero/a que elijamos sea hombre es 0,53, lo cual también es la probabilidad de que sea mujer. Ahora, cuando seleccionamos el/la segundo/a y tercero/a las probabilidad son las mismas en todos los casos. Las leyes de probabilidad indican que la probabilidad de que dos o más eventos independientes sucedan es el producto de sus probabilidades individuales. Entonces, cuál es la probabilidad de que los tres miembros de la muestra sean mujeres?\n\\[0,5\\times0,5\\times0,5=0,125\\] Resulta evidente que lo mismo sucede si queremos calcular la probabilidad de que todos sean hombres.\nAhora, bien ¿cuál sería la probabilidad de que sean dos mujeres y un hombre?\nHay tres maneras que esto pueda suceder:\n\n(#tab:compinaciones-posibles) Combinaciones posibles.\n\n\nPrimero/a\nSegundo/a\nTercero/a\n\n\n\n\nMasculino\nFemenino\nFemenino\n\n\nFemenino\nMasculino\nFemenino\n\n\nFemenino\nFemenino\nMasculino\n\n\n\nCada una de estas posibilidades tienen la misma probabilidad y como el orden en el que fueron elegidos no es relevante para la muestra, podemos sumar las probabilidades para obtener la probabilidad total: \\[(0,5\\times0,5\\times0,5)+(0,5\\times0,5\\times0,5)+(0,5\\times0,5\\times0,5) = 0,375 \\]\nLógicamente lo mismo ocurre con el caso de dos hombres y una mujer. Entonces tenemos cuatro posibilidades con distintas probabilidades:\n\nProbabilidades de las combinaciones. {#tab:probabilidades-combinaciones-posibles}\n\n\nMuestra\nProbabilidad\n\n\n\n\nTres mujeres\n0,125\n\n\nDos mujeres + un hombre\n0,375\n\n\nDos hombres + una mujer\n0,375\n\n\nTres hombres\n0,125\n\n\n\nObservamos que las probabilidades suman 1, lo cual es matemáticamente inevitable.\nEstá claro que una muestra de tan solo tres personas nunca puede ser representativa de la población, sin embargo vemos que la medida en que son poco representativas varía. Cualquiera de las muestras de 2+1 sería más representativa que las de un solo sexo, y vemos que también son probables.\nEste ejemplo es extensible a muestras más grandes con cálculos similares. Se desarrollará en más detalle en capítulos posteriores, pero para tener un ejemplo un tanto más real imaginemos que hemos decidido realizar una muestra de diez personas de la misma población (que tiene un 50 y 50 de hombres y mujeres).\n\n\nTabla 1.1: Probabilidades de las combinaciones de una muestra de diez.\n\n\nHombres\nMujeres\nProbabilidad\n\n\n\n\n0\n10\n0,001\n\n\n1\n9\n0,010\n\n\n2\n8\n0,044\n\n\n3\n7\n0,117\n\n\n4\n6\n0,205\n\n\n5\n5\n0,246\n\n\n6\n4\n0,205\n\n\n7\n3\n0,117\n\n\n8\n2\n0,044\n\n\n9\n1\n0,010\n\n\n10\n0\n0,001\n\n\n\n\nObtendríamos los resultados de la tabla Tabla 1.1) y observamos que hay aproximadamente un 0,9 de probabilidad (90%) de obtener una muestra no peor que 7-3. También no es de sorprenderse que mientras más grande sea la muestra más probable es que sea representativa4."
  },
  {
    "objectID": "01-conceptos-fundamentales.html#sec-estadisticas-descriptivas-e-inferenciales",
    "href": "01-conceptos-fundamentales.html#sec-estadisticas-descriptivas-e-inferenciales",
    "title": "1  Conceptos fundamentales",
    "section": "1.3 Estadísticas descriptivas e inferenciales",
    "text": "1.3 Estadísticas descriptivas e inferenciales\nEntre los varios usos de las estadísticas este texto tratará de dos de los más importantes. Uno es el descriptivo que consiste en describir cuantitativamente un conjunto de datos y eventualmente generalizar este análisis a una población. Otro es el de inferir propiedades y diferencias entre variables.\nVamos a desarrollar estas distinciones por medio de un ejemplo5. Supongamos que hemos hecho dos muestras aleatorias de las notas del examen final de dos cursos de la materia Métodos cuantitativos, uno dictado exclusivamente como curso teórico y el otro como curso teórico-práctico.\nLas notas son: Curso A (teórico-práctico):\n\n15, 12, 11, 18, 15, 15,9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16,17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16 y 14.\n\nY para el Curso B (teórico):\n\n11, 16, 14, 18,6,8,9, 14, 12, 12, 10, 15, 12,9, 13, 16, 17, 12,8,7, 15,5, 14, 13, 13, 12, 11, 13, 11 y 7\n\nEl examen fue identico para ambos grupos y se podía obtener un máximo de veinte.\nAntes de sacar conclusiones sobre estos datos deberíamos resumirlos. Podemos construir, por ejemplo, una tabla que muestra la frecuencia de cada nota en cada curso. Esto se llama tabla de frecuencias. También nos gustaría saber cuál es la nota más típica, la nota promedio y cuánto varían las notas respecto a éste. Estas son estadísticas descriptivas, y los desarrollaremos en los capítulos dos y tres de este texto.\nPero seguramente también quisiéramos saber con qué nivel de confianza podemos generalizar estos datos a similares grupos de datos usando métodos similares a los mencionados. Nos gustaría saber en qué medida las dos muestras que tenemos son representativas de sus respectivas poblaciones de estudiantes tomando cursos similares. Este tipo de estimaciones se verá en detalle en el capítulo cinco.\nAdemás quisiéramos saber si podemos afirmar que alguno de los dos grupos estuvo mejor que el otro en el examen final. Podríamos postular, por ejemplo, que el grupo que recibió el curso teórico-práctico debería sacar mejores notas en promedio que el otro. Para ello hay que construir un test de la hipótesis y someter nuestros datos a este test.\nTanto la tarea de estimación como el test de hipótesis comprenden la inferencia de relaciones a partir de medidas descriptivas y juntos constituyen el área de estadísticas inferenciales.\nFinalmente, podríamos juntar más datos para determinar si existe en cualquiera de los dos cursos algún sub-grupo cuyas características se relacionan con un resultado específico. Con esta información estaríamos en condiciones de predecir las notas de los estudiantes en futuras cursadas de los cursos en cuestión."
  },
  {
    "objectID": "01-conceptos-fundamentales.html#sec-variables-y-su-clasificacion",
    "href": "01-conceptos-fundamentales.html#sec-variables-y-su-clasificacion",
    "title": "1  Conceptos fundamentales",
    "section": "1.4 Variables y su clasificación",
    "text": "1.4 Variables y su clasificación\nEn estadísticas trabajamos esencialmente con cantidades variables. En estadística definimos variable como: Una característica medida u observada al hacer un experimento u observación. Si, por ejemplo, estamos investigando el clima en Buenos Aires, podemos hacer medidas de temperatura, humedad, dirección e intensidad del viento etcétera.\nLas variables pueden ser clasificadas de diferentes maneras:\n\nPor su relación con otras variables\nEn la mayoría de investigaciones cuantitativas variamos una o más conjuntos de condiciones y medimos los efectos sobre una o más propiedades que son de nuestro interés. Las condiciones que cambiamos nosotros se denominan variables independientes6 y los cuya respuesta a las condiciones cambiantes medimos se llaman variables dependientes.\n\n\nPor su nivel de medición\nCuando hacemos una medición o observación o «recogemos un dato» debemos fijarnos en su nivel de medición, también llamado escala de medición. Distinguimos cuatro niveles o escalas:\n\nNivel nominal\nCuando un dato identifica una etiqueta (o el nombre de un atributo) de un elemento, se considera que la escala de medición es una escala nominal. En esta carecen de sentido el orden de las etiquetas, así como la comparación y las operaciones aritméticas. La única finalidad de este tipo de datos es clasificar a las observaciones. Ejemplo:\n\nUna variable que indica si el visitante de este post es «hombre» o «mujer».\n\nEn esta variable se tienen dos etiquetas para clasificar a los visitantes. El orden carece de sentido, así como la comparación u operaciones aritméticas.\n\n\nNivel ordinal\nCuando los datos muestran las propiedades de los datos nominales, pero además tiene sentido el orden (o jerarquía) de estos, se dice que se mide en escala ordinal. Ejemplo:\n\nUna variable que mide la calidad del café en la cafetería de la universidad. Le podemos asignar de uno a cinco estrellas.\n\nEn esta variable sigue sin tener sentido las operaciones aritméticas, pero ahora sí tiene sentido el orden. Cuatro estrellas es mejor que dos.\n\n\nNivel de intervalo\nEn una escala de intervalo, los datos tienen las propiedades de los datos ordinales, pero a su vez la separación entre las variables tiene sentido. Este tipo de datos siempre es numérico, y el valor cero no indica la ausencia de la propiedad. Por ejemplo: La temperatura (en grados centígrados) medida de una ciudad, puede ser cero sin que tenga sentido decir que «no hay temperatura».\nEn este nivel de medición, los número mayores corresponden a temperaturas mayores. Es decir, el orden importa, pero a la vez la diferencias entre las temperaturas importa. La diferencia entre 10 grados y veinte grados es igual que la diferencia entre 20 y 30. El nivel de medida de intervalo también se conoce como el nivel intervalar.\n\n\nNivel de razón\nEn una escala de razón –también llamado de ratio o racional, los datos tienen todas las propiedades de los datos de intervalo, y la proporción entre ellos tiene sentido. Para esto se requiere que el valor cero de la escala indique la ausencia de la propiedad a medir. Ejemplos de este tipo de variables son el peso de una persona a el tiempo utilizado para una tarea y el salario de una persona. Si una persona gana 100, y otra 10, la primera gana más que la segunda (comparación). También tiene sentido decir que la primera gana 90 más que la segunda (diferencia), o que gana 10 veces más (proporción).\n\n\n\nPor su precisión\nCuando hablamos de precisión en matemáticas y estadísticas nos referimos al numero de decimales que tiene una variable. Esto es distinto de exactitud que significaría la medida en que la medición, o predicción corresponde a la realidad. 1,000 (uno coma cero cero cero), tiene más precisión que 1 (uno) si bien miden la misma cantidad. Esto lleva a la distinción que hacemos entre variables discretas y continuas. Las discretas por su naturaleza tienen precisión cero (no lleva decimales) y las continuas pueden tener la cantidad de decimales que queramos. Para ilustrar la diferencia consideramos dos variables: edad y numero de hijos. En cuanto a la edad se puede tener diez años, diez años y medio o si queremos agregar más precisión: 20,45 años. En cambio numero de hijos es una variable discreta. Se puede tener cero, uno o más, pero no se puede tener 1,45 hijo.\nPor su naturaleza vemos que las variables de escala nominal y ordinal son siempre discretas. Las de escala de intervalo y de escala de razón, en cambio pueden ser tanto discretas como continuas.\nLa mayoría de variables de interés en las ciencias duras se miden por escala de razón o de intervalo, mientras las escalas ordinal y nominal son más importantes en ciencias humanas. El nivel de medición de una variable es de suma importancia cuando decidimos qué medidas de tendencia central, variabilidad y dispersión elegimos para nuestro análisis, y qué test de hipótesis son adecuados. Es un error muy común entre investigadores, particularmente en las ciencias sociales, asumir una escala superior a lo teóricamente sostenible."
  },
  {
    "objectID": "01-conceptos-fundamentales.html#glosario",
    "href": "01-conceptos-fundamentales.html#glosario",
    "title": "1  Conceptos fundamentales",
    "section": "1.5 Glosario",
    "text": "1.5 Glosario\n\n\n\n\nButler, Christopher. 1985. Statistics in linguistics. Basil Blackwell."
  },
  {
    "objectID": "02-distribuciones-de-frecuencias.html",
    "href": "02-distribuciones-de-frecuencias.html",
    "title": "2  Distribuciones de frecuencias",
    "section": "",
    "text": "En este capítulo desarrollaremos el concepto de distribución estadística. Seguiremos desarrollando el ejemplo de notas de los exámenes finales de dos grupos de estudiantes e introduciremos otros ejemplos. Exploraremos el concepto de frecuencia de observaciones, cómo visualizarlos y estimar sus algunas de sus características."
  },
  {
    "objectID": "02-distribuciones-de-frecuencias.html#explorando-los-datos",
    "href": "02-distribuciones-de-frecuencias.html#explorando-los-datos",
    "title": "2  Distribuciones de frecuencias",
    "section": "2.1 Explorando los datos",
    "text": "2.1 Explorando los datos\nRecordemos las muestras de exámenes finales que vimos en el capitulo anterior.\nGrupo A (teórico-práctico):\n\n15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16 y 14\n\nGrupo B (teórico):\n\n11, 16, 14, 18, 6, 8, 9, 14, 12, 12, 10, 15, 12, 9, 13, 16, 17, 12, 8, 7, 15, 5, 14, 13, 13, 12, 11, 13, 11 y 7\n\nA simple vista no es tan fácil darse cuenta «qué pasa» con estos datos. Podemos por lo pronto darnos cuenta de que el grupo B tiene más notas de un solo dígito, pero más allá no resulta obvio cómo les fue en los distintos grupos."
  },
  {
    "objectID": "02-distribuciones-de-frecuencias.html#tablas-de-frecuencias",
    "href": "02-distribuciones-de-frecuencias.html#tablas-de-frecuencias",
    "title": "2  Distribuciones de frecuencias",
    "section": "2.2 Tablas de frecuencias",
    "text": "2.2 Tablas de frecuencias\nPara darnos cuenta mejor de las estructuras que estamos analizando podemos construir una tabla de frecuencias, que en este caso es un resumen de cuántos alumnos sacaron cuál nota de las posibles (sobre veinte).\n\n\n\n\nTabla 2.1: Frecuencia de notas por grupo\n\n\nNota\nGrupo A\nGrupo B\n\n\n\n\n1\n1\n2\n\n\n2\n2\n3\n\n\n3\n2\n5\n\n\n4\n3\n4\n\n\n5\n4\n3\n\n\n6\n6\n2\n\n\n7\n3\n2\n\n\n8\n4\n1\n\n\n9\n3\n1\n\n\n10\n2\n\n\n\n11\n\n1\n\n\n12\n\n1\n\n\n13\n\n2\n\n\n14\n\n2\n\n\n15\n\n1\n\n\n\n\n\n\nAhora podemos hacer algunas observaciones adicionales. Se nota que el rango (distancia entre el menor y el mayor valor del conjunto) es más amplio en el grupo B que en el grupo A. Posiblemente también nos damos cuenta que el valor más frecuente del grupo A (15) es superior al más frecuente del grupo B (12).\n\nEjemplo en R\nSi bien es posible hacer una tabla de frecuencias a mano, simplemente contando las observaciones en cada categoría y anotando el resultado en orden, también tenemos funciones en R para el propósito.\n\ntable(\n  c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14)\n)\n\n#> \n#>  9 11 12 13 14 15 16 17 18 19 \n#>  1  2  2  3  4  6  3  4  3  2\n\n\nEn este ejemplo estamos usando dos funciones, una dentro de otra. La función c, le pide a R que arme un cconjunto de datos, y los datos que queremos usar van entre paréntesis y separados por coma. Esto, a su vez, lo estamos haciendo dentro de la función table que genera una tabla de frecuencias.\nTambién es posible darle un nombre a los datos a usar o «asignarlos a una variable», lo cual puede ser útil cuando se quiere reutilizar. Esto se hace de la siguiente manera:\n\nx <- c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14)\n\nCon esto podemos usar x como alias para los datos que le asignamos. Entonces:\n\ntable(x)\n\n#> x\n#>  9 11 12 13 14 15 16 17 18 19 \n#>  1  2  2  3  4  6  3  4  3  2\n\n\nnos da el mismo resultado.\nPor lo general se recomienda usar nombres de variables que tengan algún sentido, en lugar de usar genéricos como x, y, z o a, b, c. En R las variables pueden tener múltiples caracteres (pero no espacios), por lo que podríamos ingresar:\n\ngrupo.A <- c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14)\n\ny nos daría el resultado deseado:\n\ntable(grupo.A)\n\n#> grupo.A\n#>  9 11 12 13 14 15 16 17 18 19 \n#>  1  2  2  3  4  6  3  4  3  2"
  },
  {
    "objectID": "02-distribuciones-de-frecuencias.html#sec-histogramas",
    "href": "02-distribuciones-de-frecuencias.html#sec-histogramas",
    "title": "2  Distribuciones de frecuencias",
    "section": "2.3 Histogramas",
    "text": "2.3 Histogramas\nPara seguir explorando las tablas que hemos creado en la sección anterior se pueden visualizar con un histograma. El histograma resume los datos dentro de algunos rangos, por ejemplo 8-9, 10-11, 12-13 etcétera, y se cuenta el número de observaciones dentro de cada rango.\nPara nuestros datos obtenemos:\n\n\n\n\n\ny\n\n\n\n\n\nComparando estos dos diagramas nos damos cuenta de que la estructura de los datos son disimilares. En el grupo A las notas se centran alrededor de quince, en cambio para el grupo B la concentración está en el rango diez-catorce, con un pico menor alrededor de siete.\n\n2.3.0.1 Ejemplo en R: Histograma\nHacer un histograma con R es bastante sencillo. Usamos la función hist, de histograma y los datos que queremos visualizar. Si lo asignamos a una variable, como lo vimos en la parte de las tablas (con table).\n\ngrupo.A <- c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14)\nhist(grupo.A)\n\n\n\n\nLa función hist tiene muchas opciones adicionales. Para conocerlas se puede ingresar ?hist (signo de interrogación y «hist») en la consola de R y aparecerá la descripción completa de ellas. Lo mismo es cierto para cualquier función de R. El mismo resultado se obtiene usando la función help(hist).\n\n\n2.3.0.2 Ejemplo en R: Histograma en ggplot\nUsando los paquetes de tidyverse podemos generar un histograma con el packete ggplot2. Se carga por default junto con muchos otros paquetes. A diferencia del ejemplo anterior la función espera un data.frame como argumento. Para generar un histograma con los mismos datos debemos entonces proceder con crear una estructura de data.frame primero y luego proceder.\n\nmy_data <- data.frame(\n  grupo.A = c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14)\n)\n\nNótese que usamos el operador = dentro de la definición del data.frame. Luego cargamos las funciones de tidyverse y procedemos a construir nuestro gráfico.\n\nlibrary(tidyverse) # Carga todos los paquetes, incluso ggplot2\nggplot(my_data, aes(x=grupo.A)) + \n  geom_histogram()\n\n\n\n\nvemos que si bien los datos son los mismos las columnas parecen separados. Esto se debe a que por defecto el geom_histogram distribuye los datos en 30 columnas, lo cual es demasiado para el caso que tenemos. Podemos arreglar esto agragando otro parametro a la función asi:\n\nggplot(my_data, aes(x=grupo.A)) + \n  geom_histogram(binwidth = 1)\n\n\n\n\nen este caso hemos especificado que el ancho de cada columna sea de 1, con lo cual se visualizan mejor estos datos.\n\n2.3.0.2.1 Agregando un poco de color\nPodemos también manipular los colores de las columnas con algunos parametros más:\n\nggplot(my_data, aes(x=grupo.A)) + \n  geom_histogram(binwidth = 1, fill=\"white\", color='red')\n\n\n\n\n\n2.3.0.3 El operador «pipe»\nEl uso de %>% es muy frecuente cuando uno trabaja con el tidyverse."
  },
  {
    "objectID": "02-distribuciones-de-frecuencias.html#polígono-de-frecuencias",
    "href": "02-distribuciones-de-frecuencias.html#polígono-de-frecuencias",
    "title": "2  Distribuciones de frecuencias",
    "section": "2.4 Polígono de frecuencias",
    "text": "2.4 Polígono de frecuencias\nLos datos también de pueden visualizar con un polígono de frecuencias. En este tipo de visualización ponemos un punto en la intersección de la nota (eje horizontal) y la frecuencia (eje vertical) y trazamos una linea entre los puntos. Una de las ventajas de este tipo de visualización es que facilita la comparación entre varias distribuciones ya que los podemos desplegar en un mismo diagrama.\n\n\n\n\n\nFigura 2.1: Polígono de frecuencias de notas obtenidas por dos grupos de estudiantes\n\n\n\n\nApreciamos con más precisión los valores más típicos y diferencias entre los dos grupos. También podemos ver que la parte inferior de la escala de notas está sin uso, característica que comparten ambos grupos.\n\nOtro ejemplo\nEn este ejemplo vamos a considerar un libro de la literatura romántica: «Persuasion» escrito por Jane Austen [Austen (1817)]1. Vamos a visualizar el número de caracteres por palabra en el texto. Obtenemos:\n\n\n\n\n\nFigura 2.2: Polígono de frecuencias del largo de palabras en un texto de Austin\n\n\n\n\nA differencia de la distribución de notas, vemos acá que encontramos observaciones a lo largo del rango de uno a deciseis, con la concentración de valores alrededor de tres. Esto tiene su interpretación bastante intuitiva ya que el uso de palabras cortas, como son artículos, preposiciones y conjunciones abundan en cuanquier texto y las palabras muy largas son de uso menos frecuente. Resulta lógico suponer que encontraríamos un perfil similar en cualquier texto de cierta longitud."
  },
  {
    "objectID": "02-distribuciones-de-frecuencias.html#sec-perfil-de-la-distribucion",
    "href": "02-distribuciones-de-frecuencias.html#sec-perfil-de-la-distribucion",
    "title": "2  Distribuciones de frecuencias",
    "section": "2.5 Perfil de la distribución",
    "text": "2.5 Perfil de la distribución\nLas distribuciones de notas que vimos en las secciones anteriores tienen relativamente pocos datos, por lo que siempre van a parecer algo irregulares. Si tenemos muchos datos, sobre todo si con se escala de medición continua, podemos imaginarnos que en lugar de trazar una linea llegamos a trazar más bien una curva entre los puntos. Esto nos permite hacer una abstracción de las distribuciones y hablar de distribuciones teóricas. La más conocida de ellas sin duda es la distribución normal, también llamada de Gauss o gaussiana.\n\n\n\n\n\nDistribución normal\n\n\n\n\nVamos a desarrollar el tema de la distribución normal con más detalle en el capítulo 4. Por ahora simplemente vamos a considerar si los datos de nuestras muestras se asemejan a ésta o si tiene otro perfil.\n\n2.5.1 Asimetría o Sesgo\nCuando una distribución se inclina en una dirección u otra decimos, es decir que no es simétrica, se dice que tiene un sesgo o que es asimétrica. Se habla de sesgo negativo y sesgo positivo (también: asimetría positiva/negativa y a la izquierda/derecha todos equivalentes). Es positivo o negativo según en qué dirección tiene su cola larga.\n\n\n\n\n\nDistribuciónes normal y sesgadas\n\n\n\n\nVemos que nuestras distribuciones de notas corresponden a una distribución de sesgo negativo, ya que hay menos notas en la parte inferior de la escala que en la parte superior. En cambio, la distribución de número de characteres en el texto de Austen tiene sesgo positivo.\n\n\n\n\n\nFigura 2.3: Polígonos de frecuencias\n\n\n\n\nNótese también que la si bien la escala vertical de los dos gráficos son de muy diferente magnitud, la máxima frecuencia es veinte mil (20.000) y seis (6) respectivamente, podemos comparar las dos distribuciones."
  },
  {
    "objectID": "02-distribuciones-de-frecuencias.html#glosario",
    "href": "02-distribuciones-de-frecuencias.html#glosario",
    "title": "2  Distribuciones de frecuencias",
    "section": "2.6 Glosario",
    "text": "2.6 Glosario\n\nAsimetría\n\nEl hecho de que una distribución no sea simétrica. Equivalente en inglés: «Skew».\n\nDistribución normal\n\nDistribución teórica de una variable. Es simétrica y con forma de campana. Equivalente en inglés: «Normal distribution».\n\nHistograma\n\nVisualización de frecuencia agrupadas de observaciones de una variable. Función relevante en R: hist. Equivalente en inglés: «Histogram».\n\nPolígono de frecuencias\n\nVisualización de frecuencias de observaciones de una variable. Equivalente en inglés: «Frequency poligon».\n\nSegso\n\nEl hecho de que una distribución no sea simétrica. Equivalente en inglés: «Skew».\n\nTable de frecuencias\n\nTabla que resume las frecuencias de las observaciones de una variable. Función relevante en R: table. Equivalente en inglés: «Frequency table».\n\n\n\n\n\n\nAusten, Jane. 1817. Persuasion. John Murray.\n\n\nSilge, Julia, y David Robinson. 2016. «tidytext: Text Mining and Analysis Using Tidy Data Principles in R». JOSS 1 (3). https://doi.org/10.21105/joss.00037."
  },
  {
    "objectID": "03-tendencia-central-y-variabilidad.html",
    "href": "03-tendencia-central-y-variabilidad.html",
    "title": "3  Centralización y dispersión",
    "section": "",
    "text": "En el capítulo 2 vimos que resumir los datos y generar visualizaciones nos permite entender mejor la estructura y algunas propiedades de un conjunto de datos, como son sus vales más frecuentes y rango de observaciones. En este capítulo desarrollaremos algunas medidas cuantitativas más precisas de estas propiedades. Específicamente desarrollaremos medidas de centralización o tendencia central y dispersión."
  },
  {
    "objectID": "03-tendencia-central-y-variabilidad.html#centralización",
    "href": "03-tendencia-central-y-variabilidad.html#centralización",
    "title": "3  Centralización y dispersión",
    "section": "3.1 Centralización",
    "text": "3.1 Centralización\nLa centralización o tendencia central de un conjunto de datos es uno o un número reducido de valores que representan todo el conjunto.\nExisten tres medidas de centralicación: la media, la mediana y la moda. A continuación las vamos a definir y ver cómo se calculan y luego vamos a considerar cuándo se debe usar cada una de ellas.\n\n3.1.1 La media\nLa media es seguramente la medida de centralización de uso más frecuente 1. Se conoce también como el promedio y, más técnicamente, la media arithmetica. La media se obtiene por la suma de las observaciones dividido por el número de observaciones. Por ejemplo si queremos sacar el promedio de seis observaciones de una variable: 15, 12, 11, 18, 15 y 15; tenemos:\n\\[\n{{15 + 12 + 11 + 18 + 15 + 15}\\over{6}}={86\\over6}=14,33\n\\tag{3.1}\\]\nEn el caso de nuestra muestra de notas para de capítulos anteriores tenemos:\n\\[\n{{ 15 + 12 + 11 + 18 + 15 + 15+ \\\\\n  9 + 19 + 14 + 13 + 11 + 12 + \\\\\n  18 + 15 + 16 + 14 + 16 + 17 + \\\\\n  15 + 17 + 13 + 14 + 13 + 15 + \\\\\n  17 + 19 + 17 + 18 + 16 + 14}\\over{30}}={448\\over30}=14.93\n\\tag{3.2}\\]\nYa con el cómputo en Ecuación 3.2 nos damos cuenta de que si bien es posible hacer estos cálculos a mano puede resultar bastante engorroso. Además con tantos números dando vuelta sube la probabilidad de un error de tipeo y con lo cual sacaríamos un resultado incorrecto.\n\nEjemplo 3.1 (La media) Por suerte es bastante sencillo sacar la media con R. Para los dos ejemplos anteriores tenemos:\n\nx = c(15, 12, 11, 18, 15 , 15)\nmean(x)\n\n#> [1] 14.33333\n\n\ny\n\nnotas = c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, \n           15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, \n           17, 18, 16, 14)\nmean(notas)\n\n#> [1] 14.93333\n\n\n\n\nNotación matemática\nEn textos de matemática y estadística se usa con frecuencia llaves para significar un conjunto, de modo que los datos del primer conjunto se expresaría así: x = {15, 12, 11, 18, 15 , 15}.\nUna notación compacta para significar la suma de las observaciones en una variable es \\(\\Sigma\\): la letra griega sigma, en mayúscula.\nPara significar el número de observaciones de usa N, de número.\nAsí se puede definir la media de manera compacta así:\n\\[\n{\\Sigma{x}}\\over{N}\n\\]\nTambién se usa una barra vertical sobre el nombre de la variable para significar la media (o promedio aritmético): por ejemplo: \\[\\bar{x} = 14,33\\]\nEntonces en general tenemos:\n\nDefinición 3.1 (La media) \\[\n\\bar{x} = {\\Sigma{x}\\over{N}}\n\\]\n\nque se podría leer: «la media de equis es igual a la suma de las observaciones de equis sobre el número de observaciones».\n\n\n\n3.1.2 La mediana\nOtra medida de centralización es la mediana (también: valor mediano). Para obtenerla ponemos nuestros datos en orden ascendiente y sacamos el valor que está justo en la mitad. Por ejemplo: si queremos sacar la mediana de {15, 12, 11, 18, 15, 15, 9}, primero los ordenamos: {9, 11, 12, 15, 15 ,15, 18}. Vemos que hay siete observaciones con lo cual la mediana es la observación que está en cuarta posición, es decir que la mediana de estos datos es 15. Si el conjunto de datos tiene un número par de observaciones, no va a haber una observación justo en el medio. En ese caso se toman los dos valores del medio, se los suma y se divide por dos. Por ejemplo: {8, 8, 9, 11, 12, 15, 15 ,15}. Acá tenemos ocho observaciones (ya ordenados) tomamos los dos valores de la posición cuarta y quinta, los sumamos y dividimos por dos: \\({11+12\\over2}=11,5\\).\n\nNotación matemática\nEl valor mediano, o la mediana, se denota en notación matemática con una tilde como la que se usa en la letra ñ en español. Al igual que la barra para la media, se coloca por encima de la variable, así: \\[\\huge{\\tilde{x}}\\].\n\nEjemplo 3.2 (La mediana) \nPodemos sacar la mediana de forma sencilla con R con la función median.\n\nx = c(9, 11, 12, 15, 15 ,15, 18)\nmedian(x)\n\n#> [1] 15\n\n\ny\n\nx = c(8, 8, 9, 11, 12, 15, 15 ,15)\nmedian(x)\n\n#> [1] 11.5\n\n\n\n\n\n\n3.1.3 La moda\nLa moda es la observación más frecuente del conjunto. Por ejemplo: {9, 11, 12, 15, 15 ,15, 18}. El valor 15 es la moda de estos datos.\nA diferencia de las otras medidas de centralidad la moda no necesariamente es un valor único. Si tuviéramos por ejemplo: {2, 4, 5, 7, 7, 7, 9, 11, 12, 15, 15, 15, 18} hay dos valores con la misma frecuencia máxima. Tanto 7 como 15 aparecen tres veces. En este caso hay dos modas y hablamos de una distribución bimodal.\nVemos un ejemplo en el gráfico que sigue.\n\n\n\n\n\n\n\n3.1.4 ¿Cuál usar?\nLa selección de una medida de centralización depende de varios factores:\n\nLa escala de medición de la variable (nominal, ordinal, de intervalo o de razón)\nLa forma de la distribución - si hay sesgo o no\nPara qué vamos a usar la medida.\n\nLa media debería usarse solo para variables de escala de intervalo o de razón. Si los datos son ordenables, pero sin que se pueda hablar de distancias reales entre los datos la mediana es más apropiada. Y en los casos donde ni esto es posible la moda puede ser la única medida disponible. Por ejemplo: si decimos que Italia es un país católico estamos expresando la moda de la variable nominal «religión», y si decimos que Alemania es un país católico y protestante estamos expresando una distribución bimodal de la misma variable. Podemos observar en el gráfico que en realidad se podría hablar incluso de una distribución trimodal.\n\n\n\n\n\nReligión en Alemania\n\n\n\n\nEn cuanto a la forma de la distribución se favorece la mediana por sobre la media si la distribución es muy sesgada. Esto ocurre sobre todo si hay valores extremos o atípicos. Por ejemplo si tenemos los datos: {15, 12, 11, 18, 15, 15, 200} está claro que si calculamos la media el valor extremo (200) va influir mucho más que cualquier otra observación. En este caso la media es 40,85 y el mediano 15. El primer valor (40,85) no es muy representativo de la muestra ya que no corresponde a ninguna observación y está lejos de cualquiera de ellas. El mediano, en cambio, puede resultar una mejor medida en este caso.\n\n\n\n\n\nMedidas de centralización en una distribución con sesgo positivo\n\n\n\n\nPara darnos cuenta de cuál de las medidas puede ser la más adecuada si tenemos datos por lo menos numéricos podemos sacar las tres medidas y ver qué tanto de asemejan unas a otras. Hay que tener en mente que cualiér distribución de datos reales va a tener un sesgo, la distribución perfectamente normal solo existe en teoría. Entonces debemos fijarnos si el sesgo que tenemos justifica el uso de una medida en espeficia. Por ejemplo, para nuestros datos de notas de dos grupos tenemos:\n\nGrupo A\n\nMedia: 14,93\nMediana: 15\nModa: 15\n\nGrupo B:\n\nMedia: 11,76\n\nMediana: 12\n\nModa: 12\n\n\nVemos que hay muy poca diferencia entre las tres medidas por lo cual vamos a concluir que el sesgo observado no es lo suficientemente fuerte como para justificar el uso de otra medida que la media."
  },
  {
    "objectID": "03-tendencia-central-y-variabilidad.html#medidas-de-dispersión",
    "href": "03-tendencia-central-y-variabilidad.html#medidas-de-dispersión",
    "title": "3  Centralización y dispersión",
    "section": "3.2 Medidas de dispersión",
    "text": "3.2 Medidas de dispersión\nEn la sección anterior desarrollamos varias medidas de centralización y cuál eligir para describir el valor «más típico» de los datos. Cuando calculamos medidas de dispersión estamos contestando la pregunta: ¿cuán típico es este valor?\nCuando tratamos con variables nominales, como el ejemplo de religión en Alemania de la sección anterior, lo mejor que podemos hacer el indicar la proporción o porcentaje2, pero si los datos son de alguna escala ya numérica tenemos algunas posibilidades que nos permiten más exactitud.\n\n3.2.1 Rango o amplitud\nEl rango de un conjunto de datos son dos números: el valor mínimo y el valor máximo. Por ejemplo el conjunto de datos {9, 11, 12, 15, 15 ,15, 18} tiene un rango 9 a 18; y el conjunto {2, 4, 5, 7, 7, 7, 9, 11, 12, 15, 15 ,15, 18} tiene un rango de 2 a 18.\nEn castellano se usa con alguna frecuencia también el término amplitud como equivalente a rango.\n\nPara sacar el rango de un conjunto de datos en R podemos usar la función range. Así:\n\nx = c(2, 4, 5, 7, 7, 7, 9, 11, 12, 15, 15 ,15, 18)\nrange(x)\n\n#> [1]  2 18\n\n\n\n\n\n3.2.2 El rango intercuartílico\nOtra medida de dispersión que tenemos a disposición es el rango intercuartílico o rango intercuartíl. Para calcularlo dividimos las observaciones en cuatro partes iguales y sacamos los valores de cada corte. Esto nos da cinco valores3, le los cuales el rango intercuartílico es la diferencia entre el segundo y el cuarto. Este sería el rango de las observaciones del 50% de los datos que se encuentran más cerca la mediana del mismo.\n\n\n\n\n\nCuartiles y rangos\n\n\n\n\nEl rango intercuartílico da una idea de la dispersión de los datos y es por su naturaleza menos sensitivo a valores extremos.\n\nEjemplo 3.3 (Sacar el rango intercuartílico en R) Para sacar en rango intercuartílico podemos usar la función quantiles. Por defecto divide la distribución en cuartiles.\n\nx = c(2, 4, 5, 7, 7, 7, 9, 11, 12, 15, 15 ,15, 18)\nquantile(x)\n\n#>   0%  25%  50%  75% 100% \n#>    2    7    9   15   18\n\n\n\nVemos que en este caso el rango intercuartíl es 7 y 15, que da una amplitúd de 8 ya que \\(15 - 7 = 8\\).\n\n\n3.2.3 La varianza y desviación estándar\nLa medida de dispersión más usada en estadística es la desviación estándar, también conocida como desviación típica. Esta medida tiene una relación matemática muy estrecha con la varianza que tiene usos menos frecuentes. Ambas medidas tienen propiedades que los hacen útiles para otras técnicas estadísticas.\nPara calcular la desviación estándar debemos primero calcular la varianza. Para ello tomamos la diferencia de cada observación de la media. Recordemos que la media se expresa con \\(\\bar{x}\\) (equis con barra). Entonces la diferencia entre una observación de x y la media es \\(x - \\bar{x}\\). Luego los llevamos al cuadrado \\((x - \\bar{x})^2\\) los sumamos y dividimos por el número total de observaciones. Para expresarlo usamos la notación que ya vimos. Entonces \\(\\Sigma\\) es «la suma de» y N es «el total de las observaciones». Juntando todo tenemos:\n\nDefinición 3.2 (Varianza) \n\\[\n\\text{varianza} = {{\\Sigma (x - \\bar{x})^2}\\over{N}}\n\\]\n\nAhora para sacar la desviación estándar tomamos la raíz cuadrada de la varianza. La desviación estándar de la población se representa por la letra griega \\(\\sigma\\) que es sigma pero en minúscula. Entonces tenemos:\n\nDefinición 3.3 (Desviación estándar de la población) \\[\n\\sigma = {\\sqrt{{\\Sigma (x - \\bar{x})^2}\\over{N}}}\n\\]\n\nSi estamos trabajando con una muestra en lugar de la población completa, que es el caso más común cuando trabajamos con estadísticas se usa la letra «s». También se hace un ajuste en el denominador de la fórmula ya que se ha comprobado que sin el ajuste la medida puede resultar sesgada si la muestra tiene pocas observaciones. La formula para una muestra es:\n\nDefinición 3.4 (Desviación estándar de la muestra) \\[\ns = {\\sqrt{{\\Sigma (x - \\bar{x})^2}\\over{N-1}}}\n\\]\n\nFinalmente. Ya que s y \\(\\sigma\\) son la raíz cuadrada de la varianza, esta también se denomina por las mismas letras, pero llevado al cuadrado: \\(s^2\\) y \\(\\sigma^2\\)\nPor suerte es sencillo sacar tanto la varianza como la desviación estándar en R. Usamos las funciones var y sd4.\n\nx = c(2, 4, 5, 7, 7, 7, 9, 11, 12, 15, 15 ,15, 18)\nvar(x)\n\n#> [1] 24.69231\n\nsd(x)\n\n#> [1] 4.969136\n\n\n\n¿Por qué se prefiere la desviación estándar?\nHay varios motivos más bien técnicos por los que se prefiere la desviación estándar por sobre la varianza. Sin embargo tiene también algunas ventajas bastante práctica e incluso intuitivas. Una de las más importantes es que la dispersión se expresa en la misma unidad que los datos. Para profundizar esto vemos un ejemplo. Los salarios de una PYME son: $14.000, $14.000, $14.000, $16.000, $17.000, $18.000, $26.000 y $35.000. La media de estos es 19,250, y la desviación estándar es: 7,497. La interpretación de la desviación estándar en este caso es que los salarios en promedio tiene una diferencia de $7,497 (por arriba o abajo) del salario medio de $19,250.\n\n\n\n3.2.4 Visualizar la dispersión\nPuede resultar útil visualizar la dispersión de un conjunto de datos. Esto se logra con un diagrama de caja (box-plot). Vemos un ejemplo de ello en la figura 3.1.\n\n\n\n\n\nFigura 3.1: Ejemplo de box-plot\n\n\n\n\nEn este tipo de visualización la mediana está representada por la linea horizontal más gruesa, la caja corresponde al rango intercuartíl y los extremos de la linea horizontal representan el rango de los datos. Lo podemos apreciar en la figura @(ref:box-plot-with-explanation)\n\n\n\n\n\nEjemplo de box-plot con explicaciones\n\n\n\n\n\nEjemplo 3.4 (Boxplot) La función boxplot nos permite generar un boxplot en R.\n\nnotas = c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, \n           15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, \n           17, 18, 16, 14)\nboxplot(notas)"
  },
  {
    "objectID": "03-tendencia-central-y-variabilidad.html#glosario",
    "href": "03-tendencia-central-y-variabilidad.html#glosario",
    "title": "3  Centralización y dispersión",
    "section": "3.3 Glosario",
    "text": "3.3 Glosario\n\nAmplitud\n\nLa diferencia entre la mínima y la máxima de una variable. También se llama rango Función relevante en R: range. Equivalente en inglés: «Range».\n\nCentralización\n\nEl hecho de que una variable puede describirse por uno o más valores. También se llama tendiencia central. Equivalente en inglés: «Central tendency».\n\nDesviación estándar (de la muestra).\n\nMedia de la diferencia entre la media y todas las observaciones de la muestra. Fórmula: \\(s = {{\\sqrt{ \\Sigma (x - \\bar{x})^2}\\over{N}} }\\) Función relevante en R: sd. Equivalente en inglés: «Standard deviation».\n\nDesviación estándar (de la población).\n\nMedia de la diferencia entre la media y todas las observaciones de la población. Fórmula: \\(\\sigma = {{\\sqrt{ \\Sigma (x - \\bar{x})^2}\\over{N}} }\\) Función relevante en R: sd. Equivalente en inglés: «Standard deviation (of the population)».\n\nDesviación típica\n\nVer desviación estándar. Equivalente en inglés: «Standard deviation».\n\nMedia\n\nLa suma de las observaciónes de una variable dividido por el número de las observaciones. También se conoce como la media aritmética. Fórmula: \\(\\bar{x} = {\\Sigma{x}\\over{N}}\\) Función relevante en R: mean. Equivalente en inglés: «Mean».\n\nMediana\n\nEl la observación de una variable que está justo en el medio cuando los valores están ordenados. Función relevante en R: median. Equivalente en inglés: «Median».\n\nModa\n\nEl valor más frecuente de la observaciones de una variable. Equivalente en inglés: «Mode».\n\nRango\n\nLa diferencia entre la mínima y la máxima de una variable. También se llama amplitud Función relevante en R: range. Equivalente en inglés: «Range».\n\nRango intercuartílico\n\nRango dentro del cual se encuentras en 50% más centralizado de las variables. Función relevante en R: quantile. Equivalente en inglés: «Interquartile range (IQR)».\n\nVarianza\n\nMedia de la diferencia cuadrada entre la media y todas las observaciones. Fórmula: \\(\\sigma^2 = {{\\Sigma (x - \\bar{x})^2}\\over{N}}\\) Función relevante en R: var. Equivalente en inglés: «Variance»."
  },
  {
    "objectID": "04-la-distribucion-normal.html",
    "href": "04-la-distribucion-normal.html",
    "title": "4  La distribución normal",
    "section": "",
    "text": "En el Capítulo 2 tocamos brevemente la llamada distribución normal. En este capítulo vamos a desarrollar con más detalle esta distribución, fundamental para muchas técnicas estadísticas y cuantitativas."
  },
  {
    "objectID": "04-la-distribucion-normal.html#importancia-de-la-distribución-normal",
    "href": "04-la-distribucion-normal.html#importancia-de-la-distribución-normal",
    "title": "4  La distribución normal",
    "section": "4.1 Importancia de la distribución normal",
    "text": "4.1 Importancia de la distribución normal\nComo vimos en la sección 2.5, si tenemos muchos datos y construimos un polígono de frecuencias, es posible trazar una curva entre los puntos de la distribución. También mencionamos que la llamada distribución normal es de particular interés para trabajo estadístico y cuantitativo. Hay varios razones de ello:\n\nMuchos fenómenos que podemos medir tanto en las ciencias exactas como las sociales de asemejan en su frecuencia a esta distribución.\nLa distribución normal tiene ciertas propiedades matemáticas que nos permiten predecir qué proporción de la población (estadística) caerá dentro de cierto rango si la variable tiene distribución normal.\nVarios tests de significanza de diferencia entre conjuntos de datos presumen que los datos del conjunto tiene una distribución normal."
  },
  {
    "objectID": "04-la-distribucion-normal.html#propiedades-de-la-curva-normal",
    "href": "04-la-distribucion-normal.html#propiedades-de-la-curva-normal",
    "title": "4  La distribución normal",
    "section": "4.2 Propiedades de la curva normal",
    "text": "4.2 Propiedades de la curva normal\nComo ya vimos, la curva normal tiene forma de campana y es simétrica. Por ende, las tres medidas de centralización la media, la mediana y la moda coinciden en el punto superior de la curva, como lo podemos apreciar en la Figura 4.1.\n\n\n\n\n\nFigura 4.1: Curva normal\n\n\n\n\nCiertas propiedades importantes de esta curva se relacionan con la manera en que el área debajo de la curva de puede seccionar con lineas verticales con origen en distintos puntos del eje horizontal. Para explorar estas vamos a considerar algunos histogramas, el tipo de visualización que vimos en la sección 2.3. El alto de cada barra es proporcional a la frecuencia de observaciones y como el ancho de las barras es el mismo en todos los casos el área de cada barra también es proporcional a la frecuencia de observaciones. El ancho puede representar una sola unidad, o varias si agrupamos, por ejemplo por rango etario como lo vemos en la figura 4.2, en el que hemos sacado una muestra aleatoria de mil observaciones de un test de matemáticas a nivel nacional. Los hemos agrupado por rangos de diez, es decir de 0 a 10, de 10 a 20 y así sucesivamente. Hemos sobrepuesto una curva normal teórica para apreciar hasta qué punto se asemeja la distribución observada a la teórica.\n\n\n\n\n\nFigura 4.2: Muestra de notas de un test de matemática (N=1000)\n\n\n\n\nAhora, bien, si en lugar de agrupar las notas en grupos de diez1 los podemos también agregar en grupos de cinco. Entonces obtenemos un histograma como el de la figura Figura 4.3 .\n\n\n\n\n\nFigura 4.3: Muestra de notas de un test de matemática (N=1000)\n\n\n\n\nPodemos seguir achicando el ancho de las barras, y vemos que si bien el histograma es puntudo mientras menos anchas son las barras más se aproxima a la curva. En la Figura 4.4 hemos achicado las barras para que cada una represente tan solo un valor entero, es decir tan solo una de las cien notas posibles. Se entiende que es posible seguir con más precisión si, por ejemplo, el examen fue calificado con la posibilidad de asignar notas con decimales.\n\n\n\n\n\nFigura 4.4: Muestra de notas de un test de matemática (N=1000)\n\n\n\n\nLa curva normal de define por dos propiedades: La media y la desviación estándar. Si conocemos estos dos valores es posible construir la curva aplicando una fórmula 2 un tanto compleja y con poca importancia fuera del ámbito plenamente teórico.\nDe más importancia son algunas propiedades que tiene la curva. Si graficamos la curva normal y expresamos los valores en el eje horizontal en desviaciones estándares (también se dice «sigmas» por su letra griega \\(\\sigma\\)), el área que está de cada lado de la linea es constante y conocido. Si trazamos una linea justo en el medio (\\(\\sigma=0\\)), sabemos que un 50% de las observaciones están a la derecha y la izquierda de esa linea. Lo mismo aplica a una distribución expresado en un histograma. En la fig-normal-curve-with-cuts vemos cuales son los cortes para desviaciones estándares de menos 3 a 3.\n\n\n\n\n\nFigura 4.5: Área debajo de la curva normal\n\n\n\n\nEsta propiedad es de bastante utilidad y se puede aprovechar de varias maneras. Si tenemos una muestra de datos cuya distribución presumimos normal (en el Sección 7.2 vamos a desarrollar cómo lo podemos determinar) ya sabemos que más o menos el 68% de las observaciones va estar dentro de ± una desviación estándar de la media y más del 95% se encontrará dentro de dos desviaciones. Por último el 99% de las observaciones de encuentran dentro de tres desviaciones estándares de la media. A veces se refiere a esta propiedad como la regla empírica o la regla de de 68-95-99,7.\n\nVariables normalizadas\nEn textos de estadística frecuentemente se habla de variable normalizada, también se conoce como unidad tipificada, variable centrada reducida o variable estandarizada. Normalizar una variable es simplemente expresar su magnitud en unidades de desviación estándar. Para lograr ello tomamos la variable, restamos la media y dividimos por la desviación estándar. En literatura en inglés es de uso frecuente el término «z-score», por lo que su definición formal (véase @def-definition-z-score)) lleva esta letra.\n\nDefinición 4.1 (Variable normalizada) La variable normalizada z de un conjunto de datos X se obtiene por la fórmula siguiente:\n\\[\n  z = {x-\\bar{x}\\over{\\sigma}}\n\\]\ndonde:\n\nz: la variable normalizada\nx: una observación de X\n\\(\\bar{x}\\): la media de las observaciones\n\\(\\sigma\\) o s: la desviación estándar de la población o muestra respectivamente.\n\n\nEs importante entender que normalizar una variable no cambia su valor, solo su unidad de cuenta: El lo mismo comprar medio kilo de queso que comprar quinientos gramos.\nNormalizar las variables nos permite comparar su distribución independientemente de su unidad de cuenta y amplitud, también nos permite sacar conclusiones sobre probabilidades y proporciones. Vamos a desarrollar esta idea por medio de un ejemplo.\n\nEjemplo 4.1 (Analizando datos del ministerio de salud) En el 2007 el Ministerio de Salud de Argentina realizó un estudio (ENNyS 2007) que entre otras recopiló datos sobre la estatura de las argentinas entre 19 y 49 años. La media fue de 161,01 centímetros con una desviación estándar de 6,99. Con estos datos podemos construir nuestra curva.\n\n\n\n\n\nFigura 4.6: Estatura de argentinas entre 19 y 49 años\n\n\n\n\nAhora, sabiendo que esta variable tiene una distribución normal podemos saber que casi el 70% de las argentinas miden entre 154,04 y 168 centímetros. También podemos encontrar respuesta a una pregunta como: ¿qué proporción de la población femenina mide más que 175 centímetros? Para ello tenemos que normalizar el dato así:\n\\[\nz = {175 - 161,01\\over{6.99}} = {13,99\\over{6.99}} = 2,001\n\\]\nCon este número podemos volver a la @fig-normal-curve-with-cuts y fijarnos que con por arriba de 2 desviaciones estándar (o 2\\(\\sigma\\)) está el 2,2% de la población. Es el área indicado en rojo en la figura @fig-curva-con-segmento.\n\n#| label: fig-curva-con-segmento\n#| echo: false\n#| fig-cap: \"Proporción de argentinas que miden más de 175 centímetros\"\n\n\nplot_estatura+\n  geom_area(position = \"identity\", data = estatura %>% filter(x>175), fill='red')\n\n\n\n\n\nEn este caso tuvimos un poco se suerte ya que la variable normalizada resultó un número redondo que era fácil encontrar en la figura Figura 4.5. Ahora digamos que queremos conocer la proporción de la población que mide menos de 150 centímetros, ¿cómo hacemos? Primero normalizamos:\n\\[\nz = {150 - 161,01\\over{6.99}} = {11,01\\over{6.99}} = -1,575\n\\]\nCon este número podemos sacar la proporción por ejemplo calculando el área debajo del segmento de la curva con cálculos integrales, lo podemos buscar en una tabla de probabilidades o podemos recurrir a la función pnorm (p: probabilidad, norm: normal)de R así:\n\npnorm(-1.575)\n\n#> [1] 0.05762822\n\n\nentonces el 5,76% de la población de argentinas entre 19 y 49 años miden menos de un metro con cincuenta.\nTambién podemos expresar esto en términos de probabilidades: Si medimos una mujer argentina de entre 19 y 49 años seleccionada aleatoriamente de la población, la probabilidad de que mida menos de 150 centímetros es de 5,76% (p=0,0576)."
  },
  {
    "objectID": "04-la-distribucion-normal.html#sec-evaluar-la-normalidad",
    "href": "04-la-distribucion-normal.html#sec-evaluar-la-normalidad",
    "title": "4  La distribución normal",
    "section": "4.3 Evaluar la normalidad",
    "text": "4.3 Evaluar la normalidad\nHemos visto que el hecho de que una variable tenga una distribución normal nos resulta muy útil para extraer información sobre sus propiedades. También nos permite realizar algunos tests estadísticos que veremos en capítulos posteriores.\nEn la [sección @sec-cual-usar] decidimos usar la media como medida de centralización porque las tres medidas disponibles –media, mediana y moda– se aproximaban unas a otras. Si queremos saber si una variable se aproxima a la curva normal podemos generar un histograma y sobreponer una curva normal. Así podemos sacar alguna conclusión inspeccionando el gráfico.\nTambién podemos valernos del conocimiento de la proporción de observaciones que deben estar dentro de la primera y segunda desviación estándar y verificar si nuestros datos se conforman con estas predicciones.\n\nEjemplo 4.2 (Notas de dos cursos) \nSi tomamos nuestros datos de las notas de nuestros dos cursos que vimos en la sección 1.3 y que fuimos desarrollando a lo largo de los capítulos anteriores podemos realizar este análisis.\nGrupo A: {15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14}\nGrupo B: {11, 16, 14, 18, 6, 8, 9, 14, 12, 12, 10, 15, 12, 9, 13, 16, 17, 12, 8, 7, 15, 5, 14, 13, 13, 12, 11, 13, 11, 7}\n\nGrupo A:\n\nMedia: 14.93\nDesviación estándar: 2,49\nEntre \\(\\pm{1}\\) desviación: 66%\nEntre \\(\\pm{2}\\) desviaciones: 96%\n\nGrupo B:\n\nMedia: 11,76\nDesviación estándar: 3,31\nEntre \\(\\pm{1}\\) desviación: 66%\nEntre \\(\\pm{2}\\) desviaciones: 96%\n\n\nObservamos que nuestras notas carecen en cierta medida de valores extremos, sin embargo la muestra es relativamente pequeña con lo cual nos conformamos con estos resultados y consideramos normales las distribuciones.\n\n\nEjemplo 4.3 (Ejemplo en R) \nSi no queremos hacer estos cálculos a mano los podemos hacer también en R, así:\n\ngrupo.A = c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14)\n\nmedia= mean(grupo.A)\ndesviacion = sd(grupo.A)\nN = 30\nsum( \n    grupo.A <  media + desviacion \n    &\n    grupo.A > media - desviacion  \n)/N\n\n#> [1] 0.6666667\n\nsum( \n    grupo.A <  media + desviacion * 2\n    &\n    grupo.A > media - desviacion  * 2\n)/N\n\n#> [1] 0.9666667\n\n\n\nExisten también tests más formales de normalidad que desarrollaremos en capítulos posteriores."
  },
  {
    "objectID": "04-la-distribucion-normal.html#glosario",
    "href": "04-la-distribucion-normal.html#glosario",
    "title": "4  La distribución normal",
    "section": "4.4 Glosario",
    "text": "4.4 Glosario\n\nRegla empírica\n\nCuando la distribución es normal el 68% de las observaciones se encuentran entre \\(\\pm\\) una desviación estándar de la media, el 95% entre dos desviaciones estándar y el 99,7% entre tres. Equivalente en inglés: «Empirical rule».\n\nVariable normalizada\n\nVariable expresada en desviaciones estándar Fórmula: \\(z = {x-\\bar{x}\\over{\\sigma}}\\) o \\(z = {x-\\bar{x}\\over{s}}\\) Función relevante en R: scale. Equivalente en inglés: «z-score».\n\n\n\n\n\n\nENNyS. 2007. «Encuesta Nacional de Nutrición y Salud.» Ministerio de Salud de Argentina."
  },
  {
    "objectID": "05-parametros-de-poblacion-y-muestra.html",
    "href": "05-parametros-de-poblacion-y-muestra.html",
    "title": "5  Estimación de parámetros",
    "section": "",
    "text": "Hemos visto que si trabajamos con poblaciones que son potencialmente infinitas o muy grandes usamos muestras para nuestro trabajo cuantitativo. Las medidas que calculamos en base a estas muestras son estimativos de los parámetros de la población. Si tenemos una muestra de estatura de argentinas entre 19 y 49 años de edad, como la que vimos en el ejemplo 4.1, no sabemos con certeza cuál es la media de la población. La estimamos en base a una muestra. Con ello no podemos afirmar que la media es la misma para la población, de hecho ignoramos cuál es la media de la población. Lo que sí podemos calcular un intervalo de valores dentro de los cuales tenemos cierta confianza de que nuestro valor estimativo sea correcto para la población.\nEn este capítulo desarrollaremos las técnicas que se utilizan para arribar a estos intervalos de confianza y calcular un margen de error."
  },
  {
    "objectID": "05-parametros-de-poblacion-y-muestra.html#distribución-muestral",
    "href": "05-parametros-de-poblacion-y-muestra.html#distribución-muestral",
    "title": "5  Estimación de parámetros",
    "section": "5.1 Distribución muestral",
    "text": "5.1 Distribución muestral\nSi suponemos que la estatura promedio de las argentinas entre 19 y 49 años es de 161 centímetros con una desviación estándar de 6,99, estos serían los parámetros de la población. Si sacamos cinco muestras aleatorias de veinte observaciones de esta población van a arrojar resultados distintos a estos valores. Algunas muestras van a tener una media por arriba de la media real y otras van a tener una media por debajo.\n\n\nEjemplo 5.1 (Distribucion de muestras) \n\n\n\n\nFigura 5.1: Cinco Muestras de 20 obseraciones\n\n\n\n\n\nComo lo podemos observar en la figura Figura 5.1 la distribución de las muestras es simétrica y normal. La media de nuestras muestras es 161,42; ligeramente por arriba de la media real, y la desviación estándar es de 6,17; más de medio centímetro por debajo de la desviación estándar de la población. La distribución muestral tiene algunas propiedades que son útiles para nuestro trabajo estadístico:\n\nSe aproxima a una distribución normal. Esto se conoce como el teorema del límite central.\nLa media de la distribución es igual (o casi igual) a la media de la población.\nLa dispersión es menor a la de la población general.\n\nEl número (3) de la lista tiene su lógica ya que en una muestra aleatoria un valor frecuente tiene más probabilidad de ser seleccionada que un valor extremo. La diferencia entre curva normal de la población y la curva de la distribución muestral está ilustrada en la figura 5.2.\n\n\n\n\n\nFigura 5.2: Distribución de la población y la muestra"
  },
  {
    "objectID": "05-parametros-de-poblacion-y-muestra.html#sec-el-error-estandar-y-su-interpretacion",
    "href": "05-parametros-de-poblacion-y-muestra.html#sec-el-error-estandar-y-su-interpretacion",
    "title": "5  Estimación de parámetros",
    "section": "5.2 El error estándar y su interpretación",
    "text": "5.2 El error estándar y su interpretación\nLa variabilidad de las medias muestrales se puede medir por su desviación estándar. Esta medida se conoce como el error estándar y tiende a disminuir cuando aumenta el tamaño de la(s) muestra(s).\n\nDefinición 5.1 (Error estandar) \\[\nSE = {\\sigma\\over{\\sqrt{N}}}\n\\]\nsi conocemos la desviación estándar de la población, y\n\\[\nSE = {s\\over{\\sqrt{N}}}\n\\]\nsi usamos la desviación estándar de la muestra.\ndonde:\n\nSE: el error estándar (por sus siglas en inglés «Standard Error»)\n\\(\\sigma\\): la desviación estándar de la población\ns: desviación estándar de la muestra\nN: número de observaciones de la muestra\n\n\nNótese que el error estándar no disminuye en relación directamente proporcional con el tamaño de la muestra. Ya que tomamos la raíz cuadrada de N, es necesario cuadruplicar el tamaño de la muestra para reducir el error estándar a la mitad.\n\n5.2.1 Intervalos de confianza\nVolvemos a nuestro ejemplo de la estatura de las argentinas entre 19 y 49 en 2007. Si sacamos una muestra aleatoria de esta población de tan solo 30 observaciones. de manera que:\nMuestra = {163, 171, 171, 167, 164, 160, 153, 176, 162, 171, 166, 164, 169, 160, 151, 155, 156, 147, 162, 170, 164, 160, 158, 159, 157, 159, 156, 162, 159, 174}\npodemos calcular la media y la desviación estándar de la muestra. Obtenemos \\(\\bar{x}=160,94\\) y s = 6,89 respectivamente. Con esto podemos calcular el error estándar:\n\\[\nSE = {s\\over{\\sqrt{N}}} = {6,89\\over{\\sqrt{30}}} = {s\\over{5,477}} = 1,257\n\\] Ahora podemos estimar que la media de la población es de 160,94 \\(\\pm\\) 1,257. Hemos reportado muestra estimación con un margen de error. Pero ¿cómo se interpreta este número?\nSea \\(\\mu\\) la media real –por convención se usa la letra griega \\(\\mu\\) que corresponde a m para la media de la población. La desviación de la media de la muestra entonces es de \\(161,94 - \\mu\\). Podemos normalizar esta variable por división con la desviación estándar de la muestra:\n\\[\nz = {161,94 - \\mu\\over1,257}\n\\]\nRecordemos que se usa z para la variable normalizada. Para muestras desde más o menos 30 observaciones, z tiene una distribución normal, con lo cual nos podemos valer de la regla empírica y mirar la figura 4.5 para darnos cuenta qué tan probable es que nuestro valor caiga dentro o fuera de los rangos esperados. El error estándar es, entonces, el rango de valores que caen dentro de una desviación estándar en la curva normal del error, es decir que hay un 68% de probabilidad de que el valor real esté dentro del rango reportado.\nPodemos valernos de esta información para calcular rangos que nos den más confianza en nuestra estimación. La regla empírica dice que el 95% de las observaciones se encuentran entre dos desviaciones estándar de la media. Si se expresa con un poco más de precisión es de 1,96. Este número mágico o valor crítico de usa mucho en los textos con análisis cuantitativo ya que se puede demostrar matemáticamente que:\n\\[\n\\text{media de la muestra} \\pm(1,96\\times{SE})\n\\] es un estimado de la media de la población con un 95% de confianza.\nDe la misma manera tenemos:\n\\[\n\\text{media de la muestra} \\pm(2,58\\times{SE})\n\\]\nque nos da un rango con 99% de confianza.\nEntonces, para nuestra muestra de argentinas podemos decir que estimamos que la media de la población (\\(\\mu\\)) es:\n\nentre 160,94 y 162,20 con un 68% de confianza\nentre 159,73 y 164,66 con un 95% de confianza\nentre 158,94 y 165,44 con un 99% de confianza"
  },
  {
    "objectID": "05-parametros-de-poblacion-y-muestra.html#sec-la-distribucion-t",
    "href": "05-parametros-de-poblacion-y-muestra.html#sec-la-distribucion-t",
    "title": "5  Estimación de parámetros",
    "section": "5.3 La distribución t",
    "text": "5.3 La distribución t\nEn la sección anterior vimos que la razón:\n\\[\nz = {\\bar{x}\\over{SE}}\n\\]\ntiene una distribución normal cuando la muestra tiene un tamaño grande. Cuando la muestra es relativamente pequeña, sin embargo, tiende a otra distribución llamada la distribución t y a veces distribución t de Student1.\nEl valor de t se calcula de la misma manera que el error estándar, pero debido a las características de la distribución los valores críticos son distintos dependiendo de los grados de libertad (que el la mayoría de los casos es igual a N-1.)\n\nEjemplo 5.2 (Muestra pequeña) Hacemos una muestra aleatorea de 15 argentinas y medimos su estatura, esta vez con precisión milimetrica y obtenemos:\nX = {153,26; 158,81; 165,73; 159,85; 160,56; 166,69; 159,85; 148,07; 160,3; 173,02; 154,55; 145,52; 159,98; 158,22; 166,12 }\nLa media es de 159,36 y la desviación estándar de 7,125. Por tanto: \\[\n  SE = {s\\over{\\sqrt{N}}} = {7,125\\over{\\sqrt{15}}} = 1,338\n  \\]\nEl valor crítico de t con 14 grados de libertad (N-1) es \\(\\pm{2,145}\\).\n\\[\n2,145 \\times{SE} = 2,145 \\times 1,338 = 2,869\n\\]\nPor tanto, basado en esta muestra más chica podemos estimar que la media de la población es de 159,36 \\(\\pm2,869\\) es decir entre 156,49 y 162,23 centímetros.\n\nDel ejemplo 5.2 vemos que si bien logramos estimar la media de la población, el margen de error es más amplio que con una muestra más grande.\n\n¿Dónde obtenemos los valores críticos de t?\nSe pueden consultar los valores críticos de la distribución t para distintos grados de libertad en tablas estadísticas, como el del apendix A o en linea. También se puede sacar con una función en R llamada qt.\n\n\nEjemplo 5.3 (Ejemplo en R: Extraer el valor crítico de t) \nqt(p = 0.025, df = 14)\n\n#> [1] -2.144787\n\n\nLa función toma dos argumentos p de qué proporción de la curva en cada lado queremos y df que son los grados de libertad, en este caso 15-1=14. Ponemos el valor de 0.025 porque queremos un 2,5% de arriba y un 2,5% de abajo (=5%)."
  },
  {
    "objectID": "05-parametros-de-poblacion-y-muestra.html#glosario",
    "href": "05-parametros-de-poblacion-y-muestra.html#glosario",
    "title": "5  Estimación de parámetros",
    "section": "5.4 Glosario",
    "text": "5.4 Glosario\n\nDistribución muestral\n\nEl resultado de todas las muestras posibles que pueden ser tomadas de una población Equivalente en inglés: «Sample distribution».\n\nDistribución t\n\nDistribución de probabilidad de una muestra pequeña de una distribución normal. Función relevante en R: qt. Equivalente en inglés: «T distribution».\n\nError estándar\n\nLa desviación estándar de la distribución muestral. Fórmula: \\(SE = {\\sigma\\over{\\sqrt{N}}}\\) o \\(SE = {s\\over{\\sqrt{N}}}\\) Equivalente en inglés: «Standard error».\n\nIntervalo de confianza\n\nIntervalo dentro del cual estimamos que se encuentre un valor buscado, con cierto porcentaje de confianza. Equivalente en inglés: «Confidence Interval»."
  },
  {
    "objectID": "06-diseno-de-proyecto-y-test-de-hipotesis.html#el-método-científico",
    "href": "06-diseno-de-proyecto-y-test-de-hipotesis.html#el-método-científico",
    "title": "6  Diseño de proyectos y test de hipotesis",
    "section": "6.1 El método científico",
    "text": "6.1 El método científico\nEl filósofo de ciencias Karl Popper es considerado por muchos como el padre de la teoría científica moderna. Sostiene que la ciencia avanza proponiendo teorías e ideas que sean empíricamente refutables. Cuando una teoría es refutada por investigaciones empíricas surgen otras teorías que toman en cuenta las refutaciones de las anteriores y son sometidos al mismo proceso. Este tipo de pensamiento se conoce también como pensamiento «deductivo» y es fundamental para las ciencias empíricas. Deductivo, en este caso es contrario a «inductivo» toma como confirmatorias toda observación que sostiene una teoría, sea esta falseable o no.\nPor ejemplo, podemos proponer la teoría de que «en la Ciudad de Buenos Aires nunca cae nieve». Durante la segunda mitad del siglo pasado podíamos corroborar nuestra teoría día tras día al medir el nivel de nieve –que era cero–, pero bastó con una sola nevada, que ocurrió el nueve de julio del 2007, para que nuestra teoría quedara refutada.\nPara que una teoría sea científica tiene que ser posible demostrar su falsedad empíricamente, es decir tenemos que poder obtener datos, por experimentos u observaciones, capazes de comprobar que la teoría no es correcta. Esto se llama el principio de falsabilidad,1 falsación o refutabilidad.\nNuestra teoría de la falta de nieve en la ciudad de Buenos Aires es científica, ya la podemos hacer medidas para refutarla. El hecho de que la teoría resultó incorrecta no implica que no sea científica.\nCabe mencionar que existen ciencias: las ciencias «formales» como las matemáticas, la lógica formal etcétera; cuyas teorías no dependen de observación empírica ya que se concentran en el estudio abstracto de cantidades, estructuras y cambio."
  },
  {
    "objectID": "06-diseno-de-proyecto-y-test-de-hipotesis.html#el-diseño-de-una-investigación",
    "href": "06-diseno-de-proyecto-y-test-de-hipotesis.html#el-diseño-de-una-investigación",
    "title": "6  Diseño de proyectos y test de hipotesis",
    "section": "6.2 El diseño de una investigación",
    "text": "6.2 El diseño de una investigación\n\nEstudios experimentales y observacionales\nPodemos distinguir entre dos tipos de investigación científica en las ciencias empíricas. Los estudios experimentales son estudios donde nosotros manipulamos alguna variable para darnos cuenta qué efecto tiene. En nuestro ejemplo de dos cursos con metodologías distintas, nosotros hemos manipulado la variable metodología. Como hemos mencionado antes en la sección 1.4 esta es la variable independiente. Los estudios experimentales son muy frecuentes en las ciencias naturales y también se aplican a las ciencias humanas.\nEn las ciencias humanas, sin embargo, a menudo nos encontramos con datos en los que no podemos manipular la variable independiente. En el caso de los datos lingüísticos de la figura Figura 2.2, no podemos cambiar el largo de las palabras. Nos tenemos que limitar a recoger los datos e intentar discernir alguna relación entre ellas. Igual tenemos una variable dependiente «largo de palabra» y una independiente «frecuencia», solo que no controlamos la variable independiente. Este tipo de estudios son observacionales y a veces se habla de estudios correlacionales.\n\n\nFuentes de ruido en los datos\nCuando estamos haciendo un estudio experimental controlamos no solo la variable independiente, sino también podemos diseñar el experimento para minimizar el efecto de otras variables que puedan influir en la variable dependiente. La meta es de minimizar los efectos provinientes de de factores que no son relevantes para nuestro estudio a fin de poder afirmar con más confianza que los efectos observados en realidad tienen que ver con la variable independiente. En el caso de los dos grupos con metodologías distintos podemos, por ejemplo, asegurarnos de que los dos cursos tengan el mismo profesor, se dicte en horarios similares y que los de estudiantes que reciben el curso tengan características similares en cuanto a edad, género, promedio de notas en otras materias etcétera. En el caso de un estudio observacional no tenemos este nivel de control, lo que sí podemos hacer es intentar estimar el efecto de interferencia de otras variables y tomarlo en cuenta en nuestros análisis.\nIncluso en el caso de un estudio experimental, no es realista esperar que podemos remover totalmente el efecto de variables irrelevantes. A lo que podemos aspirar y debemos intentar, sin embargo, es de remover la mayor cantidad posible de variación sistemática. Si en el caso del las notas de los grupos de estudiantes pusimos todos los hombres en un grupo y todas las mujeres en otro, no podemos saber si la diferencia que observamos se debe la diferencia de metodología didáctica o si es una diferencia de género. Por ello es preciso hacer lo posible para que las variables que son irrelevantes para nuestra investigación operen de manera aleatoria en nuestras muestras y, de ser posible, minimizar su efecto. Si no operan de manera aleatoria corremos el riesgo de en realidad medir otra variable –género en lugar de metodología– de la que queremos investigar, y si su efecto genera mucha varianza va a bajar la confianza que podemos tener el las conclusiones obtenidas."
  },
  {
    "objectID": "06-diseno-de-proyecto-y-test-de-hipotesis.html#tests-de-hipótesis",
    "href": "06-diseno-de-proyecto-y-test-de-hipotesis.html#tests-de-hipótesis",
    "title": "6  Diseño de proyectos y test de hipotesis",
    "section": "6.3 Tests de hipótesis",
    "text": "6.3 Tests de hipótesis\nVimos en la sección 5.2 que podemos estimar los valores de la población en base a muestras y que podemos calcular un margen de error y niveles de confianza de estas estimaciones. Podemos valernos de los mismos conceptos para concluir algo sobre la relación entre variables: independiente y dependiente por ejemplo.\n\n6.3.1 Tests estadísticos de significanza\nEn el caso de nuestros dos grupos de estudiantes (véase: 6.3.6) ya vimos que existe una diferencia entre los dos grupos en la media de la nota obtenida. De la figura 2.1 vimos que igual las dos distribuciones de solapan en gran medida. Por tanto no podemos afirmar con absoluta certeza que las diferencias observadas son el efecto de la metodología pedagógica aplicada o si son producto de la inherente variabilidad de las muestras.\nEl objetivo de un test estadístico de significanza es determinar si las diferencias observadas el resultado de variación aleatoria o si pueden razonablemente ser atribuidos a la variable independiente.\n\n\n6.3.2 La hipótesis nula y alternativa\nPara testear una hipótesis el primer paso es establecer una hipotesis nula. Esta hipótesis afirma que no existe el efecto que estamos investigando. Siguiendo los lineamientos del método cientifico, ahora nuestra labor es, a través de mediciones u observaciones, refutar esta hipótesis, con lo cual podemos proponer otra, llamada hipótesis alternativa. Una hipótesis nula se formula como una afirmación precisa y empiricamente refutable. En el ejemplo de los dos grupos de estudiantes la hipotesis nula podría expresarse como: «No existe diferencia entre la media de notas entre los dos grupos».\nTambién debemos formular una o dos hipotesis alternativas. Si formulamos dos, una va a afirmar que la media de notas del grupo A es superior a la del grupo B y la otra que la media de notas del grupo B es mayor a la media de notas del grupo A. Si usamos una sola hipótesis alternativa esta simplemente plantea que la media notas de los dos grupos es desigual.\n\nNotación formal\nEn notación formal, muy frecuente en textos académicos, se usa la letra H (mayuscula) para significar una hipótesis y tiene subindice «0» o «null». Las hipótesis alternativas reciben subindice numérica (1 y 2 etcétera). En el caso descrito en la sección anterior se podría expresar así:\n\\(H_0: \\text{No hay diferencia entre los grupos}\\)\n\\(H_1: \\text{Hay diferencia}\\)\no, includo más formal:\n\\(H_0: \\mu_A=\\mu_B\\)\n\\(H_1: \\mu_A\\neq\\mu_B\\).\n\nLa estrategia del test de hipótesis acumular evidencia empírica que nos permita refutar la hipótesis nula y no intentar fomentar cualquiera de las alternativas directamente. Lo que temenos que hacer es aplicar un test estadístico y calcular la probabilidad de obtener las observaciones que hemos obtenido y si esa probabilidad es muy baja, refutamos \\(H_0\\) a favor de una de las alternativas.\nEs preciso aclarar que nunca podemos estar absolutamente seguros de estar justificados en refutar \\(H_0\\). Siempre existe la posibilidad de que las diferencias observadas de deban a la aleatoriedad de las muestras. Lo que sí podemos mostrar es que la probabilidad de que así sea es muy baja.\n\n\n6.3.3 Niveles de significanza\nDado que siempre existe la posibilidad de refutar injustificadamente nuestra \\(H_0\\), tenemos que determinar un nivel debajo del cual estamos dispuestos a equivocarnos en nuestra afirmación. Este se llama el nivel de significanza, también se describe con la letra griega \\(\\alpha\\) y se llama nivel-\\(\\alpha\\) (nivel alfa). El nivel de significanza está coneptual y matemáticamente ligado con los [intervalos de confianza] que vimos en el capítulo @sec-estimacion-de-parametros.\nSi estamos dispuestos a rechazar \\(H_0\\) si la probabilidad (p) de hacerlo injustificadamente es igual o menor a 0,05, eligimos un nivel de significanza de 0,05, también llamado «nivel de 5%». Su notación a menudo se encuentra como: \\(p\\leqslant0,05\\). Este nivel es bastante común en las ciencias humanas, en cambio en otras disciplinas de las ciencias exactas y médicas por ejemplo, a veces se opera con \\(p\\leqslant0,01\\) o \\(p\\leqslant0,001\\), lo que significa que se acepta rechazar injustificadamente \\(H_0\\) una vez en cien o una vez en mil respectivamente.\nPara cada test estadístico y cada nivel de significanza eligido existirá un valor crítico o un rango crítico dentro del cual el valor del cálculo estadístico tiene que encontrarse para que las diferencias observadas en las muestras se consideren estadísticamente significativos. Si el valor del test estadístico no cae en ese rango no podemos rechazar \\(H_0\\) sobre la base este conjunto específico de observaciones, pero es posible que debamos repetir el estudio con muestras más grandes.\n\n\n6.3.4 Tipos de error\nCuando tomamos la decisión de rechazar o aceptar la hipótesis nula hay dos errores que podemos cometer. Podemos rechazar \\(H_0\\) cuando \\(H_0\\) es correcta, o podemos aceptar \\(H_0\\), cuando es falsa. En el primer caso estamos hablando de un error de tipo I, también denominado error de tipo \\(\\alpha\\) o falso positivo. En el segundo caso hablamos de un error de tipo II, error de tipo \\(\\beta\\) (beta) o falso negativo.\n\n\n6.3.5 Tests direcionales y no direcionales\nEn la sección 6.3.2 propusimos una hipótesis nula y su alternativa:\n\nEjemplo 6.1 (Hipotesis nula y una alternativa) \n\n\\(H_0: \\mu_A=\\mu_B\\)\n\\(H_1: \\mu_A\\neq\\mu_B\\).\n\n\\(H_1\\) se leería: «la media de A es desigual a la media de B». Este ejemplo 6.1 es de una predición no direcional. Es decir que no hemos tomado una posición a priori sobre si esperamos que las diferencias que observemos sean positivos o negativos.\nA veces tenemos razones bien fundadas en creer que las diferencias, si las observamos, van a darse en una direción u otra. Si por ejemplo estamos midiendo la estaturas de muestras aleatorias de argentinas y argentinos podemos suponer de antemano que los hombres van a ser más altos que las mujeres ya que está comprobado que es así en otros países, hay razones biológicas etcétera. En ese caso podríamos formular una predicción direccional, lo cual significa que nuestra hipótesis alternativa es una sola y va en una dirección específica:\n\nEjemplo 6.2 (Hipotesis nula y una alternativa direccional) \n\n\\(H_0: \\mu_M=\\mu_F\\)\n\\(H_1: \\mu_M > \\mu_F\\).\n\nLa diferencia entre usar un test direccional o no direccional influye en los valores críticos de los diferentes tests. Si usamos un test direccional –y está justificado su uso, claro– disminuye el riesgo de cometer un error de tipo II. Está ilustrado en las figura 6.1: para un test no-direcional necesitamos un 2,5% en cada extremo de la curva para que sume 5%, en el test direccional «gastamos» todo el lado positivo.\n\n\n\n\n\nFigura 6.1: Test no direccionales y test direccionales\n\n\n\n\n\nEjemplo 6.3 (¿cara o cruz?) \nPara desarrollar un poco más el concepto de test de hipótesis vamos a imaginarnos que estamos jugando a cara o cruz. Si tiramos una moneda hay un 50 y 50 de que salga cruz o cara. Tiramos la moneda y sale cara. La tiramos dos veces y sale dos veces cara. Tres veces – tres caras… y seguimos perdiendo.\n¿En qué momento empezamos a sospechar que la moneda tiene dos caras?\nAún sin conocimientos matemáticos o de la teoría de la probabilidad empieza a obrar nuestra intuición –basada en nuestra experiencia que por su naturaleza es empírica.\nPodemos formalizar el problema de la siguiente manera:\n\\(H_0\\): La moneda es honesta\n\\(H_1\\): La moneda tiene dos caras.\nPodemos también calcular las probabilidades de lo que está pasando. La probabilidad de que salga cara es 0,5 (50%) y de que salga cara dos veces es, por tanto, \\(0,5\\times0,5=0,25\\). Podemos calcular las probabilidades de varios casos más:\n3 caras: \\(0,5\\times0,5\\times0,5=0,125\\)\n4 caras: \\(0,5\\times0,5\\times0,\\times0,55=0,0625\\)\n5 caras: \\(0,5\\times0,5\\times0,\\times0,55=0,03125\\),\ny vemos que si sale cara cinco veces de cinco ya podemos rechazar nuestra \\(H_0\\) con un nivel de significanza de 0,05 (\\(p\\leqslant0,05\\)).\n\n\n\n6.3.6 ¿Qué test usar?\nEn los capítulos que siguen vamos a desarrollar algunos tests de significanza estadística: el test de z, el test de t de Student, Mann-Whitney U, \\(\\chi^2\\), Wilcoxon y sign-test. La elección de cuál de ellos usar en un caso específico dependerá de:\n\nEscala de medición de las variables\nLas características de su distribución\nSi las muestras son correlacionadas o no,\n\ny los iremos detallando en cada caso.\n\n\n6.3.7 Procedimiento\nEl diseño de una investigación cuantitativa se puede resumir en estos cuatro pasos:\n\nFormular hipotesis nula y alternativa(s)\nDecidir el nivel de significanza estadística\nEligir un test estadístico a utilizarse\nAplicar la estadística y decidir si rechazamos \\(H_0\\) o no."
  },
  {
    "objectID": "06-diseno-de-proyecto-y-test-de-hipotesis.html#glosario",
    "href": "06-diseno-de-proyecto-y-test-de-hipotesis.html#glosario",
    "title": "6  Diseño de proyectos y test de hipotesis",
    "section": "6.4 Glosario",
    "text": "6.4 Glosario\n\nError tipo I\n\nEl error de rechazar \\(H_0\\) cuando esta es correcta. Equivalente en inglés: «Type I error».\n\nError tipo II\n\nEl error de no rechazar \\(H_0\\) cuando esta es incorrecta. Equivalente en inglés: «Type II error».\n\nFalsabilidad\n\nEl hecho de que sea posible refutar una hipótesis, por medio de métodos empíricos. Equivalente en inglés: «Falsifiability».\n\nHipotesis alternativa\n\nHipótesis a la que recurrimos si logramos refutar \\(H_0\\). Fórmula: \\(H_1\\) Equivalente en inglés: «Alternative hypothesis.».\n\nHipotesis núla\n\nLa hipótesis que plantea que el patrón que estamos buscando no existe. A través de un estudio empírico intentaremos refutar esta hipótesis. Fórmula: \\(H_0\\) Equivalente en inglés: «Null hypothesis (\\(H_0\\))».\n\nMétodo científico\n\nMetodología basada en la observación, medición y experimentación; y la formulación, análisis y modificación de hipótesis. Equivalente en inglés: «Scientific method».\n\nNivel de significanza\n\nLa probabilidad de rechazar \\(H_0\\) cuando esta es correcta. Fórmula: \\(\\alpha\\) Equivalente en inglés: «Alpha-level».\n\nTest direccional\n\nTest estadístico en la que hypótesis alternativa de expresa en una dirección u otra. Equivalente en inglés: «Directional test».\n\nTest no direccional\n\nTest estadístico en la que hypótesis alternativa de expresa sin dirección especificar dirección. Equivalente en inglés: «Non-directional test»."
  },
  {
    "objectID": "07-tests-parametricos.html",
    "href": "07-tests-parametricos.html",
    "title": "7  Pruebas paramétricas",
    "section": "",
    "text": "En este capítulo vamos a desarrollar algunos técnicas estadísticos que nos permiten realizar una prueba o un test de diferencias entre medias de dos conjuntos de datos provenientes de muestras independientes o correlacionadas. Los tests que vamos a ver se llaman «paramétricos», lo cual quiere decir viene con algunas presunciones acerca de los datos:\nLas pruebas estadísticas son las que nos permiten, a algún nivel de significanza, rechazar o aceptar la hipótesis nula (\\(H_0\\)), por lo que son de bastante utilidad en investigaciones cuantitativas."
  },
  {
    "objectID": "07-tests-parametricos.html#sec-prueba-t-de-student-para-muestras-independientes",
    "href": "07-tests-parametricos.html#sec-prueba-t-de-student-para-muestras-independientes",
    "title": "7  Pruebas paramétricas",
    "section": "7.1 Prueba t de Student para muestras independientes",
    "text": "7.1 Prueba t de Student para muestras independientes\nSupongamos que tenemos dos muestras aleatorias e independientes con medias de \\(\\bar{x_1}\\) y \\(\\bar{x_2}\\) y que queremos saber si estas dos medias son signifacativamente distintas a un nivel de \\(p\\leqslant0,05\\). Esto es lo mismo que decir que si afirmamos que hay una diferencia entre las muestras tenemos un 95% de probabilidad de tener razón. Lo que tenemos que calcular, entonces, es la probabilidad de que las dos muestras pueder provenir de la misma distribución y que la diferencia que vemos es por varianza en esa población. En otras palabras: queremos saber si dos muestras con la diferencia observada (\\(\\bar{x_1}-\\bar{x_2}\\)) podrían tener provenir de la misma población.\nSi sacamos un número significativo de muestras de una misma población la media de estas muestra va a tener una diferencia con la media de la población, en algunos casos más altos y en otros más bajos. Usamos este conocimiento para calcular el error estándar:\n\\[\nSE = {\\sigma\\over{\\sqrt{N}}}.\n\\tag{7.1}\\]\nDe la misma manera existe un error estándar de diferencias entre medias (SED por sus siglas en ingles).\n\nDefinición 7.1 (Error estándar de diferencia entre medias) \\[\nSED = \\sqrt{\\sigma^2_1/N_1 + \\sigma^2_1/N_2}\n\\]\ndonde:\n\n\\(\\sigma^2_1\\) y \\(\\sigma^2_2\\): las varianzas de las poblaciones 1 y 2\n\\(N_1\\) y \\(N_2\\): es el número de observaciones en cada muestra.\n\n\nAl igual que con el error estándar, a menudo desconocemos la varianza de la población, por lo cual lo estimamos de la muestra y la formula es la que vemos en la definición 7.2\n\nDefinición 7.2 (Error estándar de diferencia entre medias estimado de muestras) \\[\nSED = \\sqrt{s^2_1/N_1 + s^2_1/N_2}\n\\]\ndonde:\n\n\\(s^2_1\\) y \\(s^2_2\\): las varianzas de las muestras 1 y 2\n\\(N_1\\) y \\(N_2\\): es el número de observaciones en cada muestra.\n\n\nVimos en la sección 5.3que para muestras relativamente pequeñas (N<30) la distribución de la muestra tiende a la distribución t de Student. Podemos valernos de esto para calcular la probabilidad de que nuestro SED esté en el rango requerido aplicando la formula de la definición.\n\nDefinición 7.3 (Prueba de t) \\[\nt = {{(\\bar{x_1}-\\bar{x_2})}\\over{SED}}.\n\\]\n\nSi aplicamos la fórmula de la definición 7.3 nos sale un valor que podemos comparar con los valores críticos de la tabla del apendice A para determinar si rechazamos \\(H_0\\) o no.\n\nEjemplo 7.1 (Prueba t) \n\nVolvemos ahora a nuestros datos de notas de dos grupos de estudiantes con diferentes metodologías pedagígicos. Queremos saber con un nivel de significanza de 0,05 si existe diferencia entre la media de los dos grupos. Nuestras hipótesis nula y alternativa son entonces:\n\\(H_0:\\mu_A=\\mu_B\\),\n\\(H_1: \\mu_A\\neq\\mu_B\\).\nLos datos son:\nGrupo A: {15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14} y\nGrupo B: {11, 16, 14, 18, 6, 8, 9, 14, 12, 12, 10, 15, 12, 9, 13, 16, 17, 12, 8, 7, 15, 5, 14, 13, 13, 12, 11, 13, 11, 7}.\nLa media y desviación estándar:\n   Grupo A:\n       \\(\\bar{x_A} = 14,933\\)\n       \\(s = 2,490\\)\n       \\(N=30\\)\n   Grupo B:\n      \\(\\bar{x} = 11,77\\)\n      \\(s = 3,308\\)\n      \\(N=30\\).\nAplicando la fórmula de la definición 7.2 obtenemos:\n\\[\nSED = \\sqrt{s^2_1/N_1 + s^2_1/N_2} = \\sqrt{2,490^2/30 + 3,308^2/N_2} = 0,756\n\\]\ny podemos calcular el valor de t aplicando la fórmula de la definición 7.3\n\\[\nt = {{\\bar{x_1}-\\bar{x_2}}\\over{SED}} = {{14.933-11,766}\\over{0,756}}=4,188.\n\\]\nSi buscamos este valor en el Apendix A para 29 grados de libertad (N-1), vemos que debemos rechazar \\(H_0\\) y concluir que existe una diferencia estadísticamente significativa entre las dos muestras. Tenemos razón de creer que el método pedagógico influye en los resultados finales de los estudiantes.\n\n\nEjemplo 7.2 (Prueba t en R) \n\nSi no queremos hacer todos estos cálculos a mano podemos hacerlos en R usando la función t.test. Toma como parámetros las dos muestras que queremos comparar.\n\nGrupo.A = c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14)\nGrupo.B = c(11, 16, 14, 18, 6, 8, 9, 14, 12, 12, 10, 15, 12, 9, 13, 16, 17, 12, 8, 7, 15, 5, 14, 13, 13, 12, 11, 13, 11, 7)\nt.test(Grupo.A,Grupo.B)\n\n#> \n#>  Welch Two Sample t-test\n#> \n#> data:  Grupo.A and Grupo.B\n#> t = 4.1887, df = 53.88, p-value = 0.0001046\n#> alternative hypothesis: true difference in means is not equal to 0\n#> 95 percent confidence interval:\n#>  1.650905 4.682428\n#> sample estimates:\n#> mean of x mean of y \n#>  14.93333  11.76667\n\n\nVemos que el test nos devuelve además un valor de p más preciso."
  },
  {
    "objectID": "07-tests-parametricos.html#sec-test-de-normalidad",
    "href": "07-tests-parametricos.html#sec-test-de-normalidad",
    "title": "7  Pruebas paramétricas",
    "section": "7.2 Prueba de Shapiro-Wilks",
    "text": "7.2 Prueba de Shapiro-Wilks\nEn la sección 4.3 mencionamos que existen algunas maneras de estimar si una variable tiene una distribución normal o no. Nos basamos sobre todo en la forma de los polígonos de frecuencias (figura 2.1). Ahora vamos a introducir un test más formal de normalidad.\nEl test de Shapiro-Wilks plantea la hipótesis nula que una muestra proviene de una distribución normal. Eligimos un nivel de significanza, por ejemplo 0,05, y tenemos una hipótesis alternativa que sostiene que la distribución no es normal.\nTenemos:\n\\(H_0\\): La distribución es normal\n\\(H_1\\): La distribución no es normal,\no más formalmente aún:\n\\(H_0: X \\sim \\mathcal{N}(\\mu,\\sigma^2)\\)\n\\(H_1: X \\nsim \\mathcal{N}(\\mu,\\sigma^2)\\).\nAhora el test Shapiro-Wilks intenta rechazar la hipotesis nula a nuestro nivel de significanza. Para realizar el test usamos la función shapiro.test en R:\n\nEjemplo 7.3 (Test de Shapiro Wilks en R) \n\n\nGrupo.A = c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14)\n\nshapiro.test(Grupo.A)\n\n#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  Grupo.A\n#> W = 0.97032, p-value = 0.548\n\nGrupo.B = c(11, 16, 14, 18, 6, 8, 9, 14, 12, 12, 10, 15, 12, 9, 13, 16, 17, 12, 8, 7, 15, 5, 14, 13, 13, 12, 11, 13, 11, 7)\n\n\nshapiro.test(Grupo.B)\n\n#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  Grupo.B\n#> W = 0.97636, p-value = 0.7227\n\n\n\nVemos que en ambos casos el valor de probabilidad (p) es muy superios a nuestro nivel elegido (0,05), por lo que no rechazamos la hipótesis nula.\nEn el caso de los ejemplos 7.1 y 7.2 ya obramos bajo la premisa de que las variables tenían una distribución normal, pero generalmente conviene realizar el test Shapiro-Willks antes de decidir qué prueba estadística vamos a usar. Si rechazamos \\(H_0\\), es decir si no concluimos que la distribución sea normal, no deberíamos usar un test paramétrico."
  },
  {
    "objectID": "07-tests-parametricos.html#prueba-de-fisher",
    "href": "07-tests-parametricos.html#prueba-de-fisher",
    "title": "7  Pruebas paramétricas",
    "section": "7.3 Prueba de Fisher",
    "text": "7.3 Prueba de Fisher\nAl inicio del capítulo también vimos que uno de los requisitos para que una prueba estadística paramétrica sea válida es que las varianzas sean de similar magnitud. Para ello también existe un test, el test de Fisher2 que plantea las hipótesis:\n\\(H_0: \\sigma^2_1 = \\sigma^2_2\\),\n\\(H_1: \\sigma^2_1 \\neq \\sigma^2_2\\)\nSin entrar en mucho detalle teórico, en R hay una función var.test para este propósito. La función toma dos argumentos: los dos conjuntos de datos que queremos comparar.\n\nEjemplo 7.4 (Realizar la prueba de Fisher en R) \n\n\nvar.test(Grupo.A, Grupo.B)\n\n#> \n#>  F test to compare two variances\n#> \n#> data:  Grupo.A and Grupo.B\n#> F = 0.56675, num df = 29, denom df = 29, p-value =\n#> 0.1321\n#> alternative hypothesis: true ratio of variances is not equal to 1\n#> 95 percent confidence interval:\n#>  0.2697517 1.1907335\n#> sample estimates:\n#> ratio of variances \n#>          0.5667472\n\n\n\nVemos que el valor de probabilidad \\(p\\) es mayor a nuestro nivel de significanza (\\(p\\leqslant0,05\\)), con lo cual no rechazamos \\(H_0\\) y concluimos que las varianzas son relativamente similares."
  },
  {
    "objectID": "07-tests-parametricos.html#sec-prueba-t-para-muestras-pareadas",
    "href": "07-tests-parametricos.html#sec-prueba-t-para-muestras-pareadas",
    "title": "7  Pruebas paramétricas",
    "section": "7.4 Prueba t para muestras pareadas",
    "text": "7.4 Prueba t para muestras pareadas\nEn los ejemplos 7.1 y 7.2 teníamos dos grupos de estudiantes de dos cursos distintos, pero en muchos tenemos observaciones pareadas o datos interdependientes. Esto es muy típico de investigaciones experimentales en los que medimos la variable dependiente antes y después3 de cambiar la variable independiente. Si, por ejemplo, queremos investigar el efecto de la cafeína sobre el pulso sanguineo podríamos obtener una muestra de personas y tomarles el pulso antes y después de hacerles tomar una taza de café.\nEn este sacamos las diferencias entre las dos medidas y comparamos estas diferencias con la distribución teórica. La fórmula está en la definición 7.4.\n\nDefinición 7.4 (Prueba t para muestras dependientes) \\[\nt = {{\\bar{X}_D}\\over{s_D\\over{\\sqrt{n}}}}\n\\]\ndonde:\n\n\\({\\bar{X}_D}\\): media de las diferencias\n\\(s_D\\): la desviación estándar de las diferencias\nn: número de pares de observaciones.\n\n\nLo que nos va a decir la prueba t en este caso es si la diferencia es significativamente diferente a cero: Si la variable independiente no tiene efecto entonces debería dar lo mismo medir antes o después. Las hipótesis planteadas son, por tanto:\n\\(H_0: \\bar{X}_D = 0\\),\n\\(H_1: \\bar{X}_D \\neq 0\\).\n\nEjemplo 7.5 (Prueba t dependiente) En este ejemplo (Shier 2004) vamos a suponer que tenemos un grupo de veinte estudiantes y queremos investigar el efecto del uso de algún recurso didáctico, por ejemplo un video en YouTube, en su destreza para resolver cierto tipo de problemas matemáticos. Les tomamos un test inicial, pedimos que miren el video y cuando terminen tomamos otro test. Ahora tenemos dos observaciones de cada estudiante. Calculamos la diferencia entre ellos. El resultado de todo esto está resumido en la tabla 7.1.\n\n\n\n\nTabla 7.1: Resultados de dos tests de matemáticas\n\n\nNombre\nAntes\nDespués\nDiferencia\n\n\n\n\nManuel\n18\n22\n4\n\n\nMiguel\n21\n25\n4\n\n\nJosé\n16\n17\n1\n\n\nAntonio\n22\n24\n2\n\n\nDolores\n19\n16\n-3\n\n\nManuela\n24\n29\n5\n\n\nPedro\n17\n20\n3\n\n\nLucía\n21\n23\n2\n\n\nCecilia\n23\n19\n-4\n\n\nJuan\n18\n20\n2\n\n\nPaula\n14\n15\n1\n\n\nFrancisco\n16\n15\n-1\n\n\nAngel\n16\n18\n2\n\n\nSoledad\n19\n26\n7\n\n\nLuis\n18\n18\n0\n\n\nCristina\n20\n24\n4\n\n\nLaura\n12\n18\n6\n\n\nCarlos\n22\n25\n3\n\n\nCarmen\n15\n19\n4\n\n\nJavier\n17\n16\n-1\n\n\n\n\n\n\nLa media de las diferencias es 2.05 con una desviación estándar de 2,837. Entonces tenemos:\n\\[\nt = {{\\bar{X}_D}\\over{s_D\\over{\\sqrt{n}}}} =  {{2,05}\\over{2,837\\over{\\sqrt{20}}}}=3,231.\n\\]\nBuscando este valor en la tabla de valores críticos con 19 (N-1) grados de libertad vemos que sí podemos rechazar la hipótesis nula y concluir que hay una diferencia estadísticamente significativa entre los resultados de los dos tests.\n\n\nEjemplo 7.6 (Ejemplo en R) \nPara reproducir en R lo que hicimos en el ejemplo 7.5 tenemos que tener sumo cuidado con el ingreso de los datos. Ya que hay dos observaciones por estudiante lo más conveniente es ponerlos en un data.frame. Vamos a incluir los nombres de los estudiantes, si bien no son necesarios para el cálculo sirve mantener la referencia para poder verificar el correcto ingreso de los datos con los tests. Vamos a ingresar los datos a mano aunque en la práctica seguramente se leyera de un archivo externo de R. Usamos la función t.test con un paramertro adiciónal paired=TRUE para avisar que son datos pareados.\n\n# Ingresamos los datos\n datos.pre.post = data.frame(\n   Nombre = c('Luis', 'Javier', 'Pedro', 'Soledad', 'Manuel', 'Cecilia', 'Cristina', 'Angel', 'Manuela', 'José', 'Juan', 'Antonio', 'Carmen', 'Carlos ', 'Francisco', 'Miguel', 'Laura', 'Lucía', 'Paula', 'Dolores'),\n   Pre = c(18, 21, 16, 22, 19, 24, 17, 21, 23, 18, 14, 16, 16, 19, 18, 20, 12, 22, 15, 17),\n   Post = c(22, 25, 17, 24, 16, 29, 20, 23, 19, 20, 15, 15, 18, 26, 18, 24, 18, 25, 19, 16)\n )\n\n# Verificamos la homogeneidad de varianzas\nvar.test(datos.pre.post$Pre,datos.pre.post$Post)\n\n#> \n#>  F test to compare two variances\n#> \n#> data:  datos.pre.post$Pre and datos.pre.post$Post\n#> F = 0.60329, num df = 19, denom df = 19, p-value =\n#> 0.2795\n#> alternative hypothesis: true ratio of variances is not equal to 1\n#> 95 percent confidence interval:\n#>  0.238790 1.524186\n#> sample estimates:\n#> ratio of variances \n#>          0.6032913\n\n# Verificamos que los datos tienen distribución normal\nshapiro.test(datos.pre.post$Pre)\n\n#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  datos.pre.post$Pre\n#> W = 0.98197, p-value = 0.9569\n\nshapiro.test(datos.pre.post$Post)\n\n#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  datos.pre.post$Post\n#> W = 0.94235, p-value = 0.2654\n\n# Realizamos prueba t\n\nt.test(datos.pre.post$Post,datos.pre.post$Pre, paired = TRUE)\n\n#> \n#>  Paired t-test\n#> \n#> data:  datos.pre.post$Post and datos.pre.post$Pre\n#> t = 3.2313, df = 19, p-value = 0.004395\n#> alternative hypothesis: true mean difference is not equal to 0\n#> 95 percent confidence interval:\n#>  0.7221251 3.3778749\n#> sample estimates:\n#> mean difference \n#>            2.05\n\n\nVemos que el resultado tiene significanza estadística alta (\\(p\\leqslant0,01\\)). El cálculo de R también nos da un intervalo de confianza al 95%."
  },
  {
    "objectID": "07-tests-parametricos.html#prueba-de-z",
    "href": "07-tests-parametricos.html#prueba-de-z",
    "title": "7  Pruebas paramétricas",
    "section": "7.5 Prueba de z",
    "text": "7.5 Prueba de z\nExiste también una prueba, llamada de z, que se puede usar para muestras más grandes. Se basa en el hecho de que cuando las muestras son más grandes tienden a una distribución normal y no una distribución t. Aparte de eso su concepto y mecánica es similar a la de la prueba t. Puede aplicarse cuando las muestras tienen más de 30 (N>30) observaciones y la principal diferencia de que es capaz de detectar diferencias más pequeñas en los datos lo que reduce el riesgo de un error tipo II."
  },
  {
    "objectID": "07-tests-parametricos.html#resumen-de-procedimiento",
    "href": "07-tests-parametricos.html#resumen-de-procedimiento",
    "title": "7  Pruebas paramétricas",
    "section": "7.6 Resumen de procedimiento",
    "text": "7.6 Resumen de procedimiento\nLa figura 7.1 despliega un diagrama de flujo para eligir un test estadístico inferencial.\n\n\n\n\n\nFigura 7.1: Diagrama de flujo para selección de estadística inferencial"
  },
  {
    "objectID": "07-tests-parametricos.html#glosario",
    "href": "07-tests-parametricos.html#glosario",
    "title": "7  Pruebas paramétricas",
    "section": "7.7 Glosario",
    "text": "7.7 Glosario\n\nError estándar de diferencias entre medias\n\nEl error estándar calculado sobre la distribución de diferencias entre dos muestras. Fórmula: \\(SED = \\sqrt{\\sigma^2_1/N_1 + \\sigma^2_1/N_2}\\) Equivalente en inglés: «Standar error of differences (SED)».\n\nPrueba de Fisher\n\nPrueba estadística que nos permite estimar si la varianza de dos muestras en similar. Equivalente en inglés: «Fisher test».\n\nPrueba de Shapiro-Wilks\n\nPrueba estadística que nos permite estimar en qué medida una muestra proviene de una distribución normal. Equivalente en inglés: «Shapiro-Wilks Test».\n\nPrueba de z\n\nPrueba estadística que nos permite estimar si dos muestras grandes (N>30 para ambas) provienen de poblaciones diferentes. Equivalente en inglés: «z-test».\n\nPrueba t para muestras independientes\n\nTest estadístico que nos indica si la media de dos muestras tienen más diferencias de lo que se esperaría si son aleatorias. Fórmula: \\(t = {{(\\bar{x_1}-\\bar{x_2})}\\over{SED}}\\) Función relevante en R: t.test. Equivalente en inglés: «T-test for independent samples».\n\nPrueba t para muestras pareadas\n\nTest estadístico que nos indica si la media de dos muestras correlacionadas tienen más diferencias de lo que se esperaría por razones aleatorias. Fórmula: \\(t = {{\\bar{X}_D}\\over{s_D\\over{\\sqrt{n}}}}\\) Función relevante en R: t.test. Equivalente en inglés: «T-test for dependent samples».\n\n\n\n\n\n\nShier, Rosie. 2004. «Paired t-tests». http://www.statstutor.ac.uk/resources/uploaded/paired-t-test.pdf."
  },
  {
    "objectID": "08-tests-no-parametricos.html",
    "href": "08-tests-no-parametricos.html",
    "title": "8  Pruebas no paramétricas",
    "section": "",
    "text": "En el capítulo 7 vimos que para usar esas pruebas tenemos que cumplir con algunos requisitos sobre la distribución normal de las variables, nivel de medición y homogeneidad de las varianzas. Con alguna frecuencia, sin embargo, resulta que nuestros datos no cumplen con alguno de esos requisitos. Esto se puede dar por la naturaleza de la investigación, por ejemplo si estamos investigando un fenómeno que no se puede medir a escala de intervalo o razón; o tenemos relativamente pocos datos y luego de realizar los test de Fisher y Shapiro nos damos cuenta de que o la varianza es muy heterogénea o que las variables carecen de distribución normal.\nPor suerte todavía hay esperanza. Existen algunas pruebas estadísticas, llamadas no paramétricas que nos pueden salvar en estos casos. En este capítulo desarrollaremos tres de ellos."
  },
  {
    "objectID": "08-tests-no-parametricos.html#sec-prueba-u-de-mann-whitney",
    "href": "08-tests-no-parametricos.html#sec-prueba-u-de-mann-whitney",
    "title": "8  Pruebas no paramétricas",
    "section": "8.1 Prueba U de Mann-Whitney",
    "text": "8.1 Prueba U de Mann-Whitney\nLa prueba U de Mann-Whitney resulta útil si tenemos dos muestras independientes y queremos si hay una diferencia en la magnitud de la variable que estamos estudiando, pero no podemos usar la prueba de t independiente o la prueba de z porque los datos no cumplen con alguno de los requisitos. Para realizar la prueba U de Mann-Whitney ponemos las observaciones de las dos muestras en orden ascendiente y asignamos un rango ordinal de manera que 1 corresponde a la observación de menor magnitud, 2 a la segunda etcétera. Luego nos fijamos en las diferencias entre las observaciones.\nLa prueba se basa en una comparación de cada observación de una muestra \\(x_i\\) con cada observación en la segunda muestra \\(y_j\\). Si las muestras tienen la misma mediana, entones cada observación tiene un 0,5 (50%) de chance de ser mayor o menor que la observación correspondiente de la otra muestra. Por tanto plantea las hipotesis:\n\\(H_0: P(x_i>y_j)={1\\over2}\\)\n\\(H_1: P(x_i>y_j)\\neq{1\\over2}\\)\nLa prueba U de Mann-Whitney también se conoce con otros nombres: Mann–Whitney–Wilcoxon, Wilcoxon rank-sum test y Wilcoxon–Mann–Whitney. Por ello está disponible en R por medio de la función wilcox.test.\n\nEjemplo 8.1 (Prueba U de Mann-Whitney en R) \n\nEn este ejemplo vamos a suponer que tenemos datos diagnósticos de cuatro mujeres y cinco hombres. Todos fueron diagnosticados con diabetes y tenemos la edad a la cual se les descubrió la enfermedad. Queremos saber si hay diferencia en la edad entre hombres y mujeres. Los datos son:\nHombres: {19, 22, 16, 29, 24},\nMujeres: {20, 11, 17, 12}.\n\n\nHombres = c(19, 22, 16, 29, 24)\nMujeres = c(20, 11, 17, 12)\nwilcox.test(Hombres, Mujeres)\n\n#> \n#>  Wilcoxon rank sum exact test\n#> \n#> data:  Hombres and Mujeres\n#> W = 17, p-value = 0.1111\n#> alternative hypothesis: true location shift is not equal to 0\n\n\nVemos que no podemos rechazar \\(H_0\\) en este caso."
  },
  {
    "objectID": "08-tests-no-parametricos.html#sec-prueba-de-los-rangos-con-signo-de-wilcoxon",
    "href": "08-tests-no-parametricos.html#sec-prueba-de-los-rangos-con-signo-de-wilcoxon",
    "title": "8  Pruebas no paramétricas",
    "section": "8.2 Prueba de los rangos con signo de Wilcoxon",
    "text": "8.2 Prueba de los rangos con signo de Wilcoxon\nVimos en la sección 8.1 que la prueba U de Mann-Whitney puede ser una alternativa a la prueba de t de Student para muestras intependiente (véase la sección 7.1) cuando los requisitos para un test paramétrico no se cumplen. Si los datos son pareados tenemos la prueba de los rangos con signo de Wilcoxon como alternativa a prueba t para muestras pareadas que vimos en la sección 7.4.\nLa lógica de la prueba de los rangos con signo de Wilcoxon es similar a la de la prueba de t pareada. Si no hay diferencia en el antes y despues, por ejemplo, las diferencias entre las observaciones deberían tender a cero.\n\nEjemplo 8.2 (Prueba de los rangos con signo de Wilcoxon en R) \n\nEn este ejemplo vamos a suponer que tenemos un grupo de doce pacientes con artritis y les damos dos medicaciones distintas para aliviar los síntomas. Pedimos a todos que nos indiquen cuantas horas de alivio observaron con ambas drogas.\nLos datos se observan en la tabla 8.1.\n\n\n\n\nTabla 8.1: Eficiencia de dos medicamentos, reportada por los pacientes.\n\n\nPaciente\nDroga.A\nDroga.B\n\n\n\n\n1\n2,0\n3,5\n\n\n2\n3,6\n5,7\n\n\n3\n2,6\n2,9\n\n\n4\n2,7\n2,4\n\n\n5\n7,3\n9,9\n\n\n6\n3,4\n3,3\n\n\n7\n14,9\n16,7\n\n\n8\n6,6\n6,0\n\n\n9\n2,3\n3,8\n\n\n10\n2,1\n4,0\n\n\n11\n6,8\n9,1\n\n\n12\n8,5\n20,9\n\n\n\n\n\n\nEn R ponemos los datos en un data.frame:\n\ndatos = data.frame(\n  Paciente = c( 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12),\n  Droga.A = c( 2,  3.6,  2.6,  2.7,  7.3,  3.4,  14.9,  6.6,  2.3,  2.1,  6.8,  8.5),\n  Droga.B = c( 3.5,  5.7,  2.9,  2.4,  9.9,  3.3,  16.7,  6,  3.8,  4,  9.1,  20.9)\n)\n\nE iniciamos nuestros tests:\n\nvar.test(datos$Droga.A,datos$Droga.B)\n\n#> \n#>  F test to compare two variances\n#> \n#> data:  datos$Droga.A and datos$Droga.B\n#> F = 0.41865, num df = 11, denom df = 11, p-value =\n#> 0.1643\n#> alternative hypothesis: true ratio of variances is not equal to 1\n#> 95 percent confidence interval:\n#>  0.1205199 1.4542635\n#> sample estimates:\n#> ratio of variances \n#>          0.4186498\n\n\n¡Bien! No tenemos problemas de varianza.\n\nshapiro.test(datos$Droga.A)\n\n#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  datos$Droga.A\n#> W = 0.80692, p-value = 0.01124\n\nshapiro.test(datos$Droga.B)\n\n#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  datos$Droga.B\n#> W = 0.7883, p-value = 0.006919\n\n\n¡Ups!, las variables no tienen distribución normal. Entonces no podemos usar la prueba t pareada, tenemos que probar con Wilcoxon.\nUsamos la función wilcox.test con el parametro extra de paired = TRUE.\n\nwilcox.test(datos$Droga.A, datos$Droga.B, paired = TRUE)\n\n#> \n#>  Wilcoxon signed rank test with continuity correction\n#> \n#> data:  datos$Droga.A and datos$Droga.B\n#> V = 8, p-value = 0.01669\n#> alternative hypothesis: true location shift is not equal to 0\n\n\nVemos que el valor p se encuentra debajo de nuestro nivel de significanza (\\(\\alpha=0,05\\)), con lo cual rechazamos \\(H_0\\) y concluimos que hay una diferencia estadísticamente significativa entre las dos mediamentos.\n\n\n¿Y si usabamos la prueba t igual?\nSi nos hubéramos olvidado de verificar la conformidad de los requisitos podríamos haber caído en la prueba t paramétrica, ¿qué hubiera pasado?\nVeamos:\n\nt.test(datos$Droga.A, datos$Droga.B, paired = TRUE)\n\n#> \n#>  Paired t-test\n#> \n#> data:  datos$Droga.A and datos$Droga.B\n#> t = -2.1465, df = 11, p-value = 0.05498\n#> alternative hypothesis: true mean difference is not equal to 0\n#> 95 percent confidence interval:\n#>  -4.28706458  0.05373125\n#> sample estimates:\n#> mean difference \n#>       -2.116667\n\n\nPodemos observar que la prueba de t es sensible a la falta de normalidad en nuestras variables y no logra rechazar \\(H_0\\)."
  },
  {
    "objectID": "08-tests-no-parametricos.html#sec-prueba-de-signos",
    "href": "08-tests-no-parametricos.html#sec-prueba-de-signos",
    "title": "8  Pruebas no paramétricas",
    "section": "8.3 Prueba de signos",
    "text": "8.3 Prueba de signos\nLa prueba de Wilcoxon que vimos en la sección 8.2 requiere que los datos tengan una escala de medición (véase la sección 1.4) de intervalo. Pero a veces tenemos datos que solo se pueden medir a escala ordinal como por ejemplo la preferencia por alguna bebida de 1 a 5. En este caso no es razonable afirmar que la diferencia entre uno y dos es la misma que entre dos y tres, entonces no podemos tomar en cuenta la magnitud de esas diferencias.\nLa prueba de signos resuelve este problema convirtiendo la diferencia en una variable trinaria: puede ser cero, positiva o negativa. La lógica del test es similar a la de Wilcoxon, si no hay un patrón en las observaciones estas diferencias deberían tender a cero. Para realizar un test de signo debemos primero anotar el signo (positivo, negativo o cero) de todas los pares de observaciones que tenemos. Cuando la diferencia es cero se excluye el par del análisis y reducimos N acorde a eso. Luego sumamos los positivos por un lado y los negativos por otro y tomamos el menor le los dos. Este número, a menudo significado por una W, de puede compara con la tabla de valores críticos para el N que quedó, que se puede consultar en el apendice B para N entre 5 y 25.\nCuando N es superior a 25, es decir cuando tenemos venticinco o más observaciones que no sean cero, se puede transformar W en una variable normalizada. Usando la fórmula en la definición 8.1.\n\nDefinición 8.1 (Normalizar W del test de signos) \\[\nz={{N-2\\times{W}-1}\\over\\sqrt{N}}\n\\]"
  },
  {
    "objectID": "08-tests-no-parametricos.html#realizar-prueba-de-sign-para-n25",
    "href": "08-tests-no-parametricos.html#realizar-prueba-de-sign-para-n25",
    "title": "8  Pruebas no paramétricas",
    "section": "8.4 Realizar prueba de sign para N>25",
    "text": "8.4 Realizar prueba de sign para N>25\n\n\nEn este ejemplo vamos a suponer que hemos preguntado a 150 personas su opinión sobre el café de dos cafeterías: A y B, de la Ciudad de Buenos Aires. Les pedimos que indiquen en una escala de 1 a 5 cuánto les gusta cada producto. De ellos cincuenta dan el mismo ranking a ambos productos, con lo sus opiniones se eliminan del cálculo. De los restantes cien tenemos 39 que prefieren B y 61 que prefieren A. Tomamos el menor valor (39) y aplicamos la fórmula:\n\\[\nz={{N-2\\times{W}-1}\\over\\sqrt{N}} = {{100-2\\times{39}-1}\\over\\sqrt{100}} = {21\\over10} = 2,1\n\\]\nRecordamos que el valor mágico de la distribución normal –la regla empírica– es 1,96 para nuestro nivel de significanza \\((p\\leqslant0,05)\\) y concluimos que existe una diferencia estadísticamente significativa."
  },
  {
    "objectID": "08-tests-no-parametricos.html#cuál-usar",
    "href": "08-tests-no-parametricos.html#cuál-usar",
    "title": "8  Pruebas no paramétricas",
    "section": "8.5 ¿Cuál usar?",
    "text": "8.5 ¿Cuál usar?\nEn la figura 8.1 podemos ver un diagrama de flujo para eligir un test no paramétrico.\n\n\n\n\n\nFigura 8.1: Diagrama de flujo para selección de pruebas estadísticas no paramétricas."
  },
  {
    "objectID": "08-tests-no-parametricos.html#glosario",
    "href": "08-tests-no-parametricos.html#glosario",
    "title": "8  Pruebas no paramétricas",
    "section": "8.6 Glosario",
    "text": "8.6 Glosario\n\nPrueba de los rangos con signo de Wilcoxon\n\nPrueba estadística. Alternativa a la prueba t pareada, cuando los datos no cumplen con los requisitos para pruebas paramétricas. Función relevante en R: wilcox.test. Equivalente en inglés: «Wilcoxon ranked sign test».\n\nPrueba de signos\n\nPrueba estadística. Alternativa a la prueba t pareada, cuando los datos son de escala ordinal. Equivalente en inglés: «Sign-test».\n\nPrueba U de Mann-Whitney\n\nPrueba estadística. Alternativa a la prueba t o prueba z, cuando los datos no cumplen con los requisitos para pruebas paramétricas. Función relevante en R: wilcox.test. Equivalente en inglés: «Mann-Whitney U test»."
  },
  {
    "objectID": "09-chi-cuadrado.html",
    "href": "09-chi-cuadrado.html",
    "title": "9  Prueba de \\(\\chi^2\\)",
    "section": "",
    "text": "En los capítulos Capítulo 7 y Capítulo 8 vimos varios tests estadísticos que nos permiten apreciar la significanza de diferencias entre dos conjuntos de medidas cuantitativas. Las variables que vimos se medían en escala de razón, intervalo u ordinal. En este capítulo vamos a explorar algunas técnicas que nos permiten trabajar con variables que no se pueden medir en términos numéricos, sino que son de tipo «sí-o-no»; es decir que son de escala nominal.\nEn particular vamos a explorar la distribuciónd de \\(\\chi^2\\) de Pearson. \\(\\chi\\) es una letra griega que suele pronunciarse «ji» (/xi/) y «chi» (/tʃiː)/1."
  },
  {
    "objectID": "09-chi-cuadrado.html#características",
    "href": "09-chi-cuadrado.html#características",
    "title": "9  Prueba de \\(\\chi^2\\)",
    "section": "9.1 Características",
    "text": "9.1 Características\nEl test de \\(\\chi^2\\) nos permite comparar las frecuencias que observamos con las frecuencias que esperaríamos en base a un modelo teórico o una hipótesis sobre la distribución de la variable en cuestión. Por cada par de valores observados y esperados calculamos la diferencia y aplicamos la fórmula de la definición 9.1.\n\nDefinición 9.1 (\\(\\chi^2\\)) \\[\n\\chi^2 = \\sum{(O-E)^2\\over{E}}\n\\] donde:\n\nO: la frecuencia observada\nE: la frecuencia esperada\n\n\nEs importante tener en cuenta que \\(\\chi^2\\) se calcula usando las frecuencias y no las proporciones.\nLa hipótesis nula es que no existe diferencia entre los valores observamos y los valores esperados. La alternativa es que hay tal diferencia. La forma de la distribución \\(\\chi^2\\), al igual que la de t, depende de los grados de liberdad que desarrollaremos más adelante."
  },
  {
    "objectID": "09-chi-cuadrado.html#prueba-de-independencia-o-asociación",
    "href": "09-chi-cuadrado.html#prueba-de-independencia-o-asociación",
    "title": "9  Prueba de \\(\\chi^2\\)",
    "section": "9.2 Prueba de independencia o asociación",
    "text": "9.2 Prueba de independencia o asociación\nUn uso muy frecuente de la prueba de \\(\\chi^2\\) es la de probar si dos características son independientes o tienen una asociación de manera que las frecuencias elevadas en una de ellas suele ser acompañado con frecuencias altas en la otra.\nDigamos que estamos haciendo una encuesta de opinión y preguntamos a 1230 argentinas y a 961 argentinos si están a favor o en contra de la ley del aborto o no. Queremos saber si en género de la persona está asociado con esa opinión. Entonces nuestros datos se pueden desplegar en una tabla 2 por 2.\n\n\n?(caption)\n\n\n\n\n\n\n\nA favor\nEn contra\n\n\n\n\nMujeres\n762\n468\n\n\nHombres\n484\n477\n\n\n\n\n\n\nLa hipótesis nula es que no hay asociación entre las dos variables, es decir que el género de la persona no se asocia con su opinión política sobre este tema. Para calcular los valores esperados tenemos que calcular las sumas de las filas y las columnas y además el total de ellos.\n\n\n\n\nTabla 9.1: Opiniones sobre la ley del aborto.\n\n\n\nA favor\nEn contra\ntotal\n\n\n\n\nMujeres\n762\n468\n1230\n\n\nHombres\n484\n477\n961\n\n\ntotal\n1246\n945\n2191\n\n\n\n\n\n\nEl valor esperado es la cantidad de las observaciones que caen en cada celda si las distribuimos proporcionalmente. Esto se calcula multiplicando las sumas de la fila y columna de la celda respectiva y dividir por el total de las observaciones. Por ejemplo, el valor esperado de mujeres a favor sería:\n\\[\nE = {{1230\\times1246}\\over2191} = 699,48\n\\]\nSi calculamos esto para todas las celdas obtenemos:\n\n\n\n\nTabla 9.2: Valores esperados: opiniones sobre la ley del aborto.\n\n\n\nA favor\nEn contra\ntotal\n\n\n\n\nMujeres\n699,49\n530,51\n1230\n\n\nHombres\n546,51\n414,49\n961\n\n\ntotal\n1246,00\n945,00\n2191\n\n\n\n\n\n\ny con esto podemos calcular las diferencias.\n\n\n\n\nTabla 9.3: Diferencias entre valores observados y esperados.\n\n\n\nA favor\nEn contra\n\n\n\n\nMujeres\n62,51\n-62,51\n\n\nHombres\n-62,51\n62,51\n\n\n\n\n\n\ny podemos aplicar la fórmula en la definición 9.1:\n\\[\n\\chi^2 = \\sum{(O-E)^2\\over{E}} = {62,52^2\\over699,49} +{-62,52^2\\over530,51} +{62,52^2\\over546,51}+{-62,52^2\\over414,49} = 29,53.\n\\]\nPodemos comparar este valor con los de la tabla en el apendice C para un grado de libertad. Vemos que rechazamos \\(H_0\\) y concluimos que el género sí influye en la opinión sobre este tema.\n\n9.2.1 Grados de libertad\nA lo largo de este texto se ha mencionado en algunas ocasiones el término grados de libertad y hasta ahora no ha sido demasiado complejo calcularlo restando uno del número de observaciones. El concepto de grado de libertad se puede entender si consideramos la tabla 9.1 en la que tenemos una tabla de contingencia \\(2\\times2\\). Calculamos en ese caso las frecuencias marginales que están el la columna suma. Imaginemos que tenemos la misma tabla con las frecuencias marginales pero con una sola de las frecuencias observadas. Así lo hemos hecho en la tabla 9.4.\n\n\n\n\nTabla 9.4: Tabla de contingencia con un solo valor.\n\n\n\nA favor\nEn contra\ntotal\n\n\n\n\nMujeres\n762\n-\n1230\n\n\nHombres\n-\n-\n961\n\n\ntotal\n1246\n945\n2191\n\n\n\n\n\n\nCon este único valor podemos rellenar las demás celdas, ya que su contenido está dato por la diferencia entre ese valor y los totales marginales. Esto quiere decir que en esta tabla hay un solo valor que se pueda asignar arbitrariamente, el resto está dado por este valor. Por ello decimos que tenemos un solo grado de libertad.\nEn capítulos anteriores hemos visto que los grados de libertad a menudo son N-1. Podemos usar un ejemplo sencillo para demostrar por qué tiene que ser así. Si hacemos un conjunto de tres números y queremos que la suma sea diez, podemos asignar cualquier número en las primeras dos posiciones, pero cuando vamos a asignar el tercero ya no tenemos libertad de eligir. Entonces tenemos dos grados de libertad.\nPara una tabla de contingencia la fórmula general para calcular los grados de libertad es: \\((c-1)\\times(f-1)\\) es decir número de columnas menos uno por número de filas menos uno. Si la tabla es de \\(3\\times3\\), tendríamos 4 grados de libertad."
  },
  {
    "objectID": "09-chi-cuadrado.html#prueba-de-chi2-en-r",
    "href": "09-chi-cuadrado.html#prueba-de-chi2-en-r",
    "title": "9  Prueba de \\(\\chi^2\\)",
    "section": "9.3 Prueba de \\(\\chi^2\\) en R",
    "text": "9.3 Prueba de \\(\\chi^2\\) en R\n\nEn este ejemplo vamos a realizar la misma prueba de \\(\\chi^2\\) que fuimos desarrollando en las secciones anteriores. Podemos usar la función de R chisq.test para realizarla. Toma como argumento una matriz de datos de las frecuencias.\n\nM <- as.table(\n  rbind(c(762, 468), \n        c(484, 477))\n  )\n# Damos nombre a las columnas y las filas \ncolnames(M) <- c(\"A favor\",\"En contra\")\nrownames(M) <- c(\"Mujeres\",\"Hombres\")\n\n# Verificamos el ingreso de datos\nM\n\n#>         A favor En contra\n#> Mujeres     762       468\n#> Hombres     484       477\n\n\nComo se puede observar, la sintaxis de R no es del todo intuitiva, por lo que siempre conviene verificar que tenemos los números y nombres correctos antes de proceder con el test.\n\n# Realizamos test de ji-cuadrado\nchisq.test(M)\n\n#> \n#>  Pearson's Chi-squared test with Yates' continuity\n#>  correction\n#> \n#> data:  M\n#> X-squared = 29.06, df = 1, p-value = 7.019e-08\n\n\nEl valor de p es tan bajo que R lo devuelve en notación científica. La parte e-08 quiere decir que el número es: 0,000000007019, es decir que hay ocho ceros antes de los dígitos significativos.\nTambién vemos que el valor de \\(\\chi^2\\) que calculó R es distinto al que calculamos a mano, aunque sea por unas décimas. Esto se debe a que por defecto R hace una corrección de Yates. Yates descubrió que para una tabla de contingencia \\(2\\times2\\) hay un sesgo positivo y propuso una técnica para contrarrestar el sesgo. Si queremos usar la formula original, y la que usamos para nuestro cálculo a mano podemos agregar el parámetro correct = FALSE a la función así:\n\nchisq.test(M, correct = FALSE)\n\n#> \n#>  Pearson's Chi-squared test\n#> \n#> data:  M\n#> X-squared = 29.53, df = 1, p-value = 5.506e-08\n\n\ny vemos que R coincide con nuestros cálculos."
  },
  {
    "objectID": "09-chi-cuadrado.html#glosario",
    "href": "09-chi-cuadrado.html#glosario",
    "title": "9  Prueba de \\(\\chi^2\\)",
    "section": "9.4 Glosario",
    "text": "9.4 Glosario\n\nGrados de libertad\n\nNúmero de valores que se pueda asignar arbitrariamente a un conjunto manteniendo estable sus propiedades. Equivalente en inglés: «Degrees of freedom».\n\nPrueba de \\(\\chi^2\\) «ji cuadrado»\n\nPrueba estadística que nos permite apreciar si dos variables nominales están asociadas. Fórmula: \\(\\chi^2 = \\sum{(O-E)^2\\over{E}}\\) Equivalente en inglés: «Chi-square test»."
  },
  {
    "objectID": "10-correlaciones.html",
    "href": "10-correlaciones.html",
    "title": "10  Correlación",
    "section": "",
    "text": "La correlación es el área de las estadísticas que estudia la relación sistemática entre dos o más variables e intenta contestar a preguntas como: ¿Si sube A va a subir B también? En este capítulo desarrollaremos algunas técnicas para contestar este tipo de pregunta."
  },
  {
    "objectID": "10-correlaciones.html#visualización",
    "href": "10-correlaciones.html#visualización",
    "title": "10  Correlación",
    "section": "10.1 Visualización",
    "text": "10.1 Visualización\nEl primer paso para estudiar posibles relaciones entre variables es visualizarlos. Si tenemos dos variables medidas por cada miembro de la población o muestra que estamos investigando podemos generar un diagrama de disperción también conocido como scatterplot. En este tipo de visualización cada miembro de la muestra/población está representado por un punto, y las coordinadas del punto corresponde a las dos variables que hemos medido, en el eje horizontal y vertical respectivamente.\nEl la figura 10.1, vemos que la concentración de puntos suben de la izquierda a la derecha. Es decir cuando avanzamos en el eje horizontal avanzamos en el eje vertical también. Es un ejemplo de una correlación positiva, como podría ser edad y estatura.\n\n\n\n\n\nFigura 10.1: Correlación positiva\n\n\n\n\nEn la figura 10.2 vemos lo contrario, mientras avanzamos en el eje vertical retrocedemos (o bajamos) en el eje horizontal. Esto se conoce como correlacion negativa.\n\n\n\n\n\nFigura 10.2: Correlación negativa\n\n\n\n\nEn la figura 10.3, también vemos correlación negativa, pero es menos fuerte que en la figura 10.2.\n\n\n\n\n\nFigura 10.3: Correlación negative leve\n\n\n\n\nEn la figura 10.4 vemos una correlación negativa casi perfecta entre las dos variables.\n\n\n\n\n\nFigura 10.4: Correlación casi perfecta\n\n\n\n\nEn la figura 10.5 vemos un caso de correlación inexistente entre las variables en cuestión.\n\n\n\n\n\nFigura 10.5: Correlación nula\n\n\n\n\nEn la figura 10.6 vemos que existe una relación entre las dos variables, pero que esta no es lineal.1\n\n\n\n\n\nFigura 10.6: Relación no lineal\n\n\n\n\nLas figuras 10.1, 10.2, 10.3, 10.4, -Figura 10.5] y 10.6 demuestran por qué es preciso graficar los datos al inicio del análisis. Nos da una indicación de si existe una correlación o no, si es positiva o negativa y que tan fuerte es. También nos podemos darnos cuenta de patrones en los datos que no son lineales, como es el caso de los datos en la figura 10.6. Asimismo, a veces nos encontramos con una correlación como la que vemos en la figura 10.4. Las correlaciones que son demasiado perfectas suelen ser un signo de advertencia y podemos preguntarnos si en realidad son dos variables distintas o si las dos están midiendo lo mismo.\n\n\nEjemplo 10.1 (Generar diagrama de dispersión en R) \n# Generamos datos\ndatos = data.frame(\n  x=rnorm(100),\n  y=rnorm(100)\n)\n\n# Graficamos\nplot(datos)\n\n\n\n\n\nEn el ejemplo 10.1 utilizamos la función rnorm para generar cien observaciones aleatorias con distribución normal y los ponemos dentro de un data.frame. Luego usamos la función plot para graficarlos. Como nuestro data.frame tiene solo dos columnas R entiende que estos son los datos que queremos graficar. Si el data.frame tiene más columnas, podemos especificar los que queremos graficar así:\n\nplot(datos$x,datos$y)"
  },
  {
    "objectID": "10-correlaciones.html#generar-diagrama-de-dispersión-en-r-1",
    "href": "10-correlaciones.html#generar-diagrama-de-dispersión-en-r-1",
    "title": "10  Correlación",
    "section": "10.2 Generar diagrama de dispersión en R",
    "text": "10.2 Generar diagrama de dispersión en R\n\nPor defecto R viene con algunos data.frames ya cargados, uno de ellos es «trees», podemos usar la función head para ver las primeras seis filas.\n\nhead(trees)\n\n#>   Girth Height Volume\n#> 1   8.3     70   10.3\n#> 2   8.6     65   10.3\n#> 3   8.8     63   10.2\n#> 4  10.5     72   16.4\n#> 5  10.7     81   18.8\n#> 6  10.8     83   19.7\n\n\nVemos que tiene tres columnas «Girth», «Height» y «Volume» (circumferencia, alto y volumen), los que, por lógica, deben tener alta correlación. Graficamos dos de ellos.\n\nplot(trees$Girth, trees$Volume)\n\n\n\n\nSi usamos la función plot sin especificar columnas R entiende que queremos ver todas las combinaciones.\n\nplot(trees)\n\n\n\n\nEste tipo de visualización puede ser útil cuando tenemos algunas variables y queremos darnos cuenta qué correlaciones hay. La visualización funciona bien hasta cierto número de columnas –ocho más o menos–, luego se vuelve difícil de leer y por ende de interpretar."
  },
  {
    "objectID": "10-correlaciones.html#coeficientes-de-correlación",
    "href": "10-correlaciones.html#coeficientes-de-correlación",
    "title": "10  Correlación",
    "section": "10.3 Coeficientes de correlación",
    "text": "10.3 Coeficientes de correlación\nPara tener una medida cuantitativa precisa de la correlación entre las variables calculamos un coeficiente de correlación. A continuación vamos a tres de ellos, el de Pearson, el de Spearman y el coeficiente \\(\\phi\\) (de la letra griega que corresponde a f en minúscula – se pronuncia «fi». Los coeficientes de correlación se expresan por un número con varios decimales entre -1 y 1, donde -1 y 1 indican correlaciones perfectas, negativas y positivas respectivamente y 0 indica correlación nula.\nEl coeficiente Pearson es adecuado para datos de escala de razón o intervalo, el de Spearman para datos de escala ordinal y el coeficiente \\(\\phi\\) se usa para datos nominales.\n\n10.3.1 Coeficiente Pearson\nComo ya mencionamos, el coeficiente de Pearson es apropiado cuando las variables a comparar con de escala de intervalo o razón ya que toma en cuenta la magnitud relativa de las observaciones.\nSi tenemos un conjunto de pares de observaciones podemos representar el primer elemento del par por x y el segundo por y. Entonces el conjunto de los x van a tener una desviación estándar se calcula según la definición 3.4, así:\n\\[\ns_x = {\\sqrt{(\\sum(x-\\bar{x})^2\\over{N-1}}}.\n\\]\nDe la misma manera y tiene su desviación estándar: \\[\ns_y = {\\sqrt{(\\sum(y-\\bar{y})^2\\over{N-1}}}.\n\\]\nAhora podemos normalizar las variables según la definición 4.1 asi:\n\\[\nz_x = {x-\\bar{x}\\over{s_x}},\n\\]\n\\[\nz_y = {y-\\bar{y}\\over{s_y}}.\n\\]\nY con estos datos podemos calcular el coeficiente según la definición 10.1.\n\nDefinición 10.1 (Coeficiente de correlación de Pearson) \\[\nr={\\sum{z_xz_y}\\over{N-1}}\n\\] donde:\n\n\\(\\sum{z_xz_y}\\): La suma de los productos2 de las dos variables normalizadas.\n\n\nExiste otra definición es matemáticamente equivalente y que se usa a veces para hacer el cálculo a mano:"
  },
  {
    "objectID": "10-correlaciones.html#coeficiente-de-correlación-pearson",
    "href": "10-correlaciones.html#coeficiente-de-correlación-pearson",
    "title": "10  Correlación",
    "section": "10.4 Coeficiente de correlación Pearson",
    "text": "10.4 Coeficiente de correlación Pearson\n\\[\nr={N\\Sigma{xy}-\\Sigma{x}\\Sigma{y}\\over{\\sqrt{\\{N\\Sigma{x^2}-(\\Sigma{x})^2\\}\\times\\{N\\Sigma{y^2}-(\\Sigma{y})^2\\} }}}\n\\]"
  },
  {
    "objectID": "10-correlaciones.html#interpretación-de-correlacciones",
    "href": "10-correlaciones.html#interpretación-de-correlacciones",
    "title": "10  Correlación",
    "section": "10.5 Interpretación de correlacciones",
    "text": "10.5 Interpretación de correlacciones\nEs muy importante entender que una correlación, incluso alta, entre dos variables no quiere decir que la relación entre ellas es de causa y efecto. Si hacemos una muestra en la escuela secundaria y medimos estatura, por un lado, y nivel de inglés por otra, es bastante probable que encontremos una correlación muy fuerte entre las dos variables. Pero debería estar claro que ni la estatura causa conocimientos de inglés ni tampoco lo contrario. Lo que claramente pasa es que mas edad los estudiantes tienen más estatura y han cursado más niveles de inglés.\nSaltar a conclusiones sobre causalidad basadas en correlaciones es tal vez el error estadístico más frecuente en la literatura tanto académica como periodística. Nunca hay que olvidar que una correlación significativa solo nos dice que existe una relación matemática entre dos variables. No nos indica cómo interpretarla ni mucho menos sobre sus causas y efectos."
  },
  {
    "objectID": "10-correlaciones.html#glosario",
    "href": "10-correlaciones.html#glosario",
    "title": "10  Correlación",
    "section": "10.6 Glosario",
    "text": "10.6 Glosario\n\nCoeficiente \\(\\phi\\) «fi».\n\nCoeficiente que da cuenta de la correlación entre dos variables nominales. Fórmula: \\(\\phi = {{BC-AD}\\over{\\sqrt{(A+B)\\times(C+D)\\times(A+C)\\times(B+D)}}}\\) Función relevante en R: chi.test. Equivalente en inglés: «Phi correlation».\n\nCoeficiente de correlación de Pearson\n\nCoeficiente que da cuenta de la correlación entre dos variables. Fórmula: \\(r={\\sum{z_xz_y}\\over{N-1}}\\) Función relevante en R: cor. Equivalente en inglés: «Pearson coefficient».\n\nCoeficiente Spearman\n\nCoeficiente que da cuenta de la correlación entre dos variables cuando una o ambas de ellas son de escala ordinal. Fórmula: \\(\\rho = 1-{6\\sum{d^2}\\over{N(N^2-1)}}\\) Función relevante en R: cor. Equivalente en inglés: «Spearman coefficient».\n\nCorrelación negativa\n\nRelación entre dos variables que muestra que si una aumenta la otra disminuye. Equivalente en inglés: «Positive correlation».\n\nCorrelación positiva\n\nRelación entre dos variables que muestra que ambas aumentan o disminuyen simultáneamente. Equivalente en inglés: «Positive correlation».\n\n\n\n\n\n\nButler, Christopher. 1985. Statistics in linguistics. Basil Blackwell."
  },
  {
    "objectID": "11-referencias.html",
    "href": "11-referencias.html",
    "title": "Referencias",
    "section": "",
    "text": "Allaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin\nUshey, Aron Atkins, Hadley Wickham, Joe Cheng, Winston Chang, and\nRichard Iannone. 2019. Rmarkdown: Dynamic Documents for r. https://CRAN.R-project.org/package=rmarkdown.\n\n\nAusten, Jane. 1817. Persuasion. John Murray.\n\n\nButler, Christopher. 1985. Statistics in Linguistics. Basil\nBlackwell.\n\n\nENNyS. 2007. “Encuesta Nacional de Nutrición y Salud.”\nMinisterio de Salud de Argentina.\n\n\nMakowski, Dominique, Mattan S. Ben-Shachar, and Daniel Lüdecke. 2019.\n“bayestestR: Describing Effects and Their Uncertainty, Existence\nand Significance Within the Bayesian Framework.” Journal of\nOpen Source Software 4 (40): 1541. https://doi.org/10.21105/joss.01541.\n\n\nShier, Rosie. 2004. “Paired t-Tests.” http://www.statstutor.ac.uk/resources/uploaded/paired-t-test.pdf.\n\n\nSilge, Julia, and David Robinson. 2016. “Tidytext: Text Mining and\nAnalysis Using Tidy Data Principles in r.” JOSS 1 (3).\nhttps://doi.org/10.21105/joss.00037.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy\nD’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019.\n“Welcome to the tidyverse.”\nJournal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nXie, Yihui. 2015. Dynamic Documents with R and\nKnitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. http://yihui.name/knitr/.\n\n\n———. 2018. Bookdown: Authoring Books and Technical Documents with r\nMarkdown. https://CRAN.R-project.org/package=bookdown."
  },
  {
    "objectID": "A-valores-criticos-t.html",
    "href": "A-valores-criticos-t.html",
    "title": "Appendix A — Distribución t",
    "section": "",
    "text": "Tabla A.1: Valores críticos de t por nivel de significanza y grados de libertad.\n\n\nGrados\np < 0,20\np < 0,10\np < 0,05\np < 0,02\np < 0,01\n\n\n\n\n1\n3,078\n6,314\n12,706\n31,821\n63,657\n\n\n2\n1,886\n2,920\n4,303\n6,965\n9,925\n\n\n3\n1,638\n2,353\n3,182\n4,541\n5,841\n\n\n4\n1,533\n2,132\n2,776\n3,747\n4,604\n\n\n5\n1,476\n2,015\n2,571\n3,365\n4,032\n\n\n6\n1,440\n1,943\n2,447\n3,143\n3,707\n\n\n7\n1,415\n1,895\n2,365\n2,998\n3,499\n\n\n8\n1,397\n1,860\n2,306\n2,896\n3,355\n\n\n9\n1,383\n1,833\n2,262\n2,821\n3,250\n\n\n10\n1,372\n1,812\n2,228\n2,764\n3,169\n\n\n11\n1,363\n1,796\n2,201\n2,718\n3,106\n\n\n12\n1,356\n1,782\n2,179\n2,681\n3,055\n\n\n13\n1,350\n1,771\n2,160\n2,650\n3,012\n\n\n14\n1,345\n1,761\n2,145\n2,624\n2,977\n\n\n15\n1,341\n1,753\n2,131\n2,602\n2,947\n\n\n16\n1,337\n1,746\n2,120\n2,583\n2,921\n\n\n17\n1,333\n1,740\n2,110\n2,567\n2,898\n\n\n18\n1,330\n1,734\n2,101\n2,552\n2,878\n\n\n19\n1,328\n1,729\n2,093\n2,539\n2,861\n\n\n20\n1,325\n1,725\n2,086\n2,528\n2,845\n\n\n21\n1,323\n1,721\n2,080\n2,518\n2,831\n\n\n22\n1,321\n1,717\n2,074\n2,508\n2,819\n\n\n23\n1,319\n1,714\n2,069\n2,500\n2,807\n\n\n24\n1,318\n1,711\n2,064\n2,492\n2,797\n\n\n25\n1,316\n1,708\n2,060\n2,485\n2,787\n\n\n26\n1,315\n1,706\n2,056\n2,479\n2,779\n\n\n27\n1,314\n1,703\n2,052\n2,473\n2,771\n\n\n28\n1,313\n1,701\n2,048\n2,467\n2,763\n\n\n29\n1,311\n1,699\n2,045\n2,462\n2,756\n\n\n30\n1,310\n1,697\n2,042\n2,457\n2,750"
  },
  {
    "objectID": "B-valores-criticos-test-de-signo.html",
    "href": "B-valores-criticos-test-de-signo.html",
    "title": "Appendix B — Valores críticos del test de signo",
    "section": "",
    "text": "── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\n\nTabla B.1: Valores críticos de W en el test de signo por N.\n\n\nN\n0,05\n0,025\n0,01\n\n\n\n\n5\n0\n-\n-\n\n\n6\n0\n0\n-\n\n\n7\n0\n0\n0\n\n\n8\n1\n0\n0\n\n\n9\n1\n1\n0\n\n\n10\n1\n1\n0\n\n\n11\n2\n1\n1\n\n\n12\n2\n2\n1\n\n\n13\n3\n2\n1\n\n\n14\n3\n2\n2\n\n\n15\n3\n3\n2\n\n\n16\n4\n3\n2\n\n\n17\n4\n4\n3\n\n\n18\n5\n4\n3\n\n\n19\n5\n4\n4\n\n\n20\n5\n5\n4\n\n\n21\n6\n5\n4\n\n\n22\n6\n5\n5\n\n\n23\n7\n6\n5\n\n\n24\n7\n6\n5\n\n\n25\n7\n7\n6"
  },
  {
    "objectID": "C-valores-criticos-ji-cuadrado.html",
    "href": "C-valores-criticos-ji-cuadrado.html",
    "title": "Appendix C — Distribución \\(\\chi^2\\)",
    "section": "",
    "text": "Tabla C.1: Valores críticos de χ2 por nivel de significanza y grados de libertad.\n\n\nGL\np < 0,20\np < 0,10\np < 0,05\np < 0,02\np < 0,01\np < 0,001\n\n\n\n\n1\n1,642\n2,706\n3,841\n5,024\n6,635\n10,828\n\n\n2\n3,219\n4,605\n5,991\n7,378\n9,210\n13,816\n\n\n3\n4,642\n6,251\n7,815\n9,348\n11,345\n16,266\n\n\n4\n5,989\n7,779\n9,488\n11,143\n13,277\n18,467\n\n\n5\n7,289\n9,236\n11,070\n12,833\n15,086\n20,515\n\n\n6\n8,558\n10,645\n12,592\n14,449\n16,812\n22,458\n\n\n7\n9,803\n12,017\n14,067\n16,013\n18,475\n24,322\n\n\n8\n11,030\n13,362\n15,507\n17,535\n20,090\n26,124\n\n\n9\n12,242\n14,684\n16,919\n19,023\n21,666\n27,877\n\n\n10\n13,442\n15,987\n18,307\n20,483\n23,209\n29,588\n\n\n11\n14,631\n17,275\n19,675\n21,920\n24,725\n31,264\n\n\n12\n15,812\n18,549\n21,026\n23,337\n26,217\n32,909\n\n\n13\n16,985\n19,812\n22,362\n24,736\n27,688\n34,528\n\n\n14\n18,151\n21,064\n23,685\n26,119\n29,141\n36,123\n\n\n15\n19,311\n22,307\n24,996\n27,488\n30,578\n37,697\n\n\n16\n20,465\n23,542\n26,296\n28,845\n32,000\n39,252\n\n\n17\n21,615\n24,769\n27,587\n30,191\n33,409\n40,790\n\n\n18\n22,760\n25,989\n28,869\n31,526\n34,805\n42,312\n\n\n19\n23,900\n27,204\n30,144\n32,852\n36,191\n43,820\n\n\n20\n25,038\n28,412\n31,410\n34,170\n37,566\n45,315\n\n\n21\n26,171\n29,615\n32,671\n35,479\n38,932\n46,797\n\n\n22\n27,301\n30,813\n33,924\n36,781\n40,289\n48,268\n\n\n23\n28,429\n32,007\n35,172\n38,076\n41,638\n49,728\n\n\n24\n29,553\n33,196\n36,415\n39,364\n42,980\n51,179\n\n\n25\n30,675\n34,382\n37,652\n40,646\n44,314\n52,620\n\n\n26\n31,795\n35,563\n38,885\n41,923\n45,642\n54,052\n\n\n27\n32,912\n36,741\n40,113\n43,195\n46,963\n55,476\n\n\n28\n34,027\n37,916\n41,337\n44,461\n48,278\n56,892\n\n\n29\n35,139\n39,087\n42,557\n45,722\n49,588\n58,301\n\n\n30\n36,250\n40,256\n43,773\n46,979\n50,892\n59,703"
  }
]